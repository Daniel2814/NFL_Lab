{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56281bee",
   "metadata": {},
   "source": [
    "## Kaggle Predections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864256f9",
   "metadata": {},
   "source": [
    "### Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "413040de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import gc\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "torch.manual_seed(26)\n",
    "os.chdir('C:/Users/dalto/OneDrive/Pictures/Documents/Emory/NFL Lab/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afffe8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/dalto/OneDrive/Pictures/Documents/Emory/NFL Lab/data/train/input_2023_w01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bf0f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['play_id_n'] = df.groupby(['game_id','play_id']).ngroup()\n",
    "df['play_direction'] = df['play_direction'].str.strip().str.lower()\n",
    "df.loc[df['play_direction'] == 'left', 'y'] = 53.3 - df.loc[df['play_direction'] == 'left', 'y']\n",
    "df.loc[df['play_direction'] == 'left', 'x'] = 120 - df.loc[df['play_direction'] == 'left', 'x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f52bd466",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_targets = 9\n",
    "max_input = 123\n",
    "max_output = 94"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c07241e",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c0fecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_size, dropout, max_length=150):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # droput\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # create matrix\n",
    "        pe = torch.zeros(max_length, embed_size)\n",
    "\n",
    "        # position tensor shape\n",
    "        position = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        # div_term tensor shape\n",
    "        div_term = torch.exp(torch.arange(0, embed_size, 2).float() * (-torch.log(torch.tensor(10000.0)) / embed_size))\n",
    "\n",
    "        # apply sin to even indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "\n",
    "        # apply cos to odd indices\n",
    "        if embed_size % 2 == 1:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term[:-1])\n",
    "        else:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # register as buffer so it moves with model to device\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pe_slice = self.pe[:x.size(1), :].to(x.device)\n",
    "        x = x + pe_slice\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f475aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerPositionEmbedding(nn.Module):\n",
    "    def __init__(self, embed_size, num_positions = 19):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        self.position_projection = nn.Embedding(num_positions, embed_size)\n",
    "\n",
    "    def forward(self, player_positons, target_masks):\n",
    "        # ints to learnable embedding space\n",
    "        pos_embeds = self.position_projection(player_positons.long().squeeze(-1))\n",
    "\n",
    "        # target mask, ignore padded values\n",
    "        target_mask_expand = target_masks.unsqueeze(-1).expand_as(pos_embeds)\n",
    "        pos_embeds = pos_embeds * target_mask_expand.float()\n",
    "\n",
    "        return pos_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba12b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, scale=10.0):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.scale = scale\n",
    "        self.B = nn.Parameter(torch.randn(input_dim, embed_dim // 2) * scale, requires_grad=False)\n",
    "\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # float bc autocast\n",
    "        x_proj = (2 * np.pi * x.float()) @ self.B.float()\n",
    "        x_embed = torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "        return self.out_proj(x_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "762ad226",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialSoftmax(nn.Module):\n",
    "  def __init__(self, height, width, device='cuda'):\n",
    "    super(SpatialSoftmax, self).__init__()\n",
    "    self.height = height\n",
    "    self.width = width\n",
    "    self.device = device\n",
    "\n",
    "    pos_x, pos_y = np.meshgrid(np.linspace(-1., 1., width),\n",
    "                               np.linspace(-1., 1., height))\n",
    "\n",
    "    pos_x = torch.from_numpy(pos_x.reshape(self.height * self.width)).float().to(device)\n",
    "    pos_y = torch.from_numpy(pos_y.reshape(self.height * self.width)).float().to(device)\n",
    "\n",
    "    self.register_buffer('pos_x', pos_x)\n",
    "    self.register_buffer('pos_y', pos_y)\n",
    "\n",
    "  def forward(self, feature_map):\n",
    "    B, C, H, W = feature_map.shape\n",
    "    feature_flat = feature_map.view(B, C, -1)\n",
    "    softmax_attn = F.softmax(feature_flat, dim=-1)\n",
    "\n",
    "    expected_x = torch.sum(self.pos_x * softmax_attn, dim=2, keepdim = True)\n",
    "    expected_y = torch.sum(self.pos_y * softmax_attn, dim=2, keepdim = True)\n",
    "\n",
    "    expected_xy = torch.cat([expected_x, expected_y], dim=2)\n",
    "\n",
    "    return expected_xy.view(B, -1)\n",
    "\n",
    "class CNN_DownSample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        # variable based on amount of targets\n",
    "        input_chan = 2 + max_targets + 1\n",
    "\n",
    "        self.heatmap_encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_chan, out_channels=32, kernel_size=3, stride = 2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride = 1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride = 1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.spatial_softmax = SpatialSoftmax(height=28, width=61)\n",
    "\n",
    "        # heatmap to embedding\n",
    "        self.output_proj = nn.Linear(128, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.heatmap_encoder(x)\n",
    "        x = self.spatial_softmax(x)\n",
    "        x = self.output_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "708868a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, embed_size, num_layers, nhead, device, dropout, mask, max_length):\n",
    "        super(TransEncoder, self).__init__()\n",
    "        # emebef size and deivice\n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "\n",
    "        # learned matrix projection\n",
    "        self.input_projection = nn.Linear(input_dim, embed_size)\n",
    "\n",
    "        # postional encoding\n",
    "        self.position_encoding = PositionalEncoding(embed_size, dropout, max_length)\n",
    "\n",
    "        # transformer encoder layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_size,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=embed_size,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "\n",
    "        # transformation encoder\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # normalize after attention\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # input layer matrix mult\n",
    "        projected_input = self.input_projection(x)\n",
    "        # position encodings\n",
    "        out = self.position_encoding(projected_input)\n",
    "        # invert mask\n",
    "        src_key_padding_mask = ~mask\n",
    "        out = self.transformer_encoder(out, src_key_padding_mask=src_key_padding_mask)\n",
    "        # normalize gradients\n",
    "        out = self.norm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdcf6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransDecoder(nn.Module):\n",
    "    def __init__(self, target_mask, embedding, dropout, nhead, layers, max_targets, max_step_change, max_seq_len):\n",
    "        super(TransDecoder, self).__init__()\n",
    "        self.max_targets = max_targets\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.embedding = embedding\n",
    "        self.max_step = max_step_change\n",
    "        self.pos_dim = 8\n",
    "        self.role_dim = 2\n",
    "\n",
    "        # project 2d cords to embedding space\n",
    "        self.start_pos_projection = FourierEmbedding(2, embedding, scale=1.0)\n",
    "\n",
    "        # projection for movement\n",
    "        self.delta_projection = FourierEmbedding(5, embedding, scale=5.0)\n",
    "\n",
    "        # player pos embeddings\n",
    "        self.player_pos_embedding = PlayerPositionEmbedding(self.pos_dim, 19)\n",
    "\n",
    "        # player pos embeddings\n",
    "        self.player_role_embedding = PlayerPositionEmbedding(self.role_dim, 4)\n",
    "\n",
    "        # concat info\n",
    "        self.input_fusion = nn.Linear(embedding + self.role_dim + self.pos_dim, embedding)\n",
    "\n",
    "        # project outputs back to 2d space\n",
    "        self.output_projection = nn.Linear(embedding, 5)\n",
    "\n",
    "        # postional embeddings\n",
    "        self.pos_embed = PositionalEncoding(embed_size=embedding, dropout=0.15, max_length=150)\n",
    "\n",
    "        # decoder layers\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=embedding,\n",
    "                                                    nhead=nhead,\n",
    "                                                    dim_feedforward=embedding,\n",
    "                                                    dropout=dropout,\n",
    "                                                    batch_first=True,\n",
    "                                                    norm_first=True)\n",
    "\n",
    "        # decoder\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=layers)\n",
    "\n",
    "        # norm\n",
    "        self.norm = nn.LayerNorm(embedding)\n",
    "\n",
    "    def forward(self, encoded_context, start_positions, target_mask, player_position, player_role, encoder_padding_mask=None):\n",
    "        # project all of the postion embeddings\n",
    "        player_pos_embeds = self.player_pos_embedding(player_position, target_mask)\n",
    "        # role embeds\n",
    "        player_role_embeds = self.player_role_embedding(player_role, target_mask)\n",
    "        # train vs validation\n",
    "        return self.val_forward(encoded_context, start_positions, player_pos_embeds, player_role_embeds, encoder_padding_mask)\n",
    "\n",
    "    def val_forward(self, encoded_context, start_positions, player_pos_embeds, player_role_embeds, encoder_padding_mask):\n",
    "        device = encoded_context.device\n",
    "        batch_size = encoded_context.shape[0]\n",
    "\n",
    "        # init pos\n",
    "        current_input = self.start_pos_projection(start_positions).unsqueeze(2)\n",
    "\n",
    "        # player pos embeddings\n",
    "        pos_embeds = player_pos_embeds.unsqueeze(2)\n",
    "        role_embeds = player_role_embeds.unsqueeze(2)\n",
    "        combined_init = torch.cat([current_input, role_embeds, pos_embeds], dim=-1)\n",
    "        current_input_fused = self.input_fusion(combined_init)\n",
    "\n",
    "        # reshape, previous inputs\n",
    "        decoder_history = current_input_fused.view(batch_size * self.max_targets, 1, self.embedding)\n",
    "\n",
    "        # context\n",
    "        expanded_context = encoded_context.repeat_interleave(self.max_targets, dim=0)\n",
    "\n",
    "        # mem mask\n",
    "        if encoder_padding_mask is not None:\n",
    "            memory_key_padding_mask = encoder_padding_mask.repeat_interleave(self.max_targets, dim=0)\n",
    "        else:\n",
    "            memory_key_padding_mask = None\n",
    "\n",
    "        all_predictions = []\n",
    "\n",
    "        # predict actual output seq\n",
    "        for step in range(self.max_seq_len):\n",
    "\n",
    "            # postions\n",
    "            history_encoded = self.pos_embed(decoder_history)\n",
    "\n",
    "            # casual mask\n",
    "            seq_len = history_encoded.shape[1]\n",
    "            tgt_mask = nn.Transformer.generate_square_subsequent_mask(seq_len, device=device)\n",
    "\n",
    "            # through the decoded layers\n",
    "            decoded = self.transformer_decoder(\n",
    "                tgt = history_encoded,\n",
    "                memory = expanded_context,\n",
    "                tgt_mask=tgt_mask,\n",
    "                memory_key_padding_mask=memory_key_padding_mask)\n",
    "\n",
    "            decoded = self.norm(decoded)\n",
    "\n",
    "            # predict only last step\n",
    "            last_step_output = decoded[:, -1:, :]\n",
    "            next_delta_pred = self.output_projection(last_step_output)\n",
    "\n",
    "            all_predictions.append(next_delta_pred.view(batch_size, self.max_targets, 5))\n",
    "\n",
    "            # project to cords\n",
    "            next_input_embed = self.delta_projection(next_delta_pred)\n",
    "\n",
    "            # add player id context\n",
    "            player_pos_flat = player_pos_embeds.view(batch_size * self.max_targets, 1, -1)\n",
    "            player_role_flat = player_role_embeds.view(batch_size * self.max_targets, 1, -1)\n",
    "            combined_next = torch.cat([next_input_embed, player_pos_flat, player_role_flat], dim=-1)\n",
    "            next_input_fused = self.input_fusion(combined_next)\n",
    "\n",
    "            # add to context\n",
    "            decoder_history = torch.cat([decoder_history, next_input_fused], dim=1)\n",
    "\n",
    "        # stack and return preds\n",
    "        return torch.stack(all_predictions, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42f0b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqPrediction(nn.Module):\n",
    "    def __init__(self, embed_size, encoder_layers, decoder_layers,\n",
    "                 max_targets, dropout, nheads, max_step, dev='cuda') -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # general vars\n",
    "        self.embedding_size = embed_size\n",
    "        self.max_targets = max_targets\n",
    "        self.device = dev\n",
    "\n",
    "        # context cnn\n",
    "        self.context_cnn = CNN_DownSample(dim=embed_size)\n",
    "\n",
    "        # transformer encoder\n",
    "        self.encoder = TransEncoder(input_dim=embed_size,\n",
    "                                    embed_size=embed_size,\n",
    "                                    num_layers=encoder_layers,\n",
    "                                    device=dev,\n",
    "                                    nhead = nheads,\n",
    "                                    mask=None,\n",
    "                                    dropout=dropout,\n",
    "                                    max_length=150)\n",
    "\n",
    "        # decoder\n",
    "        self.decoder = TransDecoder(target_mask=None,\n",
    "                                    embedding=embed_size,\n",
    "                                    dropout=dropout,\n",
    "                                    nhead=nheads,\n",
    "                                    layers=decoder_layers,\n",
    "                                    max_targets=max_targets,\n",
    "                                    max_step_change=max_step,\n",
    "                                    max_seq_len=max_output)\n",
    "\n",
    "    def forward(self, heatmap_sequence, start_pos, target_mask,\n",
    "                input_lengths,  player_positions, player_role):\n",
    "        # derive batch size, length of transformer output\n",
    "        batch_size, seq_len = heatmap_sequence.shape[:2]\n",
    "\n",
    "        # cnn features\n",
    "        cnn_features = []\n",
    "        for t in range(seq_len):\n",
    "            frame = heatmap_sequence[:,t]\n",
    "            features = self.context_cnn(frame)\n",
    "            features = features.flatten(1)\n",
    "            cnn_features.append(features)\n",
    "\n",
    "        # stack and encode\n",
    "        sequence_feat = torch.stack(cnn_features, dim=1)\n",
    "\n",
    "        # encoder mask based on input seq\n",
    "        encoder_mask = torch.zeros(batch_size, seq_len, device=heatmap_sequence.device, dtype=torch.bool)\n",
    "        for i, length in enumerate(input_lengths):\n",
    "            encoder_mask[i, :length] = True\n",
    "\n",
    "        # context\n",
    "        encoded_context = self.encoder(sequence_feat, mask=encoder_mask)\n",
    "\n",
    "        # catch na context\n",
    "        if torch.isnan(encoded_context).any() or torch.isinf(encoded_context).any():\n",
    "            print(encoded_context)\n",
    "            raise ValueError()\n",
    "\n",
    "        # encoder padding mask\n",
    "        encoder_padding_mask = ~encoder_mask\n",
    "\n",
    "        # output predictions\n",
    "        predictions = self.decoder(encoded_context, start_pos, target_mask, player_positions, player_role, encoder_padding_mask)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e3cac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_mean_scalars(df_tracking):\n",
    "    # standard scale postion on field\n",
    "    pos_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    pos_scaler.fit(df_tracking[['x', 'y']].values)\n",
    "\n",
    "    # sort to ensure time, then take the mean change in diff between play\n",
    "    df_sorted = df_tracking.sort_values(['play_id_n', 'nfl_id', 'frame_id'])\n",
    "    deltas = df_sorted.groupby(['play_id_n', 'nfl_id'])[['x', 'y']].diff()\n",
    "\n",
    "    # rename, dop nams\n",
    "    deltas.columns = ['delta_x', 'delta_y']\n",
    "    deltas_clean = deltas.dropna()\n",
    "\n",
    "    # scaler for change values, fit to the delta\n",
    "    delta_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    delta_scaler.fit(deltas_clean[['delta_x', 'delta_y']].values)\n",
    "\n",
    "    return pos_scaler, delta_scaler\n",
    "\n",
    "pos, delta = var_mean_scalars(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cd28d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalto\\anaconda3\\envs\\nflLab\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = SeqPrediction(embed_size=64, encoder_layers=7, decoder_layers=2,\n",
    "                   max_targets=max_targets, max_step=1.4, dropout=0.2, nheads=2 , dev='cuda').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23a4424b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"C:/Users/dalto/OneDrive/Pictures/Documents/Emory/NFL Lab/model_weights/11_24_2.8_64_7_2.pth\")\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a7efb8",
   "metadata": {},
   "source": [
    "##### Pixel Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12d0af2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_kernel(sigma=0.8, kernel_size=11):\n",
    "    ax = np.linspace(-(kernel_size - 1) / 2., (kernel_size - 1) / 2., kernel_size)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    kernel = np.exp(-0.5 * (np.square(xx) + np.square(yy)) / np.square(sigma))\n",
    "    return kernel / np.max(kernel) \n",
    "\n",
    "# gaussian kernal\n",
    "GAUSSIAN_KERNEL = create_gaussian_kernel(sigma=0.8, kernel_size=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8021c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_map_vectorized(player_data, target_player_ids, max_targets, grid_width=121, grid_height=55):\n",
    "    # output map\n",
    "    num_channels = 2 + max_targets + 1\n",
    "    output_map = np.zeros((num_channels, grid_height, grid_width), dtype=np.float32)\n",
    "    \n",
    "    # paste kernal based on point\n",
    "    def add_points_to_channel(channel_idx, x_coords, y_coords):\n",
    "        kernel_r = GAUSSIAN_KERNEL.shape[0] // 2\n",
    "        \n",
    "        # cords to nearest int\n",
    "        x_ints = np.round(x_coords).astype(int)\n",
    "        y_ints = np.round(y_coords).astype(int)\n",
    "        \n",
    "        for x, y in zip(x_ints, y_ints):\n",
    "            # edges \n",
    "            x_start = max(0, x - kernel_r)\n",
    "            x_end = min(grid_width, x + kernel_r + 1)\n",
    "            y_start = max(0, y - kernel_r)\n",
    "            y_end = min(grid_height, y + kernel_r + 1)\n",
    "            \n",
    "            # kernal bounds\n",
    "            k_x_start = kernel_r - (x - x_start)\n",
    "            k_x_end = k_x_start + (x_end - x_start)\n",
    "            k_y_start = kernel_r - (y - y_start)\n",
    "            k_y_end = k_y_start + (y_end - y_start)\n",
    "            # kernal \n",
    "            output_map[channel_idx, y_start:y_end, x_start:x_end] += GAUSSIAN_KERNEL[k_y_start:k_y_end, k_x_start:k_x_end]\n",
    "\n",
    "    # offense channel\n",
    "    offense_data = player_data[player_data['player_side'] == 'Offense']\n",
    "    if not offense_data.empty:\n",
    "        add_points_to_channel(0, offense_data['x'].values, offense_data['y'].values)\n",
    "\n",
    "    # defense channel\n",
    "    defense_data = player_data[player_data['player_side'] == 'Defense']\n",
    "    if not defense_data.empty:\n",
    "        add_points_to_channel(1, defense_data['x'].values, defense_data['y'].values)\n",
    "\n",
    "    # target channel\n",
    "    player_locs = dict(zip(player_data['nfl_id'], zip(player_data['x'], player_data['y'])))\n",
    "    \n",
    "    for i, target_id in enumerate(target_player_ids[:max_targets]):\n",
    "        if target_id in player_locs:\n",
    "            x, y = player_locs[target_id]\n",
    "            add_points_to_channel(2 + i, [x], [y])\n",
    "\n",
    "    # ball channel\n",
    "    b_x = player_data['ball_land_x'].iloc[0]\n",
    "    b_y = player_data['ball_land_y'].iloc[0]\n",
    "    add_points_to_channel(-1, [b_x], [b_y])\n",
    "\n",
    "    return output_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969cf029",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "976a8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(test_input: pd.DataFrame):\n",
    "    MAX_TARGETS = 9\n",
    "    # dicts\n",
    "    pos_dict = {1: ['WR'], 2: ['TE'], 3: ['QB'], 4: ['FB'], 13: ['RB'],\n",
    "                5: ['SS'], 6: ['CB'], 7: ['FS'], 8: ['S'], 9: ['ILB'], \n",
    "                10: ['LB'], 11: ['MLB'], 12: ['DE'], 14: ['NT'],\n",
    "                15: ['OLB'], 16: ['DT'], 17: ['T'], 18: ['K'], 19:['P']}\n",
    "    \n",
    "    role_dict = {0: ['Passer'], 1:['Targeted Receiver'], 2:['Defensive Coverage'], 3:['Other Route Runner']}\n",
    "    \n",
    "    # batch info\n",
    "    batch_grids = []\n",
    "    batch_start_pos_list = []\n",
    "    batch_player_pos_list = []\n",
    "    batch_player_role_list = []\n",
    "    batch_target_mask_list = []\n",
    "    batch_input_lengths = []\n",
    "\n",
    "    # info for df reconstruction\n",
    "    meta_target_ids = []\n",
    "    meta_output_lens = []\n",
    "    for (play_id, game_id), play_df in test_input.groupby(['play_id', 'game_id']):\n",
    "        # sort frames\n",
    "        play_df = play_df.sort_values('frame_id')\n",
    "        frame_ids = play_df['frame_id'].unique()\n",
    "\n",
    "        # targets to predict\n",
    "        target_ids = play_df[play_df['player_to_predict'] == True]['nfl_id'].unique().tolist()\n",
    "        current_targets = target_ids[:MAX_TARGETS]\n",
    "        meta_target_ids.append(current_targets)\n",
    "\n",
    "        # output lens\n",
    "        t_lens = []\n",
    "        for tid in current_targets:\n",
    "            p_data = play_df[play_df['nfl_id'] == tid]\n",
    "            t_lens.append(int(p_data['num_frames_output'].iloc[0]))\n",
    "        meta_output_lens.append(t_lens)\n",
    "\n",
    "        # input grids\n",
    "        grids = []\n",
    "        for fid in frame_ids:\n",
    "            frame_data = play_df[play_df['frame_id'] == fid]\n",
    "            grid = pixel_map_vectorized(frame_data, target_ids, max_targets=MAX_TARGETS)\n",
    "            grids.append(torch.from_numpy(grid).float())\n",
    "\n",
    "        # play sequence \n",
    "        play_sequence = torch.stack(grids)\n",
    "        batch_grids.append(play_sequence)\n",
    "        batch_input_lengths.append(len(frame_ids))\n",
    "\n",
    "        # last frame \n",
    "        last_frame = play_df[play_df['frame_id'] == frame_ids[-1]]\n",
    "\n",
    "        # start pos, positon, role\n",
    "        p_start_pos = torch.zeros(MAX_TARGETS, 2)\n",
    "        p_pos_ids = torch.zeros(MAX_TARGETS, dtype=torch.long)\n",
    "        p_role_ids = torch.zeros(MAX_TARGETS, dtype=torch.long)\n",
    "        p_mask = torch.zeros(MAX_TARGETS, dtype=torch.bool)\n",
    "        \n",
    "        # mask, postion, role\n",
    "        for i, tid in enumerate(current_targets):\n",
    "            p_data = last_frame[last_frame['nfl_id'] == tid]\n",
    "            if not p_data.empty:\n",
    "                # Start Pos\n",
    "                x, y = p_data['x'].iloc[0], p_data['y'].iloc[0]\n",
    "                scaled_xy = pos.transform([[x, y]])[0]\n",
    "                p_start_pos[i] = torch.tensor(scaled_xy)\n",
    "                \n",
    "                # Position ID\n",
    "                p_pos_str = p_data['player_position'].iloc[0]\n",
    "                pid = 0\n",
    "                for k, v in pos_dict.items():\n",
    "                    if p_pos_str in v:\n",
    "                        pid = k\n",
    "                        break\n",
    "                p_pos_ids[i] = pid\n",
    "\n",
    "                 # Role ID\n",
    "                p_role_str = p_data['player_role'].iloc[0]\n",
    "                rid = 0\n",
    "                for k, v in role_dict.items():\n",
    "                    if p_role_str in v:\n",
    "                        rid = k\n",
    "                        break\n",
    "                p_role_ids[i] = rid\n",
    "                \n",
    "                # Mask\n",
    "                p_mask[i] = True\n",
    "        \n",
    "        batch_start_pos_list.append(p_start_pos)\n",
    "        batch_player_pos_list.append(p_pos_ids)\n",
    "        batch_player_role_list.append(p_role_ids)\n",
    "        batch_target_mask_list.append(p_mask)\n",
    "    \n",
    "    batch_sequence = pad_sequence(batch_grids, batch_first=True).to('cuda')\n",
    "    # stack all \n",
    "    batch_start_pos = torch.stack(batch_start_pos_list).to('cuda') # (B, 9, 2)\n",
    "    player_pos_tensor = torch.stack(batch_player_pos_list).to('cuda') # (B, 9)\n",
    "    player_role_tensor = torch.stack(batch_player_role_list).to('cuda') # (B, 9)\n",
    "    target_mask = torch.stack(batch_target_mask_list).to('cuda') # (B, 9)\n",
    "\n",
    "    # model predecions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(batch_sequence, batch_start_pos, target_mask, \n",
    "                          batch_input_lengths, player_pos_tensor, player_role_tensor)    \n",
    "    \n",
    "    # preds shape\n",
    "    pred_deltas_xy = predictions[:, :, :, :2]\n",
    "    B, S, T, _ = pred_deltas_xy.shape\n",
    "    \n",
    "    # reshape for inverse transform\n",
    "    pred_deltas_flat = pred_deltas_xy.reshape(-1, 2).cpu().numpy()\n",
    "    start_pos_flat = batch_start_pos.reshape(-1, 2).cpu().numpy()\n",
    "    \n",
    "    pred_deltas_unscaled_flat = delta.inverse_transform(pred_deltas_flat)\n",
    "    start_pos_unscaled_flat = pos.inverse_transform(start_pos_flat)\n",
    "\n",
    "    # reshape back for gpu \n",
    "    pred_deltas_unscaled = torch.tensor(pred_deltas_unscaled_flat).view(B, S, T, 2)\n",
    "    start_pos_unscaled = torch.tensor(start_pos_unscaled_flat).view(B, S, 2)\n",
    "\n",
    "    # calculate trajectory\n",
    "    pred_traj = torch.cumsum(pred_deltas_unscaled, dim=2) + start_pos_unscaled.unsqueeze(2)\n",
    "    \n",
    "    # to cpu\n",
    "    pred_traj_np = pred_traj.cpu().numpy()\n",
    "\n",
    "    # construct df\n",
    "    final_trajs = []\n",
    "    final_ids = []\n",
    "    final_steps = []\n",
    "    \n",
    "    for b in range(B):\n",
    "        targets = meta_target_ids[b]\n",
    "        lens = meta_output_lens[b]\n",
    "        play_traj = pred_traj_np[b] \n",
    "        \n",
    "        for i, tid in enumerate(targets):\n",
    "            seq_len = lens[i]\n",
    "            # cut sequnece below max\n",
    "            seq_len = min(seq_len, play_traj.shape[1])\n",
    "            \n",
    "            traj = play_traj[i, :seq_len, :]\n",
    "\n",
    "            final_trajs.append(traj)\n",
    "            final_ids.extend([tid] * seq_len)\n",
    "            final_steps.extend(np.arange(1, seq_len + 1))\n",
    "    \n",
    "    # concate\n",
    "    flat_traj = np.concatenate(final_trajs, axis=0)\n",
    "\n",
    "    # add info cols\n",
    "    df_pred = pd.DataFrame(flat_traj, columns=['x', 'y'])\n",
    "    df_pred['nfl_id'] = final_ids\n",
    "    df_pred['step'] = final_steps\n",
    "\n",
    "    return df_pred\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nflLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
