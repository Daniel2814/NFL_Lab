{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d4ef573e",
      "metadata": {},
      "source": [
        "##### Load Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9b4M7YS2sh4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9b4M7YS2sh4",
        "outputId": "372a8a87-704c-495d-a741-5222a83f0e34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "882c941d",
      "metadata": {
        "collapsed": true,
        "id": "882c941d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/databowl/')\n",
        "df = pd.read_csv('2023_tracking.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5960ee90",
      "metadata": {
        "id": "5960ee90"
      },
      "outputs": [],
      "source": [
        "play_ids = df['play_id_n'].unique()[2000:4500]\n",
        "df = df[df['play_id_n'].isin(play_ids)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40823073",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40823073",
        "outputId": "ee5d820b-a4ae-4af7-bed0-75b14a3f3e0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "max_targets = df.groupby(['play_id_n', 'frame_id'])['player_to_predict'].sum().max()\n",
        "print(max_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb3b0c43",
      "metadata": {
        "id": "eb3b0c43"
      },
      "source": [
        "##### Tabular to Pixel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7bdcf7e",
      "metadata": {
        "id": "c7bdcf7e"
      },
      "outputs": [],
      "source": [
        "def pixel_map(player_data, target_player_ids, max_targets, grid_width=121, grid_height=55, sigma=.8):\n",
        "\n",
        "    num_channels = 2 + max_targets + 1\n",
        "    # three channels, one for offense, one for defense, one for ball location, one for player to predict\n",
        "    pixel_map = np.zeros((num_channels, grid_height, grid_width), dtype=np.float32)\n",
        "\n",
        "    x_vals = player_data['x'].values\n",
        "    y_vals = player_data['y'].values\n",
        "\n",
        "    for i, (x, y) in enumerate(zip(x_vals, y_vals)):\n",
        "        x_min = max(0, int(np.floor(x - 2*sigma)))\n",
        "        x_max = min(grid_width, int(np.ceil(x + 2*sigma)) + 1)\n",
        "        y_min = max(0, int(np.floor(y - 2*sigma)))\n",
        "        y_max = min(grid_height, int(np.ceil(y + 2*sigma)) + 1)\n",
        "\n",
        "        for xi in range(x_min, x_max):\n",
        "            for yi in range(y_min, y_max):\n",
        "                dist_sq = (xi - x)**2 + (yi - y)**2\n",
        "                weight = np.exp(-dist_sq / (2 * sigma**2))\n",
        "\n",
        "                player_id = player_data.iloc[i].get('nfl_id', None)\n",
        "\n",
        "                if player_id in target_player_ids:\n",
        "                    target_idx = target_player_ids.index(player_id)\n",
        "                    if target_idx < max_targets: # to prevent error\n",
        "                        pixel_map[2 + target_idx, yi, xi] += weight\n",
        "                elif player_data.iloc[i]['player_side'] == 'Offense':\n",
        "                    pixel_map[0, yi, xi] += weight\n",
        "                elif player_data.iloc[i]['player_side'] == 'Defense':\n",
        "                    pixel_map[1, yi, xi] += weight\n",
        "\n",
        "\n",
        "    ball_x = player_data['ball_land_x'].iloc[0]\n",
        "    ball_y = player_data['ball_land_y'].iloc[0]\n",
        "\n",
        "    ball_x_min = max(0, int(np.floor(ball_x - 2*sigma)))\n",
        "    ball_x_max = min(grid_width, int(np.ceil(ball_x + 2*sigma)) + 1)\n",
        "    ball_y_min = max(0, int(np.floor(ball_y - 2*sigma)))\n",
        "    ball_y_max = min(grid_height, int(np.ceil(ball_y + 2*sigma)) + 1)\n",
        "\n",
        "    for xi in range(ball_x_min, ball_x_max):\n",
        "        for yi in range(ball_y_min, ball_y_max):\n",
        "            dist_sq = (xi - ball_x)**2 + (yi - ball_y)**2\n",
        "            weight = np.exp(-dist_sq / (2 * sigma**2))\n",
        "            pixel_map[2 + max_targets, yi, xi] += weight\n",
        "\n",
        "    return pixel_map"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fdb8c7f",
      "metadata": {
        "id": "5fdb8c7f"
      },
      "source": [
        "testing one play"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a45368c4",
      "metadata": {
        "id": "a45368c4",
        "outputId": "666b0591-43c3-4c9a-dbb5-635116ef356c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dalto\\AppData\\Local\\Temp\\ipykernel_25552\\2474093878.py:3: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_grids_t = df_play_id.groupby(['play_id_n','frame_id']).apply(\n"
          ]
        }
      ],
      "source": [
        "df_play_id = df[df['play_id_n'] == 456]\n",
        "target_player_ids = df_play_id[df_play_id['player_to_predict'] == True]['nfl_id'].unique().tolist()\n",
        "df_grids_t = df_play_id.groupby(['play_id_n','frame_id']).apply(\n",
        "    lambda x: pd.Series({'grid': pixel_map(x, target_player_ids, max_targets)})\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84373868",
      "metadata": {
        "id": "84373868"
      },
      "source": [
        "grid for all plays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fbb8477",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fbb8477",
        "outputId": "ba7bfdee-fb54-40de-c9cd-6a5a32a8980e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3746108319.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_grids = df.groupby(['play_id_n','frame_id']).apply(\n"
          ]
        }
      ],
      "source": [
        "df_grids = df.groupby(['play_id_n','frame_id']).apply(\n",
        "    lambda x: pd.Series({'grid': pixel_map(x,  x[x['player_to_predict'] == True]['nfl_id'].unique().tolist(), max_targets)})\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9189e025",
      "metadata": {
        "id": "9189e025"
      },
      "outputs": [],
      "source": [
        "df_grids = df_grids.reset_index()\n",
        "df_grids = df_grids.sort_values(['play_id_n', 'frame_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fe42dca",
      "metadata": {
        "id": "8fe42dca"
      },
      "source": [
        "visual test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35e0b800",
      "metadata": {
        "id": "35e0b800"
      },
      "outputs": [],
      "source": [
        "sample_grid = df_grids_t['grid'].iloc[30]\n",
        "\n",
        "# Count how many target player channels have data\n",
        "num_targets = 0\n",
        "for i in range(max_targets):\n",
        "    if sample_grid[2 + i].sum() > 0:\n",
        "        num_targets += 1\n",
        "\n",
        "# Create subplots: 2 base channels + ball + target players\n",
        "total_plots = 3 + num_targets\n",
        "cols = 4\n",
        "rows = (total_plots + cols - 1) // cols\n",
        "\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(14, 5*rows))\n",
        "axes = axes.flatten() if total_plots > 1 else [axes]\n",
        "\n",
        "# Plot offense\n",
        "axes[0].imshow(sample_grid[0], origin='lower', cmap='Reds')\n",
        "axes[0].set_title('Offense Players')\n",
        "axes[0].set_xlabel('X (yards)')\n",
        "axes[0].set_ylabel('Y (yards)')\n",
        "\n",
        "# Plot defense\n",
        "axes[1].imshow(sample_grid[1], origin='lower', cmap='Blues')\n",
        "axes[1].set_title('Defense Players')\n",
        "axes[1].set_xlabel('X (yards)')\n",
        "axes[1].set_ylabel('Y (yards)')\n",
        "\n",
        "# Plot ball location (at index 2 + max_targets)\n",
        "axes[2].imshow(sample_grid[2 + max_targets], origin='lower', cmap='Purples')\n",
        "axes[2].set_title('Ball Landing Location')\n",
        "axes[2].set_xlabel('X (yards)')\n",
        "axes[2].set_ylabel('Y (yards)')\n",
        "\n",
        "# Plot each target player (channels 2 through 2+max_targets-1)\n",
        "plot_idx = 3\n",
        "for i in range(max_targets):\n",
        "    if sample_grid[2 + i].sum() > 0:\n",
        "        axes[plot_idx].imshow(sample_grid[2 + i], origin='lower', cmap='Greens')\n",
        "        axes[plot_idx].set_title(f'Target Player {i+1}')\n",
        "        axes[plot_idx].set_xlabel('X (yards)')\n",
        "        axes[plot_idx].set_ylabel('Y (yards)')\n",
        "        plot_idx += 1\n",
        "\n",
        "for idx in range(total_plots, len(axes)):\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3e99f11",
      "metadata": {
        "id": "c3e99f11"
      },
      "outputs": [],
      "source": [
        "df_grids.to_pickle(\"full_grids_2500.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adae6a33",
      "metadata": {
        "id": "adae6a33"
      },
      "source": [
        "### Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b67e7a",
      "metadata": {},
      "source": [
        "##### Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc55cbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1cc55cbb",
        "outputId": "0b686605-d882-46fe-8770-b2862de0e212"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78ef7c8137b0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.functional as F\n",
        "import gc\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "df_grids = pd.read_pickle(\"full_grids_2500.pkl\")\n",
        "torch.manual_seed(26)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c6635c9",
      "metadata": {
        "id": "7c6635c9"
      },
      "source": [
        "##### Inital Params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "663f7b76",
      "metadata": {},
      "outputs": [],
      "source": [
        "max_targets = df.groupby(['play_id_n', 'frame_id'])['player_to_predict'].sum().max()\n",
        "max_input = (df['frame_id'] - df['num_frames_output']).max()\n",
        "max_output = (df['num_frames_output']).max()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a399299f",
      "metadata": {},
      "source": [
        "##### Postional Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c509a20a",
      "metadata": {},
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_size, dropout, max_length=150):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        # droput\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # create matrix\n",
        "        pe = torch.zeros(max_length, embed_size)\n",
        "\n",
        "        # position tensor shape\n",
        "        position = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # div_term tensor shape\n",
        "        div_term = torch.exp(torch.arange(0, embed_size, 2).float() * (-torch.log(torch.tensor(10000.0)) / embed_size))\n",
        "\n",
        "        # apply sin to even indices\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        # apply cos to odd indices\n",
        "        if embed_size % 2 == 1:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term[:-1])\n",
        "        else:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # register as buffer so it moves with model to device\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        pe_slice = self.pe[:x.size(1), :].to(x.device)\n",
        "        x = x + pe_slice\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd980b7c",
      "metadata": {},
      "source": [
        "##### Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8d6455d",
      "metadata": {
        "id": "e8d6455d"
      },
      "outputs": [],
      "source": [
        "class CNN_DownSample(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # variable based on amount of targets\n",
        "        input_chan = 2 + max_targets + 1\n",
        "\n",
        "        # using stride rather than max pooling preforms better as max pooling tends to compress feat. too much.\n",
        "        self.heatmap_encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_chan, out_channels=16, kernel_size=3, stride = 2, padding=1),\n",
        "            nn.BatchNorm2d(16), # normalize var and mean\n",
        "            nn.GELU(), # preforms better on average idk if itll make a difference in this application\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride = 2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride = 2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.heatmap_encoder(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f884d25",
      "metadata": {
        "id": "6f884d25"
      },
      "source": [
        "attention layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b4da6b9",
      "metadata": {
        "id": "1b4da6b9"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, nhead, mask, dropout=0.15):\n",
        "        super().__init__() # inhert from parent class\n",
        "\n",
        "        if d_model % nhead != 0:\n",
        "            raise ValueError(f\"d_model ({d_model}) must be divisible by nhead ({nhead})\")\n",
        "\n",
        "        self.d_model = d_model # dimension of model\n",
        "        self.nhead = nhead # number of attention heads, multi headed\n",
        "        self.head_dim = d_model // nhead\n",
        "\n",
        "        # create key query and values\n",
        "        self.qkv_proj = nn.Linear(d_model, 3 * d_model)\n",
        "        # learn context as a product of the attention heads\n",
        "        self.out_proj = nn.Linear(d_model, d_model)\n",
        "        # dropout as a form of regularzation\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # scaling function\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        B, L, _ = x.shape # batch and length\n",
        "\n",
        "        # create q, k, v values | init just random matrix mults, learned parameter\n",
        "        qkv = self.qkv_proj(x)\n",
        "\n",
        "        # split key, query, and value vectors into diff pares\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "\n",
        "        # transpose the matrix so that batch and nhead are treated as batches and self attention is calculated from there\n",
        "        q = q.view(B, L, self.nhead, self.head_dim).transpose(1, 2)\n",
        "        k = k.view(B, L, self.nhead, self.head_dim).transpose(1, 2)\n",
        "        v = v.view(B, L, self.nhead, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # scaled dot product, scale so values arent 0 or 1\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale # matrix mult\n",
        "\n",
        "        # set masked values to -inf so softmax does not \"give\" attention to them\n",
        "        if mask is not None:\n",
        "          if mask.dim() == 2:\n",
        "            mask = mask.expand(B, self.nhead, L, L)\n",
        "          elif mask.dim() == 3:\n",
        "            mask = mask.unsqueeze(1)\n",
        "            mask = mask.expand(B, self.nhead, L, L)\n",
        "          elif mask.dim() == 4:\n",
        "            mask = mask.expand(B, self.nhead, L, L)\n",
        "\n",
        "          scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "\n",
        "        # softmax to give attention weights to each token\n",
        "        attn_weights = torch.softmax(scores, dim=-1)\n",
        "\n",
        "        # drop some weights\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # context vector for a given input sequence\n",
        "        context = torch.matmul(attn_weights, v)\n",
        "\n",
        "        # transpose so the matrix is in the correct size to be concatinated\n",
        "        context = context.transpose(1, 2).contiguous().view(B, L, self.d_model)\n",
        "\n",
        "        # \"combine\" the outputs from the head to one general vector\n",
        "        output = self.out_proj(context)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee94df07",
      "metadata": {
        "id": "ee94df07"
      },
      "source": [
        "transformer block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445638fb",
      "metadata": {
        "id": "445638fb"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, nhead=4, mask=None, dropout=0.15):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        # self attention class definied above\n",
        "        self.self_attn = MultiHeadAttention(d_model=d_model, nhead=nhead, dropout=dropout, mask=mask)\n",
        "\n",
        "        # feed forward network for each token\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(64, 128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout), # to combat overfitting\n",
        "            nn.Linear(128, 64)\n",
        "        )\n",
        "\n",
        "        # normilzations so values are between 0-1, learned gamma and beta parameters\n",
        "        # to shift center and var for values.\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # standard dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        residual = x\n",
        "        # normalized pre attention layer, gradients flow black directly without the normalizing effecting x values\n",
        "        norm_x = self.norm1(x)\n",
        "        # self attention\n",
        "        attn_output = self.self_attn(norm_x, mask)\n",
        "        # adding residual back to self attention\n",
        "        x = residual + self.dropout(attn_output)\n",
        "\n",
        "        residual = x\n",
        "        # normalize values\n",
        "        # we do so because over the amount of layers scale can get distorted, lead to super big or small values\n",
        "        norm_x = self.norm2(x)\n",
        "        # basic fcn\n",
        "        ff_output = self.feed_forward(norm_x)\n",
        "        # adding residual back so that the gradient can flow directly back.\n",
        "        # adds a 1 + terms to gradients, helps solve the vanishing gradients problem\n",
        "        x = residual + self.dropout(ff_output)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f52a344",
      "metadata": {},
      "source": [
        "Encoder Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb6e6e4c",
      "metadata": {
        "id": "fb6e6e4c"
      },
      "outputs": [],
      "source": [
        "class TransEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, embed_size, num_layers, device, dropout, mask, max_length):\n",
        "        super(TransEncoder, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.device = device\n",
        "        # learned matrix projection\n",
        "        self.input_projection = nn.Linear(input_dim, embed_size)\n",
        "        # postional encoding\n",
        "        self.position_encoding = PositionalEncoding(embed_size, dropout, max_length)\n",
        "        # layers of model, just stacked encoding layer\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                TransformerBlock(\n",
        "                    embed_size,\n",
        "                    mask=mask,\n",
        "                    nhead=4, # number of attention heads\n",
        "                    dropout=dropout\n",
        "                )\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "        # normalize after attention\n",
        "        self.norm = nn.LayerNorm(embed_size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # input layer matrix mult\n",
        "        projected_input = self.input_projection(x)\n",
        "        # position encodings\n",
        "        out = self.position_encoding(projected_input)\n",
        "        # mask to correct dim\n",
        "        mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "        # pass through transformer block\n",
        "        for layer in self.layers:\n",
        "            out = layer(out, mask)\n",
        "        # normalize gradients\n",
        "        out = self.norm(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61374dbf",
      "metadata": {},
      "source": [
        "##### Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb3bc89",
      "metadata": {},
      "outputs": [],
      "source": [
        "# prevent lookahead\n",
        "def create_causal_mask(seq_len, device):\n",
        "    mask = torch.tril(torch.ones(seq_len, seq_len, device=device))\n",
        "    return mask.bool()\n",
        "\n",
        "# seq mask to deal with padded values\n",
        "def seq_maks(input_lengths, max_input, device):\n",
        "    batch_size = len(input_lengths)\n",
        "    input_mask = torch.zeros(batch_size, max_input, device=device, dtype=torch.bool)\n",
        "    for i, length in enumerate(input_lengths):\n",
        "        input_mask[i, :length] = True\n",
        "\n",
        "# loss with mask\n",
        "def mse_with_length_mask(predictions, targets, combined_mask):\n",
        "    mse = (predictions - targets) ** 2\n",
        "    masked_mse = mse * combined_mask.float()\n",
        "\n",
        "    valid_elements = combined_mask.sum()\n",
        "\n",
        "    if valid_elements > 0:\n",
        "        return masked_mse.sum() / valid_elements\n",
        "    else:\n",
        "        return torch.tensor(0.0, device=predictions.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2d1449e",
      "metadata": {
        "id": "b2d1449e"
      },
      "source": [
        "##### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5fada4f",
      "metadata": {
        "id": "e5fada4f"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, dropout, embedding, nhead):\n",
        "        super().__init__()\n",
        "        # attention layers\n",
        "        self.attention_self = MultiHeadAttention(d_model=embedding, nhead=4, mask=None, dropout=dropout)\n",
        "\n",
        "        # cross atten, query values, info\n",
        "        self.cross_q_proj = nn.Linear(embedding, embedding)\n",
        "        self.cross_k_proj = nn.Linear(embedding, embedding)\n",
        "        self.cross_v_proj =  nn.Linear(embedding, embedding)\n",
        "        self.cross_out_proj = nn.Linear(embedding, embedding)\n",
        "\n",
        "        self.nhead = nhead\n",
        "        self.head_dim = embedding // nhead\n",
        "        self.scale = self.head_dim ** -0.5 # 1/sqrt(dk)\n",
        "\n",
        "        # layer normal\n",
        "        self.norm1 = nn.LayerNorm(embedding)\n",
        "        self.norm2 = nn.LayerNorm(embedding)\n",
        "        self.norm3 = nn.LayerNorm(embedding)\n",
        "\n",
        "        # droput\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # fcnn\n",
        "        self.fcnn = nn.Sequential(\n",
        "            nn.Linear(embedding, embedding*2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.15),\n",
        "            nn.Linear(embedding*2, embedding)\n",
        "        )\n",
        "    # decoder forward pass\n",
        "    def forward(self, decoder_input, encoded_context, target_mask = None, casual_mask=None):\n",
        "\n",
        "        # self attention amoung decoder\n",
        "        residual = decoder_input\n",
        "        norm_x = self.norm1(decoder_input)\n",
        "        self_attn = self.attention_self(norm_x, casual_mask)\n",
        "        decoder_input = residual + self.dropout(self_attn)\n",
        "\n",
        "        # cross attention to encoder\n",
        "        norm_x = self.norm2(decoder_input)\n",
        "        cross_atn = self.encoder_cross_attention(norm_x, encoded_context)\n",
        "        # dropout, also cant do inplace ops bc of backprop\n",
        "        decoder_input = decoder_input + self.dropout(cross_atn)\n",
        "\n",
        "        # fcnn predictions\n",
        "        norm_x = self.norm3(decoder_input)\n",
        "        ffcn = self.fcnn(norm_x)\n",
        "        out = decoder_input + self.dropout(ffcn)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def encoder_cross_attention(self, query, key_value):\n",
        "        B, L_q, _ = query.shape # decoder input\n",
        "        B, L_kv, _ = key_value.shape # encoder output\n",
        "\n",
        "        q = self.cross_q_proj(query)\n",
        "        k = self.cross_k_proj(key_value)\n",
        "        v = self.cross_v_proj(key_value)\n",
        "\n",
        "        q = q.view(B, L_q, self.nhead, self.head_dim).transpose(1, 2)\n",
        "        k = k.view(B, L_kv, self.nhead, self.head_dim).transpose(1, 2)\n",
        "        v = v.view(B, L_kv, self.nhead, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
        "\n",
        "        attn_weights = torch.softmax(scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context = torch.matmul(attn_weights, v)\n",
        "        context = context.transpose(1, 2).contiguous().view(B, L_q, -1)\n",
        "\n",
        "        output = self.cross_out_proj(context)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c99a1811",
      "metadata": {},
      "source": [
        "Decoder block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fca8aa6",
      "metadata": {
        "id": "2fca8aa6"
      },
      "outputs": [],
      "source": [
        "class TransDecoder(nn.Module):\n",
        "    def __init__(self, target_mask, embedding, dropout, nhead, layers, max_targets, max_step_change, max_seq_len):\n",
        "        super(TransDecoder, self).__init__()\n",
        "        self.max_targets = max_targets\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.embedding = embedding\n",
        "        self.max_step = max_step_change\n",
        "\n",
        "        self.max_velocity = max_step_change if max_step_change else 1.35\n",
        "        self.smoothing_factor = 0.8\n",
        "\n",
        "        # project 2d cords to embedding space\n",
        "        self.positon_projection = nn.Linear(2, embedding)\n",
        "\n",
        "        # project outputs back to 2d space\n",
        "        self.output_projection = nn.Linear(embedding, 2)\n",
        "\n",
        "        # postional embeddings\n",
        "        self.pos_embed = PositionalEncoding(embed_size=embedding, dropout=0.15, max_length=150)\n",
        "\n",
        "        # decoder layers\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(embedding=embedding, dropout=dropout, nhead=nhead)\n",
        "            for _ in range(layers)\n",
        "        ])\n",
        "\n",
        "        # normalization\n",
        "        self.norm = nn.LayerNorm(embedding)\n",
        "\n",
        "    def smooth_velo(self, new_pos, current_pos, previous_pos=None):\n",
        "        if previous_pos is None:\n",
        "            delta = new_pos - current_pos\n",
        "            velo = torch.norm(delta, p=2, dim=-1, keepdim=True)\n",
        "\n",
        "            scale = torch.sigmoid(self.max_velocity - velo) * 0.5\n",
        "            smoothed_delta = delta * scale\n",
        "            return current_pos + smoothed_delta\n",
        "        else:\n",
        "            previous_velocity = current_pos - previous_pos\n",
        "            predicted_delta = new_pos - current_pos\n",
        "\n",
        "            velocity_change = predicted_delta - previous_velocity\n",
        "            velocity_change_mag = torch.norm(velocity_change, p=2, dim=-1, keepdim=True)\n",
        "\n",
        "            smooth_scale = torch.exp(-velocity_change_mag / self.max_velocity)\n",
        "            smoothed_velocity = previous_velocity * self.smoothing_factor + predicted_delta * (1 - self.smoothing_factor)\n",
        "\n",
        "            velocity_mag = torch.norm(smoothed_velocity, p=2, dim=-1, keepdim=True)\n",
        "            final_scale = torch.min(torch.ones_like(velocity_mag), self.max_velocity / (velocity_mag + 1e-8))\n",
        "\n",
        "            return current_pos + smoothed_velocity * final_scale\n",
        "\n",
        "    def forward(self, encoded_context, start_positons, target_mask, max_step_change, output_lengths):\n",
        "        # batch, max_seq, device\n",
        "        batch_size = encoded_context.shape[0]\n",
        "        device = encoded_context.device\n",
        "        max_seq_len = self.max_seq_len\n",
        "\n",
        "        # output tensor\n",
        "        all_outputs = torch.zeros(batch_size, self.max_targets, max_seq_len, 2, device=device)\n",
        "\n",
        "        # autoregressive \n",
        "        decoder_sequence = [[] for _ in range(batch_size)]\n",
        "        current_postions = start_positons.clone()\n",
        "        previous_pos = None\n",
        "\n",
        "        # output sequence\n",
        "        for step in range(max_seq_len):\n",
        "            # project pos to embedding space\n",
        "            pos_embeds = self.positon_projection(current_postions)\n",
        "\n",
        "            # add positional context\n",
        "            pos_encoding = self.pos_embed.pe[step, :self.embedding].unsqueeze(0).unsqueeze(0)\n",
        "            # Replace inplace addition with out-of-place addition\n",
        "            pos_input = pos_embeds + pos_encoding\n",
        "            # add sequence dim back\n",
        "            pos_input = pos_input.unsqueeze(2)\n",
        "\n",
        "            # decoder seq\n",
        "            for batch_idx in range(batch_size):\n",
        "                decoder_sequence[batch_idx].append(pos_input[batch_idx])\n",
        "\n",
        "            if step == 0:\n",
        "                # if first step use init pos\n",
        "                decoder_input = pos_input\n",
        "                casual_mask = None\n",
        "            else:\n",
        "                # decoder inputs\n",
        "                batch_decoder_inputs = []\n",
        "\n",
        "                # get decoder seq for values\n",
        "                for batch_idx in range(batch_size):\n",
        "                    sample_sequence = torch.cat(decoder_sequence[batch_idx], dim = 1)\n",
        "                    batch_decoder_inputs.append(sample_sequence)\n",
        "                else: \n",
        "                    dummy_input = torch.zeros(self.max_targets, step+1, self.embedding, device=device)\n",
        "                    batch_decoder_inputs.append(dummy_input)\n",
        "\n",
        "                # all samples for decoder input\n",
        "                decoder_input = torch.stack(batch_decoder_inputs)\n",
        "\n",
        "                # casual mask\n",
        "                seq_len = step + 1\n",
        "                casual_mask = create_causal_mask(seq_len, device)\n",
        "\n",
        "\n",
        "            # transformer layers\n",
        "            batch_size_curr, max_targets_curr, seq_len_curr, embed_dim_curr = decoder_input.shape\n",
        "            decoder_input_reshaped = decoder_input.view(batch_size_curr * max_targets_curr, seq_len_curr, embed_dim_curr)\n",
        "\n",
        "            # decoder layer\n",
        "            decoded = decoder_input_reshaped\n",
        "\n",
        "            # masking for future seq\n",
        "            if casual_mask is not None:\n",
        "               casual_mask_expanded = casual_mask.unsqueeze(0).expand(batch_size_curr * max_targets_curr, seq_len_curr, seq_len_curr)\n",
        "            else:\n",
        "               casual_mask_expanded = None\n",
        "\n",
        "            # pass through decoder layers\n",
        "            expanded_context = encoded_context.unsqueeze(1).repeat(1, max_targets_curr, 1, 1)\n",
        "            expanded_context = expanded_context.view(batch_size_curr * max_targets_curr, -1, self.embedding)\n",
        "\n",
        "            for layer in self.layers:\n",
        "                decoded = layer(decoded, expanded_context,target_mask, casual_mask_expanded)\n",
        "\n",
        "            # normalize gradients\n",
        "            decoded = self.norm(decoded)\n",
        "\n",
        "            # reshape and project back to cords\n",
        "            decoded = decoded.view(batch_size_curr, max_targets_curr, seq_len_curr, embed_dim_curr)\n",
        "            predictions = self.output_projection(decoded[:, :, -1, :])\n",
        "\n",
        "            # smooth velocity predictiosn \n",
        "            clamp_pred = self.smooth_velo(predictions, current_postions, previous_pos)\n",
        "\n",
        "            # store every prediction\n",
        "            all_outputs[:, :, step, :] = clamp_pred\n",
        "\n",
        "            # stack all predictions\n",
        "            previous_pos = current_postions.clone()\n",
        "            current_postions = clamp_pred.clone()\n",
        "\n",
        "        return all_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a8d4489",
      "metadata": {},
      "source": [
        "##### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad1faa5f",
      "metadata": {
        "id": "ad1faa5f"
      },
      "outputs": [],
      "source": [
        "class DJMooreSeq(nn.Module):\n",
        "    def __init__(self, embed_size, encoder_layers, decoder_layers,\n",
        "                 max_targets, dropout, nheads, max_step, dev='cuda') -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # general vars\n",
        "        self.embedding_size = embed_size\n",
        "        self.max_targets = max_targets\n",
        "        self.device = dev\n",
        "\n",
        "        # context cnn\n",
        "        self.context_cnn = CNN_DownSample()\n",
        "        context_cnn_output = 64* 7 * 16\n",
        "\n",
        "        # transformer encoder\n",
        "        self.encoder = TransEncoder(input_dim=context_cnn_output,\n",
        "                                    embed_size=embed_size,\n",
        "                                    num_layers=encoder_layers,\n",
        "                                    device=dev,\n",
        "                                    mask=None,\n",
        "                                    dropout=dropout,\n",
        "                                    max_length=150)\n",
        "\n",
        "        # decoder\n",
        "        self.decoder = TransDecoder(target_mask=None,\n",
        "                                    embedding=embed_size,\n",
        "                                    dropout=dropout,\n",
        "                                    nhead=nheads,\n",
        "                                    layers=decoder_layers,\n",
        "                                    max_targets=max_targets,\n",
        "                                    max_step_change=max_step,\n",
        "                                    max_seq_len=max_output)\n",
        "\n",
        "    def forward(self, heatmap_sequence, start_pos, target_mask, future_steps, input_lengths):\n",
        "        # derive batch size, length of transformer output\n",
        "        batch_size, seq_len = heatmap_sequence.shape[:2]\n",
        "        \n",
        "        # cnn features\n",
        "        cnn_features = []\n",
        "        for t in range(seq_len):\n",
        "            frame = heatmap_sequence[:,t]\n",
        "            features = self.context_cnn(frame)\n",
        "            features = features.flatten(1)\n",
        "            cnn_features.append(features)\n",
        "\n",
        "        # stack and encode\n",
        "        sequence_feat = torch.stack(cnn_features, dim=1)\n",
        "\n",
        "        # encoder mask based on input seq\n",
        "        encoder_mask = torch.zeros(batch_size, seq_len, device=heatmap_sequence.device, dtype=torch.bool)\n",
        "        for i, length in enumerate(input_lengths):\n",
        "            encoder_mask[i, :length] = True\n",
        "\n",
        "        # context\n",
        "        encoded_context = self.encoder(sequence_feat, encoder_mask)\n",
        "        # output predictions\n",
        "        predictions = self.decoder(encoded_context, start_pos, target_mask, future_steps, input_lengths)\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "883ff497",
      "metadata": {
        "id": "883ff497"
      },
      "source": [
        "##### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "696a328f",
      "metadata": {
        "id": "696a328f"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, loss_func, optimizer, scheduler, epochs):\n",
        "  # scaler for amp\n",
        "  scaler = torch.GradScaler(device=\"cuda\")\n",
        "\n",
        "  # loss\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  # early stopping\n",
        "  best_loss = np.inf\n",
        "  early_stop_rounds = 0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    # train mode, loss and batches\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    batches = 0\n",
        "\n",
        "    for batch_sequence, batch_targets, batch_masks, batch_start_pos, batch_input_lengths, batch_output_lengths in train_loader:\n",
        "\n",
        "        # move all items to gpu\n",
        "        batch_sequence = batch_sequence.to('cuda')\n",
        "        batch_targets = batch_targets.to('cuda')\n",
        "        batch_masks = batch_masks.to('cuda')\n",
        "        batch_start_pos = batch_start_pos.to('cuda')\n",
        "        batch_input_lengths = batch_input_lengths.to('cuda')\n",
        "        batch_output_lengths = batch_output_lengths.to('cuda')\n",
        "\n",
        "        # zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.autocast(device_type=\"cuda\"):\n",
        "            # forward pass\n",
        "            predictions = model(batch_sequence, batch_start_pos, batch_masks,\n",
        "                                batch_output_lengths, batch_input_lengths)\n",
        "\n",
        "            # train loss\n",
        "            loss = loss_func(predictions, batch_targets, batch_masks, batch_output_lengths)\n",
        "\n",
        "        # backprop\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # epoch loss\n",
        "        epoch_loss += loss.item() * batch_sequence.size(0)\n",
        "        batches += batch_sequence.size(0)\n",
        "\n",
        "    # training losses\n",
        "    avg_loss = epoch_loss / batches\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    # val set losses\n",
        "    model.eval()\n",
        "    val_epoch_loss = 0\n",
        "    val_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_sequence, val_targets, val_masks, val_start_pos, val_input_lengths, val_output_lengths in val_loader:\n",
        "            # to cuda\n",
        "            val_sequence = val_sequence.to('cuda')\n",
        "            val_targets = val_targets.to('cuda')\n",
        "            val_masks = val_masks.to('cuda')\n",
        "            val_start_pos = val_start_pos.to('cuda')\n",
        "            val_input_lengths = val_input_lengths.to('cuda')\n",
        "            val_output_lengths = val_output_lengths.to('cuda')\n",
        "\n",
        "            with torch.autocast(device_type='cuda'):\n",
        "                # predictions and loss on val set\n",
        "                val_predictions = model(val_sequence, val_start_pos, val_masks, val_output_lengths, val_input_lengths)\n",
        "\n",
        "                # validtion losses\n",
        "                val_loss = loss_func(val_predictions, val_targets, val_masks, val_output_lengths)\n",
        "\n",
        "            val_epoch_loss += val_loss.item() * val_sequence.size(0)\n",
        "            val_batches += val_sequence.size(0)\n",
        "\n",
        "    # val set losses\n",
        "    val_epoch_loss = val_epoch_loss / val_batches\n",
        "    val_losses.append(val_epoch_loss)\n",
        "\n",
        "    # learning rate sched.\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f'val_loss {val_epoch_loss}, train_loss {avg_loss}')\n",
        "\n",
        "    # early stopping check\n",
        "    if val_epoch_loss < best_loss:\n",
        "        best_loss = val_epoch_loss\n",
        "        early_stop_rounds = 0\n",
        "        torch.save(model.state_dict(), f\"best_model.pth\")\n",
        "    else:\n",
        "        early_stop_rounds += 1\n",
        "\n",
        "    if early_stop_rounds > 20:\n",
        "        print('early stopping')\n",
        "        return train_losses, val_losses\n",
        "\n",
        "  return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64a43f95",
      "metadata": {},
      "source": [
        "##### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45a24262",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MaskedSequenceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, predictions, targets, target_mask, output_len):\n",
        "        batch_size, max_targets, max_seq_len, coords = predictions.shape\n",
        "\n",
        "        if predictions.shape[2] != targets.shape[2]:\n",
        "            raise ValueError(\"seq len mismatch\")\n",
        "        \n",
        "        # len mask\n",
        "        length_mask = torch.arange(max_seq_len, device=predictions.device)[None, :] < output_len[:, None]\n",
        "\n",
        "        # masking\n",
        "        target_mask_expanded = target_mask.unsqueeze(-1).unsqueeze(-1)\n",
        "        length_mask_expanded = length_mask.unsqueeze(1).unsqueeze(-1)\n",
        "        combined_mask = target_mask_expanded & length_mask_expanded\n",
        "        combined_mask = combined_mask.expand_as(predictions)\n",
        "\n",
        "        # mse\n",
        "        mse = F.mse_loss(predictions, targets, reduction='None')\n",
        "\n",
        "        # zero out invalid pos\n",
        "        masked_mse = mse * combined_mask.float()\n",
        "\n",
        "        # valid ele\n",
        "        valid_elements = combined_mask.sum()\n",
        "\n",
        "        if valid_elements > 0:\n",
        "            return masked_mse.sum() / valid_elements\n",
        "        else:\n",
        "            return torch.tensor(0.0, device=predictions.device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3a8c28",
      "metadata": {},
      "source": [
        "##### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2ffdfec",
      "metadata": {
        "id": "f2ffdfec"
      },
      "outputs": [],
      "source": [
        "# create dataset instance by instance rather than all at once\n",
        "class NFLSequenceDataset(Dataset):\n",
        "    def __init__(self, df_grids, df_tracking, max_targets, max_input, max_output, split_indices=None):\n",
        "        # input vars\n",
        "        self.df_grids = df_grids\n",
        "        self.df_tracking = df_tracking\n",
        "        self.max_targets = max_targets\n",
        "        self.max_input = max_input\n",
        "        self.max_output = max_output\n",
        "\n",
        "        # play_ids\n",
        "        self.play_ids = df_grids['play_id_n'].unique()\n",
        "        if split_indices is not None:\n",
        "            self.play_ids = self.play_ids[split_indices]\n",
        "\n",
        "        # players to predict for each play\n",
        "        self.player_to_predict = df_tracking[df_tracking['player_to_predict'] == True].groupby('play_id_n')['nfl_id'].unique()\n",
        "\n",
        "    def __len__(self):\n",
        "        # how many plays\n",
        "        return len(self.play_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        play_id = self.play_ids[idx]\n",
        "\n",
        "        # data for a given play\n",
        "        play_data = self.df_grids[self.df_grids['play_id_n'] == play_id].sort_values('frame_id')\n",
        "        df_data = self.df_tracking[self.df_tracking['play_id_n'] == play_id]\n",
        "\n",
        "        # seq lengths\n",
        "        total_frames = play_data['frame_id'].max()\n",
        "        output_frames = int(df_data['num_frames_output'].max())\n",
        "        input_seq_len = total_frames - output_frames\n",
        "        output_seq_len = output_frames\n",
        "\n",
        "        # target play ids\n",
        "        if play_id in self.player_to_predict:\n",
        "            players = self.player_to_predict[play_id][:self.max_targets]\n",
        "        else:\n",
        "            players = []\n",
        "\n",
        "        num_receivers = len(players)\n",
        "\n",
        "        # mask for less than max target\n",
        "        target_mask = torch.zeros(self.max_targets, dtype=torch.bool)\n",
        "        target_mask[:num_receivers] = True\n",
        "\n",
        "        # input seq\n",
        "        input_sequence = torch.zeros(self.max_input, *play_data['grid'].iloc[0].shape, dtype=torch.float16)\n",
        "        act_input = min(input_seq_len, self.max_input)\n",
        "\n",
        "        for i in range(act_input):\n",
        "            if i < total_frames:\n",
        "                grid = torch.from_numpy(play_data['grid'].iloc[i]).float()\n",
        "                input_sequence[i] = grid\n",
        "\n",
        "\n",
        "        # start positons\n",
        "        start_pos = torch.zeros(self.max_targets, 2)\n",
        "\n",
        "        # last frame from dataset\n",
        "        last_frame_id = input_seq_len.copy()\n",
        "\n",
        "        last_frame_data = self.df_tracking[\n",
        "            (self.df_tracking['play_id_n'] == play_id) &\n",
        "            (self.df_tracking['frame_id'] == last_frame_id)\n",
        "        ]\n",
        "\n",
        "        # init postions fo start plyer\n",
        "        for i, receiver_id in enumerate(players):\n",
        "            receiver_data = last_frame_data[last_frame_data['nfl_id'] == receiver_id]\n",
        "            if not receiver_data.empty:\n",
        "                x = float(receiver_data['x'].iloc[0]) / 120\n",
        "                y = float(receiver_data['y'].iloc[0]) / 53.3\n",
        "                start_pos[i] = torch.tensor([x, y])\n",
        "\n",
        "\n",
        "        # target seq\n",
        "        target_positions = torch.zeros(self.max_targets, self.max_output, 2)\n",
        "        act_output = min(output_frames, self.max_output)\n",
        "\n",
        "        # target postions\n",
        "        for step in range(act_output):\n",
        "            frame_idx = input_seq_len + step\n",
        "\n",
        "            if frame_idx < len(play_data):\n",
        "                target_frame = play_data.iloc[frame_idx]['frame_id']\n",
        "                target_frame_data = self.df_tracking[\n",
        "                    (self.df_tracking['play_id_n'] == play_id) &\n",
        "                    (self.df_tracking['frame_id'] == target_frame)\n",
        "                ]\n",
        "\n",
        "                for i, receiver_id in enumerate(players):\n",
        "                    receiver_data = target_frame_data[target_frame_data['nfl_id'] == receiver_id]\n",
        "                    if not receiver_data.empty:\n",
        "                        x = float(receiver_data['x'].iloc[0]) / 120\n",
        "                        y = float(receiver_data['y'].iloc[0]) / 53.3\n",
        "                        target_positions[i, step] = torch.tensor([x, y])\n",
        "\n",
        "\n",
        "        return (\n",
        "            input_sequence,\n",
        "            target_positions,\n",
        "            target_mask,\n",
        "            start_pos,\n",
        "            torch.tensor(act_input),\n",
        "            torch.tensor(act_output)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfcbdcfc",
      "metadata": {},
      "source": [
        "##### Data Prep, Training, Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b627e37",
      "metadata": {
        "id": "4b627e37"
      },
      "outputs": [],
      "source": [
        "# split by indexs\n",
        "play_indices = np.arange(len(df_grids['play_id_n'].unique()))\n",
        "train_idx, test_idx = train_test_split(play_indices, test_size=0.2, random_state=26)\n",
        "test_idx, val_idx = train_test_split(test_idx, test_size=0.7, random_state=26)\n",
        "\n",
        "# create the datasets dynamically\n",
        "train_dataset = NFLSequenceDataset(df_grids, df, max_targets, int(max_input), int(max_output), train_idx)\n",
        "val_dataset = NFLSequenceDataset(df_grids, df, max_targets, int(max_input), int(max_output), val_idx)\n",
        "test_dataset = NFLSequenceDataset(df_grids, df, max_targets, int(max_input), int(max_output), test_idx)\n",
        "\n",
        "# create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, drop_last=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ZnN4jdggoE5",
      "metadata": {
        "id": "8ZnN4jdggoE5"
      },
      "outputs": [],
      "source": [
        "# clean envi\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfa8b6b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "cfa8b6b1",
        "outputId": "af5ecfbb-45a5-471c-ba42-bf81a9cd1bd3"
      },
      "outputs": [
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 22.16 GiB of which 11.38 MiB is free. Process 10591 has 22.14 GiB memory in use. Of the allocated memory 21.34 GiB is allocated by PyTorch, and 582.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1713340436.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1906015421.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, optimizer, scheduler, epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         predictions = model(batch_sequence, batch_start_pos, batch_masks,\n\u001b[0m\u001b[1;32m     30\u001b[0m                             batch_output_lengths, batch_input_lengths)\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3151338016.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, heatmap_sequence, start_pos, target_mask, future_steps, input_lengths)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mencoded_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# output predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1261171323.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoded_context, start_positons, target_mask, max_step_change, output_lengths)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_targets_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasual_mask_expanded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m# normalize gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-926600645.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, decoder_input, encoded_context, target_mask, casual_mask)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mnorm_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasual_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3218937738.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# scaled dot product, scale so values arent 0 or 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;31m# matrix mult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# set masked values to -inf so softmax does not \"give\" attention to them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 22.16 GiB of which 11.38 MiB is free. Process 10591 has 22.14 GiB memory in use. Of the allocated memory 21.34 GiB is allocated by PyTorch, and 582.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "# model\n",
        "model = DJMooreSeq(embed_size=64, encoder_layers=4, decoder_layers=4, max_targets=max_targets, max_step=1.4, dropout=0.1, nheads=4,dev='cuda').to('cuda')\n",
        "\n",
        "# epochs\n",
        "epochs = 1000\n",
        "\n",
        "# loss, opti, schedu\n",
        "loss_func = MaskedSequenceLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.001)\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=5, num_training_steps=epochs)\n",
        "\n",
        "# train\n",
        "train_losses, val_losses = train(model, train_loader, val_loader, loss_func, optimizer, scheduler, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y-MKVAXri79k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-MKVAXri79k",
        "outputId": "b5955a10-6d3d-426a-a0f2-94836cf26023"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state_dict = torch.load(\"2500_4_4_4_model26.pth\")\n",
        "model.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rTYw9BR_0Sms",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "collapsed": true,
        "id": "rTYw9BR_0Sms",
        "outputId": "3b48e447-589e-4f5a-ab7b-c16a3e6074e1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def visualize_predictions(model, data_loader, play_idx=0, target_player_idx=0):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_sequence, batch_targets, batch_masks, batch_start_pos, batch_input_lengths, batch_output_lengths in data_loader:\n",
        "            batch_sequence = batch_sequence.to('cuda')\n",
        "            batch_targets = batch_targets.to('cuda')\n",
        "            batch_masks = batch_masks.to('cuda')\n",
        "            batch_start_pos = batch_start_pos.to('cuda')\n",
        "            batch_input_lengths = batch_input_lengths.to('cuda')\n",
        "            batch_output_lengths = batch_output_lengths.to('cuda')\n",
        "\n",
        "            with torch.autocast(device_type=\"cuda\"):\n",
        "                predictions = model(batch_sequence, batch_start_pos, batch_masks,\n",
        "                                    batch_output_lengths, batch_input_lengths)\n",
        "\n",
        "            predicted_trajectory = predictions[play_idx, target_player_idx, :, :].cpu().numpy()\n",
        "            actual_trajectory = batch_targets[play_idx, target_player_idx, :, :].cpu().numpy()\n",
        "            mask = batch_masks[play_idx, target_player_idx].cpu().numpy()\n",
        "            output_length = batch_output_lengths[play_idx].cpu().numpy()\n",
        "\n",
        "\n",
        "            predicted_trajectory = predicted_trajectory[:output_length]\n",
        "            actual_trajectory = actual_trajectory[:output_length]\n",
        "\n",
        "            # scale back to normal \n",
        "            predicted_trajectory[:, 0] *= 120\n",
        "            predicted_trajectory[:, 1] *= 53.3\n",
        "            actual_trajectory[:, 0] *= 120\n",
        "            actual_trajectory[:, 1] *= 53.3\n",
        "\n",
        "            # plot trajectory\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(actual_trajectory[:, 0], actual_trajectory[:, 1], marker='o', linestyle='-', color='blue', label='Actual')\n",
        "            plt.plot(predicted_trajectory[:, 0], predicted_trajectory[:, 1], marker='x', linestyle='--', color='red', label='Predicted')\n",
        "            plt.xlabel('X Coordinate (yards)')\n",
        "            plt.ylabel('Y Coordinate (yards)')\n",
        "            plt.title(f'Predicted vs Actual Trajectory for Play {play_idx}, Target Player {target_player_idx}')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "\n",
        "            # first point in black\n",
        "            plt.plot(actual_trajectory[0, 0], actual_trajectory[0, 1], marker='o', color='black', markersize=8)\n",
        "            plt.plot(predicted_trajectory[0, 0], predicted_trajectory[0, 1], marker='x', color='black', markersize=8)\n",
        "\n",
        "            # last point blue\n",
        "            plt.plot(actual_trajectory[-1, 0], actual_trajectory[-1, 1], marker='o', color='blue', markersize=8)\n",
        "            plt.plot(predicted_trajectory[-1, 0], predicted_trajectory[-1, 1], marker='x', color='blue', markersize=8)\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "            break\n",
        "\n",
        "visualize_predictions(model, test_loader, play_idx=9, target_player_idx=3)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "eb3b0c43"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nflLab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
