{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9b4M7YS2sh4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9b4M7YS2sh4",
        "outputId": "746742c0-c032-42a0-f47c-ca8c05599303"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "882c941d",
      "metadata": {
        "collapsed": true,
        "id": "882c941d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/databowl/')\n",
        "df = pd.read_csv('2023_tracking.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5960ee90",
      "metadata": {
        "id": "5960ee90"
      },
      "outputs": [],
      "source": [
        "play_ids = df['play_id_n'].unique()[2000:4500]\n",
        "df = df[df['play_id_n'].isin(play_ids)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40823073",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40823073",
        "outputId": "cc431939-93f2-4927-d2c7-916d585f5918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "max_targets = df.groupby(['play_id_n', 'frame_id'])['player_to_predict'].sum().max()\n",
        "print(max_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb3b0c43",
      "metadata": {
        "id": "eb3b0c43"
      },
      "source": [
        "#### 2d Grid of Cords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7bdcf7e",
      "metadata": {
        "id": "c7bdcf7e"
      },
      "outputs": [],
      "source": [
        "def pixel_map(player_data, target_player_ids, max_targets, grid_width=121, grid_height=55, sigma=.8):\n",
        "\n",
        "    num_channels = 2 + max_targets + 1\n",
        "    # three channels, one for offense, one for defense, one for ball location, one for player to predict\n",
        "    pixel_map = np.zeros((num_channels, grid_height, grid_width), dtype=np.float32)\n",
        "\n",
        "    x_vals = player_data['x'].values\n",
        "    y_vals = player_data['y'].values\n",
        "\n",
        "    for i, (x, y) in enumerate(zip(x_vals, y_vals)):\n",
        "        x_min = max(0, int(np.floor(x - 2*sigma)))\n",
        "        x_max = min(grid_width, int(np.ceil(x + 2*sigma)) + 1)\n",
        "        y_min = max(0, int(np.floor(y - 2*sigma)))\n",
        "        y_max = min(grid_height, int(np.ceil(y + 2*sigma)) + 1)\n",
        "\n",
        "        for xi in range(x_min, x_max):\n",
        "            for yi in range(y_min, y_max):\n",
        "                dist_sq = (xi - x)**2 + (yi - y)**2\n",
        "                weight = np.exp(-dist_sq / (2 * sigma**2))\n",
        "\n",
        "                player_id = player_data.iloc[i].get('nfl_id', None)\n",
        "\n",
        "                if player_id in target_player_ids:\n",
        "                    target_idx = target_player_ids.index(player_id)\n",
        "                    if target_idx < max_targets: # to prevent error\n",
        "                        pixel_map[2 + target_idx, yi, xi] += weight\n",
        "                elif player_data.iloc[i]['player_side'] == 'Offense':\n",
        "                    pixel_map[0, yi, xi] += weight\n",
        "                elif player_data.iloc[i]['player_side'] == 'Defense':\n",
        "                    pixel_map[1, yi, xi] += weight\n",
        "\n",
        "\n",
        "    ball_x = player_data['ball_land_x'].iloc[0]\n",
        "    ball_y = player_data['ball_land_y'].iloc[0]\n",
        "\n",
        "    ball_x_min = max(0, int(np.floor(ball_x - 2*sigma)))\n",
        "    ball_x_max = min(grid_width, int(np.ceil(ball_x + 2*sigma)) + 1)\n",
        "    ball_y_min = max(0, int(np.floor(ball_y - 2*sigma)))\n",
        "    ball_y_max = min(grid_height, int(np.ceil(ball_y + 2*sigma)) + 1)\n",
        "\n",
        "    for xi in range(ball_x_min, ball_x_max):\n",
        "        for yi in range(ball_y_min, ball_y_max):\n",
        "            dist_sq = (xi - ball_x)**2 + (yi - ball_y)**2\n",
        "            weight = np.exp(-dist_sq / (2 * sigma**2))\n",
        "            pixel_map[2 + max_targets, yi, xi] += weight\n",
        "\n",
        "    return pixel_map"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fdb8c7f",
      "metadata": {
        "id": "5fdb8c7f"
      },
      "source": [
        "testing one play"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a45368c4",
      "metadata": {
        "id": "a45368c4",
        "outputId": "666b0591-43c3-4c9a-dbb5-635116ef356c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dalto\\AppData\\Local\\Temp\\ipykernel_25552\\2474093878.py:3: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_grids_t = df_play_id.groupby(['play_id_n','frame_id']).apply(\n"
          ]
        }
      ],
      "source": [
        "df_play_id = df[df['play_id_n'] == 456]\n",
        "target_player_ids = df_play_id[df_play_id['player_to_predict'] == True]['nfl_id'].unique().tolist()\n",
        "df_grids_t = df_play_id.groupby(['play_id_n','frame_id']).apply(\n",
        "    lambda x: pd.Series({'grid': pixel_map(x, target_player_ids, max_targets)})\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84373868",
      "metadata": {
        "id": "84373868"
      },
      "source": [
        "grid for all plays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fbb8477",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fbb8477",
        "outputId": "807ad0a8-56a4-4751-87a4-1e764526f074"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3746108319.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_grids = df.groupby(['play_id_n','frame_id']).apply(\n"
          ]
        }
      ],
      "source": [
        "df_grids = df.groupby(['play_id_n','frame_id']).apply(\n",
        "    lambda x: pd.Series({'grid': pixel_map(x,  x[x['player_to_predict'] == True]['nfl_id'].unique().tolist(), max_targets)})\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9189e025",
      "metadata": {
        "id": "9189e025"
      },
      "outputs": [],
      "source": [
        "df_grids = df_grids.reset_index()\n",
        "df_grids = df_grids.sort_values(['play_id_n', 'frame_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fe42dca",
      "metadata": {
        "id": "8fe42dca"
      },
      "source": [
        "visual test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35e0b800",
      "metadata": {
        "id": "35e0b800"
      },
      "outputs": [],
      "source": [
        "sample_grid = df_grids_t['grid'].iloc[30]\n",
        "\n",
        "# Count how many target player channels have data\n",
        "num_targets = 0\n",
        "for i in range(max_targets):\n",
        "    if sample_grid[2 + i].sum() > 0:\n",
        "        num_targets += 1\n",
        "\n",
        "# Create subplots: 2 base channels + ball + target players\n",
        "total_plots = 3 + num_targets\n",
        "cols = 4\n",
        "rows = (total_plots + cols - 1) // cols\n",
        "\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(14, 5*rows))\n",
        "axes = axes.flatten() if total_plots > 1 else [axes]\n",
        "\n",
        "# Plot offense\n",
        "axes[0].imshow(sample_grid[0], origin='lower', cmap='Reds')\n",
        "axes[0].set_title('Offense Players')\n",
        "axes[0].set_xlabel('X (yards)')\n",
        "axes[0].set_ylabel('Y (yards)')\n",
        "\n",
        "# Plot defense\n",
        "axes[1].imshow(sample_grid[1], origin='lower', cmap='Blues')\n",
        "axes[1].set_title('Defense Players')\n",
        "axes[1].set_xlabel('X (yards)')\n",
        "axes[1].set_ylabel('Y (yards)')\n",
        "\n",
        "# Plot ball location (at index 2 + max_targets)\n",
        "axes[2].imshow(sample_grid[2 + max_targets], origin='lower', cmap='Purples')\n",
        "axes[2].set_title('Ball Landing Location')\n",
        "axes[2].set_xlabel('X (yards)')\n",
        "axes[2].set_ylabel('Y (yards)')\n",
        "\n",
        "# Plot each target player (channels 2 through 2+max_targets-1)\n",
        "plot_idx = 3\n",
        "for i in range(max_targets):\n",
        "    if sample_grid[2 + i].sum() > 0:\n",
        "        axes[plot_idx].imshow(sample_grid[2 + i], origin='lower', cmap='Greens')\n",
        "        axes[plot_idx].set_title(f'Target Player {i+1}')\n",
        "        axes[plot_idx].set_xlabel('X (yards)')\n",
        "        axes[plot_idx].set_ylabel('Y (yards)')\n",
        "        plot_idx += 1\n",
        "\n",
        "for idx in range(total_plots, len(axes)):\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3e99f11",
      "metadata": {
        "id": "c3e99f11"
      },
      "outputs": [],
      "source": [
        "df_grids.to_pickle(\"full_grids_2500.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adae6a33",
      "metadata": {
        "id": "adae6a33"
      },
      "source": [
        "### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc55cbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1cc55cbb",
        "outputId": "da6ef8fc-1b0f-49cf-8fe8-3ae25326bf3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x785c55347790>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "df_grids = pd.read_pickle(\"full_grids_2500.pkl\")\n",
        "torch.manual_seed(26)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c6635c9",
      "metadata": {
        "id": "7c6635c9"
      },
      "source": [
        "#### Global Input Seq Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8d6455d",
      "metadata": {
        "id": "e8d6455d"
      },
      "outputs": [],
      "source": [
        "class CNN_DownSample(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # variable based on amount of targets\n",
        "        input_chan = 2 + max_targets + 1\n",
        "\n",
        "        # using stride rather than max pooling preforms better as max pooling tends to compress feat. too much.\n",
        "        self.heatmap_encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_chan, out_channels=16, kernel_size=3, stride = 2, padding=1),\n",
        "            nn.BatchNorm2d(16), # normalize var and mean\n",
        "            nn.GELU(), # preforms better on average idk if itll make a difference in this application\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride = 2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride = 2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.heatmap_encoder(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f884d25",
      "metadata": {
        "id": "6f884d25"
      },
      "source": [
        "attention layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b4da6b9",
      "metadata": {
        "id": "1b4da6b9"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, nhead, mask, dropout=0.15):\n",
        "        super().__init__() # inhert from parent class\n",
        "\n",
        "        if d_model % nhead != 0:\n",
        "            raise ValueError(f\"d_model ({d_model}) must be divisible by nhead ({nhead})\")\n",
        "\n",
        "        self.d_model = d_model # dimension of model\n",
        "        self.nhead = nhead # number of attention heads, multi headed\n",
        "        self.head_dim = d_model // nhead\n",
        "\n",
        "        # create key query and values\n",
        "        self.qkv_proj = nn.Linear(d_model, 3 * d_model)\n",
        "        # learn context as a product of the attention heads\n",
        "        self.out_proj = nn.Linear(d_model, d_model)\n",
        "        # dropout as a form of regularzation\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # scaling function\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        B, L, _ = x.shape # batch and length\n",
        "\n",
        "        # create q, k, v values | init just random matrix mults, learned parameter\n",
        "        qkv = self.qkv_proj(x)\n",
        "\n",
        "        # split key, query, and value vectors into diff pares\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "\n",
        "        # transpose the matrix so that batch and nhead are treated as batches and self attention is calculated from there\n",
        "        q = q.view(B, L, self.nhead, self.head_dim).transpose(1, 2)\n",
        "        k = k.view(B, L, self.nhead, self.head_dim).transpose(1, 2)\n",
        "        v = v.view(B, L, self.nhead, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # scaled dot product, scale so values arent 0 or 1\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale # matrix mult\n",
        "\n",
        "        # set masked values to -inf so softmax does not \"give\" attention to them\n",
        "        if mask is not None:\n",
        "          if mask.dim() == 2:\n",
        "            mask = mask.expand(B, self.nhead, L, L)\n",
        "          elif mask.dim() == 3:\n",
        "            mask = mask.unsqueeze(1)\n",
        "            mask = mask.expand(B, self.nhead, L, L)\n",
        "          elif mask.dim() == 4:\n",
        "            mask = mask.expand(B, self.nhead, L, L)\n",
        "\n",
        "          scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "\n",
        "        # softmax to give attention weights to each token\n",
        "        attn_weights = torch.softmax(scores, dim=-1)\n",
        "\n",
        "        # drop some weights\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # context vector for a given input sequence\n",
        "        context = torch.matmul(attn_weights, v)\n",
        "\n",
        "        # transpose so the matrix is in the correct size to be concatinated\n",
        "        context = context.transpose(1, 2).contiguous().view(B, L, self.d_model)\n",
        "\n",
        "        # \"combine\" the outputs from the head to one general vector\n",
        "        output = self.out_proj(context)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee94df07",
      "metadata": {
        "id": "ee94df07"
      },
      "source": [
        "transformer block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445638fb",
      "metadata": {
        "id": "445638fb"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, nhead=4, mask=None, dropout=0.15):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        # self attention class definied above\n",
        "        self.self_attn = MultiHeadAttention(d_model=d_model, nhead=nhead, dropout=dropout, mask=mask)\n",
        "\n",
        "        # feed forward network for each token\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(64, 128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout), # to combat overfitting\n",
        "            nn.Linear(128, 64)\n",
        "        )\n",
        "\n",
        "        # normilzations so values are between 0-1, learned gamma and beta parameters\n",
        "        # to shift center and var for values.\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # standard dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        residual = x\n",
        "        # normalized pre attention layer, gradients flow black directly without the normalizing effecting x values\n",
        "        norm_x = self.norm1(x)\n",
        "        # self attention\n",
        "        attn_output = self.self_attn(norm_x, mask)\n",
        "        # adding residual back to self attention\n",
        "        x = residual + self.dropout(attn_output)\n",
        "\n",
        "        residual = x\n",
        "        # normalize values\n",
        "        # we do so because over the amount of layers scale can get distorted, lead to super big or small values\n",
        "        norm_x = self.norm2(x)\n",
        "        # basic fcn\n",
        "        ff_output = self.feed_forward(norm_x)\n",
        "        # adding residual back so that the gradient can flow directly back.\n",
        "        # adds a 1 + terms to gradients, helps solve the vanishing gradients problem\n",
        "        x = residual + self.dropout(ff_output)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb6e6e4c",
      "metadata": {
        "id": "fb6e6e4c"
      },
      "outputs": [],
      "source": [
        "# use sinusoidal functions, simpler than learned values and generalizes better to unseen parameters\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_size, dropout, max_length=150):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        # droput\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # create matrix\n",
        "        pe = torch.zeros(max_length, embed_size)\n",
        "\n",
        "        # position tensor shape\n",
        "        position = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # div_term tensor shape\n",
        "        div_term = torch.exp(torch.arange(0, embed_size, 2).float() * (-torch.log(torch.tensor(10000.0)) / embed_size))\n",
        "\n",
        "        # apply sin to even indices\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        # apply cos to odd indices\n",
        "        if embed_size % 2 == 1:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term[:-1])\n",
        "        else:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # register as buffer so it moves with model to device\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        pe_slice = self.pe[:x.size(1), :].to(x.device)\n",
        "        x = x + pe_slice\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TransEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, embed_size, num_layers, device, dropout, mask, max_length):\n",
        "        super(TransEncoder, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.device = device\n",
        "        # learned matrix projection\n",
        "        self.input_projection = nn.Linear(input_dim, embed_size)\n",
        "        # postional encoding\n",
        "        self.position_encoding = PositionalEncoding(embed_size, dropout, max_length)\n",
        "        # layers of model, just stacked encoding layer\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                TransformerBlock(\n",
        "                    embed_size,\n",
        "                    mask=mask,\n",
        "                    nhead=4, # number of attention heads\n",
        "                    dropout=dropout\n",
        "                )\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "        # normalize after attention\n",
        "        self.norm = nn.LayerNorm(embed_size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # input layer matrix mult\n",
        "        projected_input = self.input_projection(x)\n",
        "        # position encodings\n",
        "        out = self.position_encoding(projected_input)\n",
        "        # mask to correct dim\n",
        "        mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "        # pass through transformer block\n",
        "        for layer in self.layers:\n",
        "            out = layer(out, mask)\n",
        "        # normalize gradients\n",
        "        out = self.norm(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2d1449e",
      "metadata": {
        "id": "b2d1449e"
      },
      "source": [
        "##### Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "024ee759",
      "metadata": {
        "id": "024ee759"
      },
      "outputs": [],
      "source": [
        "# prevent lookahead\n",
        "def create_causal_mask(seq_len, device):\n",
        "    mask = torch.tril(torch.ones(seq_len, seq_len, device=device))\n",
        "    return mask.bool()\n",
        "\n",
        "# seq mask to deal with padded values\n",
        "def seq_maks(input_lengths, max_input, device):\n",
        "    batch_size = len(input_lengths)\n",
        "    input_mask = torch.zeros(batch_size, max_input, device=device, dtype=torch.bool)\n",
        "    for i, length in enumerate(input_lengths):\n",
        "        input_mask[i, :length] = True\n",
        "\n",
        "# loss with mask\n",
        "def mse_with_length_mask(predictions, targets, combined_mask):\n",
        "    mse = (predictions - targets) ** 2\n",
        "    masked_mse = mse * combined_mask\n",
        "\n",
        "    valid_elements = combined_mask.sum()\n",
        "    if valid_elements > 0:\n",
        "        return masked_mse.sum() / valid_elements\n",
        "    else:\n",
        "        return torch.tensor(0.0, device=predictions.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5fada4f",
      "metadata": {
        "id": "e5fada4f"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, dropout, embedding, nhead):\n",
        "        super().__init__()\n",
        "        # attention layers\n",
        "        self.attention_self = MultiHeadAttention(d_model=embedding, nhead=4, mask=None, dropout=dropout)\n",
        "\n",
        "        # cross atten, query values, info\n",
        "        self.cross_q_proj = nn.Linear(embedding, embedding)\n",
        "        self.cross_k_proj = nn.Linear(embedding, embedding)\n",
        "        self.cross_v_proj =  nn.Linear(embedding, embedding)\n",
        "        self.cross_out_proj = nn.Linear(embedding, embedding)\n",
        "\n",
        "        self.nhead = nhead\n",
        "        self.head_dim = embedding // nhead\n",
        "        self.scale = self.head_dim ** -0.5 # 1/sqrt(dk)\n",
        "\n",
        "        # layer normal\n",
        "        self.norm1 = nn.LayerNorm(embedding)\n",
        "        self.norm2 = nn.LayerNorm(embedding)\n",
        "        self.norm3 = nn.LayerNorm(embedding)\n",
        "\n",
        "        # droput\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # fcnn\n",
        "        self.fcnn = nn.Sequential(\n",
        "            nn.Linear(embedding, embedding*2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.15),\n",
        "            nn.Linear(embedding*2, embedding)\n",
        "        )\n",
        "    # decoder forward pass\n",
        "    def forward(self, decoder_input, encoded_context, target_mask = None, casual_mask=None):\n",
        "\n",
        "        # self attention amoung decoder\n",
        "        residual = decoder_input\n",
        "        norm_x = self.norm1(decoder_input)\n",
        "        self_attn = self.attention_self(norm_x, casual_mask)\n",
        "        decoder_input = residual + self.dropout(self_attn)\n",
        "\n",
        "        # cross attention to encoder\n",
        "        norm_x = self.norm2(decoder_input)\n",
        "        cross_atn = self.encoder_cross_attention(norm_x, encoded_context)\n",
        "        # dropout, also cant do inplace ops bc of backprop\n",
        "        decoder_input = decoder_input + self.dropout(cross_atn)\n",
        "\n",
        "        # fcnn predictions\n",
        "        norm_x = self.norm3(decoder_input)\n",
        "        ffcn = self.fcnn(norm_x)\n",
        "        out = decoder_input + self.dropout(ffcn)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def encoder_cross_attention(self, query, key_value):\n",
        "        B, L_q, _ = query.shape # decoder input\n",
        "        B, L_kv, _ = key_value.shape # encoder output\n",
        "\n",
        "        q = self.cross_q_proj(query)\n",
        "        k = self.cross_k_proj(key_value)\n",
        "        v = self.cross_v_proj(key_value)\n",
        "\n",
        "        q = q.view(B, L_q, self.nhead, self.head_dim).transpose(1, 2)\n",
        "        k = k.view(B, L_kv, self.nhead, self.head_dim).transpose(1, 2)\n",
        "        v = v.view(B, L_kv, self.nhead, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
        "\n",
        "        attn_weights = torch.softmax(scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context = torch.matmul(attn_weights, v)\n",
        "        context = context.transpose(1, 2).contiguous().view(B, L_q, -1)\n",
        "\n",
        "        output = self.cross_out_proj(context)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccc6e89c",
      "metadata": {
        "id": "ccc6e89c"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_size, dropout, max_length=150):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        # droput\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # create matrix\n",
        "        pe = torch.zeros(max_length, embed_size)\n",
        "\n",
        "        # position tensor shape\n",
        "        position = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # div_term tensor shape\n",
        "        div_term = torch.exp(torch.arange(0, embed_size, 2).float() * (-torch.log(torch.tensor(10000.0)) / embed_size))\n",
        "\n",
        "        # apply sin to even indices\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        # apply cos to odd indices\n",
        "        if embed_size % 2 == 1:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term[:-1])\n",
        "        else:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # register as buffer so it moves with model to device\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        pe_slice = self.pe[:x.size(1), :].to(x.device)\n",
        "        x = x + pe_slice\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fca8aa6",
      "metadata": {
        "id": "2fca8aa6"
      },
      "outputs": [],
      "source": [
        "class TransDecoder(nn.Module):\n",
        "    def __init__(self, target_mask, embedding, dropout, nhead, layers, max_targets, max_step_change, max_seq_len):\n",
        "        super(TransDecoder, self).__init__()\n",
        "        self.max_targets = max_targets\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.embedding = embedding\n",
        "        self.max_step = max_step_change\n",
        "\n",
        "        # project 2d cords to embedding space\n",
        "        self.positon_projection = nn.Linear(2, embedding)\n",
        "\n",
        "        # project outputs back to 2d space\n",
        "        self.output_projection = nn.Linear(embedding, 2)\n",
        "\n",
        "        # postional embeddings\n",
        "        self.pos_embed = PositionalEncoding(embed_size=embedding, dropout=0.15, max_length=150)\n",
        "\n",
        "        # decoder layers\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(embedding=embedding, dropout=dropout, nhead=nhead)\n",
        "            for _ in range(layers)\n",
        "        ])\n",
        "\n",
        "        # normalization\n",
        "        self.norm = nn.LayerNorm(embedding)\n",
        "\n",
        "    def forward(self, encoded_context, start_positons, target_mask, max_step_change, output_lengths):\n",
        "        # batch size and device\n",
        "        batch_size = encoded_context.shape[0]\n",
        "        device = encoded_context.device\n",
        "\n",
        "        # max output length\n",
        "        max_output_len = output_lengths.max().item()\n",
        "\n",
        "        # output tensor\n",
        "        all_outputs = torch.zeros(batch_size, self.max_targets, max_output_len, 2, device=device)\n",
        "\n",
        "        # decoder seq\n",
        "        decoder_sequence = [[] for _ in range(batch_size)]\n",
        "        current_postions = start_positons.clone()\n",
        "\n",
        "        # output sequence\n",
        "        for step in range(max_output_len):\n",
        "            step_mask = step < output_lengths\n",
        "            active_batch_size = step_mask.sum().item()\n",
        "\n",
        "            if active_batch_size == 0:\n",
        "                break\n",
        "\n",
        "            # project pos to embedding space\n",
        "            pos_embeds = self.positon_projection(current_postions)\n",
        "\n",
        "            # add positional context\n",
        "            pos_encoding = self.pos_embed.pe[step, :self.embedding].unsqueeze(0).unsqueeze(0)\n",
        "            # Replace inplace addition with out-of-place addition\n",
        "            pos_input = pos_embeds + pos_encoding\n",
        "\n",
        "            # add sequence dim back\n",
        "            pos_input = pos_input.unsqueeze(2)\n",
        "\n",
        "            # decoder seq\n",
        "            for batch_idx in range(batch_size):\n",
        "                if step_mask[batch_idx]:\n",
        "                    decoder_sequence[batch_idx].append(pos_input[batch_idx])\n",
        "\n",
        "            if step == 0:\n",
        "                # if first step use init pos\n",
        "                decoder_input = pos_input\n",
        "                casual_mask = None\n",
        "            else:\n",
        "                # decoder inputs\n",
        "                batch_decoder_inputs = []\n",
        "\n",
        "                # get decoder seq for values\n",
        "                for batch_idx in range(batch_size):\n",
        "                    if step_mask[batch_idx]:\n",
        "                        sample_sequence = torch.cat(decoder_sequence[batch_idx], dim = 1)\n",
        "                        batch_decoder_inputs.append(sample_sequence)\n",
        "                    else: # if padded value etc.\n",
        "                        dummy_input = torch.zeros(self.max_targets, step+1, self.embedding, device=device)\n",
        "                        batch_decoder_inputs.append(dummy_input)\n",
        "\n",
        "                # all samples for decoder input\n",
        "                decoder_input = torch.stack(batch_decoder_inputs)\n",
        "\n",
        "                # casual mask\n",
        "                seq_len = step + 1\n",
        "                casual_mask = create_causal_mask(seq_len, device)\n",
        "\n",
        "\n",
        "            # transformer layers\n",
        "            batch_size_curr, max_targets_curr, seq_len_curr, embed_dim_curr = decoder_input.shape\n",
        "            decoder_input_reshaped = decoder_input.view(batch_size_curr * max_targets_curr, seq_len_curr, embed_dim_curr)\n",
        "\n",
        "            # decoder layer\n",
        "            decoded = decoder_input_reshaped\n",
        "\n",
        "            # masking for future seq\n",
        "            if casual_mask is not None:\n",
        "               casual_mask_expanded = casual_mask.unsqueeze(0).expand(batch_size_curr * max_targets_curr, seq_len_curr, seq_len_curr)\n",
        "            else:\n",
        "               casual_mask_expanded = None\n",
        "\n",
        "\n",
        "            for layer in self.layers:\n",
        "                decoded = layer(decoded, encoded_context.repeat_interleave(max_targets_curr, dim=0), target_mask, casual_mask_expanded)\n",
        "\n",
        "            # normalize gradients\n",
        "            decoded = self.norm(decoded)\n",
        "\n",
        "            # reshape and project back to cords\n",
        "            decoded = decoded.view(batch_size_curr, max_targets_curr, seq_len_curr, embed_dim_curr)\n",
        "            predictions = self.output_projection(decoded[:, :, -1, :])\n",
        "\n",
        "            clamp_pred = predictions\n",
        "\n",
        "            if self.max_step is not None and self.max_step > 0:\n",
        "              # change in positon\n",
        "              delta = predictions - current_postions\n",
        "              # distance between\n",
        "              dist = torch.norm(delta, p=2, dim=-1)\n",
        "              # scale preds\n",
        "              scale_factor = torch.clamp(dist / (self.max_step + 1e-9), max=1).unsqueeze(-1)\n",
        "              # clamped preds\n",
        "              clamp_pred = current_postions + scale_factor * delta\n",
        "\n",
        "            for batch_idx in range(batch_size):\n",
        "                if step_mask[batch_idx]:\n",
        "                    all_outputs[batch_idx, :, step, :] = clamp_pred[batch_idx]\n",
        "\n",
        "            # stack all predictions\n",
        "            current_postions = clamp_pred.clone()\n",
        "\n",
        "        # target mask\n",
        "        target_mask_exp = target_mask.unsqueeze(-1).unsqueeze(-1)\n",
        "        all_outputs = all_outputs * target_mask_exp\n",
        "\n",
        "        return all_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba1c1648",
      "metadata": {
        "id": "ba1c1648"
      },
      "outputs": [],
      "source": [
        "def train_seq_2_seq(df_grids, max_targets, max_input, max_output):\n",
        "    # arrays and postions\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    masks = []\n",
        "    start_positions = []\n",
        "    input_lengths = []\n",
        "    output_lengths = []\n",
        "\n",
        "    # get all offensive players\n",
        "    player_to_predict = df[df['player_to_predict'] == True].groupby('play_id_n')['nfl_id'].unique()\n",
        "\n",
        "    # get players to predict postions\n",
        "    for play_id in df_grids['play_id_n'].unique():\n",
        "        play_data = df_grids[df_grids['play_id_n'] == play_id].sort_values('frame_id')\n",
        "\n",
        "    # loop through every play\n",
        "    for play_id in df_grids['play_id_n'].unique():\n",
        "        # data for play\n",
        "        play_data = df_grids[df_grids['play_id_n'] == play_id].sort_values('frame_id')\n",
        "        df_data = df[df['play_id_n'] == play_id]\n",
        "        # frames of input and output\n",
        "        total_frames = play_data['frame_id'].max()\n",
        "        output_frames = int(df_data['num_frames_output'].max())\n",
        "\n",
        "        # get players to predict ids\n",
        "        players = player_to_predict[play_id]\n",
        "\n",
        "        # only take max targets\n",
        "        players = players[:max_targets]\n",
        "        num_receivers = len(players)\n",
        "\n",
        "        # mask of players\n",
        "        mask = torch.zeros(max_targets)\n",
        "        mask[:num_receivers] = 1\n",
        "\n",
        "        # sequence lengths\n",
        "        input_seq_len = total_frames - output_frames\n",
        "        output_seq_len = output_frames\n",
        "\n",
        "        # input sequence\n",
        "        input_grids = [torch.from_numpy(grid).float() for grid in play_data['grid'].iloc[:input_seq_len]]\n",
        "        sequence = torch.stack(input_grids, dim=0)\n",
        "\n",
        "        # add noise for regularization\n",
        "        noise = torch.randn_like(sequence) * 0.0001\n",
        "        input_sequence = sequence + noise\n",
        "\n",
        "        # pad sequence to max_size if necessary\n",
        "        if input_sequence.shape[0] < max_input:\n",
        "            padding_size = max_input - input_sequence.shape[0]\n",
        "            padding = torch.zeros(padding_size, *input_sequence.shape[1:])\n",
        "            input_sequence = torch.cat([input_sequence, padding], dim=0)\n",
        "        elif input_sequence.shape[0] > max_input:\n",
        "            input_sequence = input_sequence[:max_input]\n",
        "\n",
        "        # last frame of input sequence\n",
        "        start_pos = torch.zeros(max_targets, 2)\n",
        "        last_frame_id = play_data.iloc[input_seq_len - 1]['frame_id']\n",
        "        last_frame_data = df[(df['play_id_n'] == play_id) & (df['frame_id'] == last_frame_id)]\n",
        "\n",
        "        # get cords for the last frame of the input seq\n",
        "        for i, receiver_id in enumerate(players):\n",
        "            receiver_data = last_frame_data[last_frame_data['nfl_id'] == receiver_id]\n",
        "            if not receiver_data.empty:\n",
        "                x = float(receiver_data['x'].iloc[0]) / 120\n",
        "                y = float(receiver_data['y'].iloc[0]) / 53.3\n",
        "                start_pos[i] = torch.tensor([x, y])\n",
        "\n",
        "        # target sequence\n",
        "        target_positions = torch.zeros(max_targets, max_output, 2)\n",
        "\n",
        "        # append postions for every targeted reciver\n",
        "        for step in range(output_seq_len):\n",
        "            frame_idx = input_seq_len + step\n",
        "            if frame_idx < len(play_data):\n",
        "                target_frame = play_data.iloc[frame_idx]['frame_id']\n",
        "                last_frame_data = df[(df['play_id_n'] == play_id) & (df['frame_id'] == target_frame)]\n",
        "\n",
        "            for i, receiver_id in enumerate(players):\n",
        "                receiver_data = last_frame_data[last_frame_data['nfl_id'] == receiver_id]\n",
        "                if not receiver_data.empty:\n",
        "                    x = float(receiver_data['x'].iloc[0]) / 120\n",
        "                    y = float(receiver_data['y'].iloc[0]) / 53.3\n",
        "                    target_positions[i, step] = torch.tensor([x, y])\n",
        "\n",
        "        # if there is targets\n",
        "        if num_receivers > 0:\n",
        "            sequences.append(input_sequence)\n",
        "            targets.append(target_positions)\n",
        "            masks.append(mask)\n",
        "            start_positions.append(start_pos)\n",
        "            input_lengths.append(input_seq_len)\n",
        "            output_lengths.append(output_seq_len)\n",
        "\n",
        "    if len(sequences) == 0:\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    return (torch.stack(sequences, dim=0),\n",
        "            torch.stack(targets, dim=0),\n",
        "            torch.stack(masks, dim=0),\n",
        "            torch.stack(start_positions, dim=0),\n",
        "            torch.tensor(input_lengths),\n",
        "            torch.tensor(output_lengths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a4723f3",
      "metadata": {
        "id": "7a4723f3"
      },
      "outputs": [],
      "source": [
        "class MaskedSequenceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, predictions, targets, target_mask):\n",
        "        mask = target_mask.unsqueeze(-1).unsqueeze(-1)\n",
        "        mask = mask.expand_as(predictions)\n",
        "\n",
        "        mse = (predictions - targets) ** 2\n",
        "        # dont consider error on padding, masked tokens etc\n",
        "        masked_mse = mse * mask\n",
        "\n",
        "        # normalize for masked elements\n",
        "        valid = mask.sum()\n",
        "        if valid > 0:\n",
        "            return masked_mse.sum() / valid\n",
        "        else:\n",
        "            return torch.tensor(0.0, device=predictions.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad1faa5f",
      "metadata": {
        "id": "ad1faa5f"
      },
      "outputs": [],
      "source": [
        "class DJMooreSeq(nn.Module):\n",
        "    def __init__(self, embed_size, encoder_layers, decoder_layers,\n",
        "                 max_targets, dropout, nheads, max_step, dev='cuda') -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # general vars\n",
        "        self.embedding_size = embed_size\n",
        "        self.max_targets = max_targets\n",
        "        self.device = dev\n",
        "\n",
        "        # context cnn\n",
        "        self.context_cnn = CNN_DownSample()\n",
        "        context_cnn_output = 64* 7 * 16\n",
        "\n",
        "        # transformer encoder\n",
        "        self.encoder = TransEncoder(input_dim=context_cnn_output,\n",
        "                                    embed_size=embed_size,\n",
        "                                    num_layers=encoder_layers,\n",
        "                                    device=dev,\n",
        "                                    mask=None,\n",
        "                                    dropout=dropout,\n",
        "                                    max_length=150)\n",
        "\n",
        "        # decoder\n",
        "        self.decoder = TransDecoder(target_mask=None,\n",
        "                                    embedding=embed_size,\n",
        "                                    dropout=dropout,\n",
        "                                    nhead=nheads,\n",
        "                                    layers=decoder_layers,\n",
        "                                    max_targets=max_targets,\n",
        "                                    max_step_change=max_step,\n",
        "                                    max_seq_len=max_output)\n",
        "\n",
        "    def forward(self, heatmap_sequence, start_pos, target_mask, future_steps, input_lengths):\n",
        "        # derive batch size, length of transformer output\n",
        "        batch_size, seq_len = heatmap_sequence.shape[:2]\n",
        "        # cnn features\n",
        "        cnn_features = []\n",
        "        for t in range(seq_len):\n",
        "            frame = heatmap_sequence[:,t]\n",
        "            features = self.context_cnn(frame)\n",
        "            features = features.flatten(1)\n",
        "            cnn_features.append(features)\n",
        "\n",
        "        # stack and encode\n",
        "        sequence_feat = torch.stack(cnn_features, dim=1)\n",
        "\n",
        "        # encoder mask based on input seq\n",
        "        max_input_len = seq_len\n",
        "        encoder_mask = torch.zeros(batch_size, max_input_len, device=heatmap_sequence.device, dtype=torch.bool)\n",
        "        for i, length in enumerate(input_lengths):\n",
        "            encoder_mask[i, :length] = True\n",
        "\n",
        "        # context\n",
        "        encoded_context = self.encoder(sequence_feat, encoder_mask)\n",
        "        # output predictions\n",
        "        predictions = self.decoder(encoded_context, start_pos, target_mask, future_steps, input_lengths)\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "883ff497",
      "metadata": {
        "id": "883ff497"
      },
      "source": [
        "##### training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "696a328f",
      "metadata": {
        "id": "696a328f"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, optimizer, scheduler, epochs):\n",
        "  # loss\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  # early stopping\n",
        "  best_loss = np.inf\n",
        "  early_stop_rounds = 0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    # train mode, loss and batches\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    batches = 0\n",
        "\n",
        "    for batch_sequence, batch_targets, batch_masks, batch_start_pos, batch_input_lengths, batch_output_lengths in train_loader:\n",
        "\n",
        "        # move all items to gpu\n",
        "        batch_sequence = batch_sequence.to('cuda')\n",
        "        batch_targets = batch_targets.to('cuda')\n",
        "        batch_masks = batch_masks.to('cuda')\n",
        "        batch_start_pos = batch_start_pos.to('cuda')\n",
        "        batch_input_lengths = batch_input_lengths.to('cuda')\n",
        "        batch_output_lengths = batch_output_lengths.to('cuda')\n",
        "\n",
        "        # zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        predictions = model(batch_sequence, batch_start_pos, batch_masks,\n",
        "                            batch_output_lengths, batch_input_lengths)\n",
        "\n",
        "        # masks for loss function\n",
        "        _, _, pred_len, _ = predictions.shape\n",
        "        batch_size, _, targ_len, _ = batch_targets.shape\n",
        "        max_seq_len = min(pred_len, targ_len)\n",
        "\n",
        "        # consitent sizing\n",
        "        predictions_sliced = predictions[:, :, :max_seq_len, :]\n",
        "        batch_targets_sliced = batch_targets[:, :, :max_seq_len, :]\n",
        "        batch_masks_sliced = batch_masks[:, :max_seq_len]\n",
        "\n",
        "        # slice preds to correct len\n",
        "        len_mask = torch.zeros(batch_size, max_seq_len, device=predictions_sliced.device, dtype=torch.bool)\n",
        "\n",
        "        for i, length in enumerate(batch_output_lengths):\n",
        "            len_mask[i, :length] = True\n",
        "\n",
        "        # masks\n",
        "        target_mask_expanded = batch_masks_sliced.unsqueeze(-1).unsqueeze(-1)\n",
        "        length_mask_expanded = len_mask.unsqueeze(1).unsqueeze(-1)\n",
        "        combined_mask = target_mask_expanded * length_mask_expanded\n",
        "\n",
        "        # train loss\n",
        "        loss = mse_with_length_mask(predictions_sliced, batch_targets_sliced, combined_mask.expand_as(predictions_sliced))\n",
        "\n",
        "        # backprop\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # epoch loss\n",
        "        epoch_loss += loss.item() * batch_sequence.size(0)\n",
        "        batches += batch_sequence.size(0)\n",
        "\n",
        "    # training losses\n",
        "    avg_loss = epoch_loss / batches\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    # val set losses\n",
        "    model.eval()\n",
        "    val_epoch_loss = 0\n",
        "    val_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_sequence, val_targets, val_masks, val_start_pos, val_input_lengths, val_output_lengths in val_loader:\n",
        "            # to cuda\n",
        "            val_sequence = val_sequence.to('cuda')\n",
        "            val_targets = val_targets.to('cuda')\n",
        "            val_masks = val_masks.to('cuda')\n",
        "            val_start_pos = val_start_pos.to('cuda')\n",
        "            val_input_lengths = val_input_lengths.to('cuda')\n",
        "            val_output_lengths = val_output_lengths.to('cuda')\n",
        "\n",
        "            # predictions and loss on val set\n",
        "            val_predictions = model(val_sequence, val_start_pos, val_masks, val_output_lengths, val_input_lengths)\n",
        "\n",
        "            # size\n",
        "            _, _, pred_len, _ = val_predictions.shape\n",
        "            batch_size, _, targ_len, _ = val_targets.shape\n",
        "            max_seq_len = min(pred_len, targ_len)\n",
        "\n",
        "            # mask for sequences\n",
        "            val_predictions_sliced = val_predictions[:, :, :max_seq_len, :]\n",
        "            val_targ_sliced = val_targets[:, :, :max_seq_len, :]\n",
        "            val_mask_sliced = val_masks[:, :max_seq_len]\n",
        "\n",
        "            length_mask = torch.zeros(batch_size, max_seq_len, device=val_predictions.device, dtype=torch.bool)\n",
        "            for i, length in enumerate(val_output_lengths):\n",
        "                length_mask[i, :length] = True\n",
        "\n",
        "            # masking\n",
        "            target_mask_expanded = val_mask_sliced.unsqueeze(-1).unsqueeze(-1)\n",
        "            length_mask_expanded = length_mask.unsqueeze(1).unsqueeze(-1)\n",
        "            combined_mask = target_mask_expanded * length_mask_expanded\n",
        "\n",
        "            # Slice targets to match the sequence length of predictions\n",
        "            val_targets_sliced = val_targets[:, :, :max_seq_len, :]\n",
        "\n",
        "            # validtion losses\n",
        "            val_loss = mse_with_length_mask(val_predictions_sliced, val_targets_sliced, combined_mask.expand_as(val_predictions_sliced))\n",
        "            val_epoch_loss += val_loss.item() * val_sequence.size(0)\n",
        "            val_batches += val_sequence.size(0)\n",
        "\n",
        "    # val set losses\n",
        "    val_epoch_loss = val_epoch_loss / val_batches\n",
        "    val_losses.append(val_epoch_loss)\n",
        "\n",
        "    if scheduler is not None:\n",
        "        scheduler.step(val_epoch_loss)\n",
        "\n",
        "    print(f'val_loss {val_epoch_loss}, train_loss {avg_loss}')\n",
        "\n",
        "    # early stopping check\n",
        "    if val_epoch_loss < best_loss:\n",
        "        best_loss = val_epoch_loss\n",
        "        early_stop_rounds = 0\n",
        "        torch.save(model.state_dict(), f\"2500_4_4_4_model{epoch}.pth\")\n",
        "    else:\n",
        "        early_stop_rounds += 1\n",
        "\n",
        "    if early_stop_rounds > 20:\n",
        "        print('early stopping')\n",
        "        return train_losses, val_losses\n",
        "\n",
        "  return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5e595b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5e595b8",
        "outputId": "89c815c7-c8b6-4fa1-fe52-ee4ff500a5c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "36.0\n",
            "106.0\n"
          ]
        }
      ],
      "source": [
        "max_targets = df.groupby(['play_id_n', 'frame_id'])['player_to_predict'].sum().max()\n",
        "max_input = (df['frame_id'] - df['num_frames_output']).max()\n",
        "max_output = (df['num_frames_output']).max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oVkp4HsgHw8j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVkp4HsgHw8j",
        "outputId": "76284f86-deb8-4e2e-f4f4-91af61340a9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_delta 1.4173566946961516\n"
          ]
        }
      ],
      "source": [
        "def calculate_max_delta(df):\n",
        "    max_delta = 0.0\n",
        "    for play_id in df['play_id_n'].unique():\n",
        "        play_data = df[df['play_id_n'] == play_id].sort_values('frame_id')\n",
        "\n",
        "        for nfl_id in play_data['nfl_id'].unique():\n",
        "            player_data = play_data[play_data['nfl_id'] == nfl_id].sort_values('frame_id')\n",
        "            if len(player_data) > 1:\n",
        "                deltas = np.sqrt(np.diff(player_data['x'].values)**2 + np.diff(player_data['y'].values)**2)\n",
        "                if len(deltas) > 0:\n",
        "                    current_max_delta = np.max(deltas)\n",
        "                    max_delta = max(max_delta, current_max_delta)\n",
        "\n",
        "    return max_delta\n",
        "\n",
        "max_delta_value = calculate_max_delta(df)\n",
        "print(f\"max_delta {max_delta_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2ffdfec",
      "metadata": {
        "id": "f2ffdfec"
      },
      "outputs": [],
      "source": [
        "# create dataset instance by instance rather than all at once\n",
        "class NFLSequenceDataset(Dataset):\n",
        "    def __init__(self, df_grids, df_tracking, max_targets, max_input, max_output, split_indices=None):\n",
        "        self.df_grids = df_grids\n",
        "        self.df_tracking = df_tracking\n",
        "        self.max_targets = max_targets\n",
        "        self.max_input = max_input\n",
        "        self.max_output = max_output\n",
        "\n",
        "        # playe_ids\n",
        "        self.play_ids = df_grids['play_id_n'].unique()\n",
        "        if split_indices is not None:\n",
        "            self.play_ids = self.play_ids[split_indices]\n",
        "\n",
        "        # players to predict for each play\n",
        "        self.player_to_predict = df_tracking[df_tracking['player_to_predict'] == True].groupby('play_id_n')['nfl_id'].unique()\n",
        "\n",
        "    def __len__(self):\n",
        "        # how many plays\n",
        "        return len(self.play_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        play_id = self.play_ids[idx]\n",
        "\n",
        "        # data for a given play\n",
        "        play_data = self.df_grids[self.df_grids['play_id_n'] == play_id].sort_values('frame_id')\n",
        "        df_data = self.df_tracking[self.df_tracking['play_id_n'] == play_id]\n",
        "\n",
        "        # seq lengths\n",
        "        total_frames = play_data['frame_id'].max()\n",
        "        output_frames = int(df_data['num_frames_output'].max())\n",
        "        input_seq_len = total_frames - output_frames\n",
        "        output_seq_len = output_frames\n",
        "\n",
        "        # target play ids\n",
        "        if play_id in self.player_to_predict:\n",
        "            players = self.player_to_predict[play_id][:self.max_targets]\n",
        "        else:\n",
        "            players = []\n",
        "\n",
        "        num_receivers = len(players)\n",
        "\n",
        "        # mask for less than max target\n",
        "        mask = torch.zeros(self.max_targets)\n",
        "        mask[:num_receivers] = 1\n",
        "\n",
        "        # input seq\n",
        "        input_grids = []\n",
        "        for i in range(min(input_seq_len, self.max_input)):\n",
        "            grid = torch.from_numpy(play_data['grid'].iloc[i]).float()\n",
        "            noise = torch.randn_like(grid) * 0.0001\n",
        "            input_grids.append(grid + noise)\n",
        "\n",
        "        # pad or truncate as needed\n",
        "        while len(input_grids) < self.max_input:\n",
        "            input_grids.append(torch.zeros_like(input_grids[0]))\n",
        "        input_sequence = torch.stack(input_grids[:self.max_input], dim=0)\n",
        "\n",
        "        # start positons\n",
        "        start_pos = torch.zeros(self.max_targets, 2)\n",
        "        last_frame_id = input_seq_len\n",
        "        last_frame_data = self.df_tracking[\n",
        "            (self.df_tracking['play_id_n'] == play_id) &\n",
        "            (self.df_tracking['frame_id'] == last_frame_id)\n",
        "        ]\n",
        "\n",
        "        # init postions fo start plyer\n",
        "        for i, receiver_id in enumerate(players):\n",
        "            receiver_data = last_frame_data[last_frame_data['nfl_id'] == receiver_id]\n",
        "            if not receiver_data.empty:\n",
        "                x = float(receiver_data['x'].iloc[0]) / 120\n",
        "                y = float(receiver_data['y'].iloc[0]) / 53.3\n",
        "                start_pos[i] = torch.tensor([x, y])\n",
        "\n",
        "        # target seq\n",
        "        output_len = min(output_seq_len, self.max_output)\n",
        "        target_positions = torch.zeros(self.max_targets, self.max_output, 2)\n",
        "\n",
        "        # target postions\n",
        "        for step in range(output_len):\n",
        "            frame_idx = input_seq_len + step\n",
        "            if frame_idx < len(play_data):\n",
        "                target_frame = play_data.iloc[frame_idx]['frame_id']\n",
        "                target_frame_data = self.df_tracking[\n",
        "                    (self.df_tracking['play_id_n'] == play_id) &\n",
        "                    (self.df_tracking['frame_id'] == target_frame)\n",
        "                ]\n",
        "\n",
        "                for i, receiver_id in enumerate(players):\n",
        "                    receiver_data = target_frame_data[target_frame_data['nfl_id'] == receiver_id]\n",
        "                    if not receiver_data.empty:\n",
        "                        x = float(receiver_data['x'].iloc[0]) / 120\n",
        "                        y = float(receiver_data['y'].iloc[0]) / 53.3\n",
        "                        target_positions[i, step] = torch.tensor([x, y])\n",
        "\n",
        "        final_output_len = min(output_len, self.max_output)\n",
        "\n",
        "        return (\n",
        "            input_sequence,\n",
        "            target_positions,\n",
        "            mask,\n",
        "            start_pos,\n",
        "            torch.tensor(min(input_seq_len, self.max_input)),\n",
        "            torch.tensor(final_output_len)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b627e37",
      "metadata": {
        "id": "4b627e37"
      },
      "outputs": [],
      "source": [
        "# split by indexs\n",
        "play_indices = np.arange(len(df_grids['play_id_n'].unique()))\n",
        "train_idx, test_idx = train_test_split(play_indices, test_size=0.3, random_state=26)\n",
        "test_idx, val_idx = train_test_split(test_idx, test_size=0.7, random_state=26)\n",
        "\n",
        "# create the datasets dynamically\n",
        "train_dataset = NFLSequenceDataset(df_grids, df, max_targets, int(max_input), int(max_output), train_idx)\n",
        "val_dataset = NFLSequenceDataset(df_grids, df, max_targets, int(max_input), int(max_output), val_idx)\n",
        "test_dataset = NFLSequenceDataset(df_grids, df, max_targets, int(max_input), int(max_output), test_idx)\n",
        "\n",
        "# create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, drop_last=True, num_workers=3)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=3)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ZnN4jdggoE5",
      "metadata": {
        "id": "8ZnN4jdggoE5"
      },
      "outputs": [],
      "source": [
        "# clean envi\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfa8b6b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfa8b6b1",
        "outputId": "9e95bfbc-7fdf-4379-e717-370c0370abc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_loss 0.7201902161325727, train_loss 0.5552555061535004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_loss 0.021934190418216443, train_loss 0.04879347829857346\n",
            "val_loss 0.02249508662326705, train_loss 0.014003727700424577\n",
            "val_loss 0.02222924214388643, train_loss 0.01345626159075545\n",
            "val_loss 0.023203048568573737, train_loss 0.013043084339913698\n",
            "val_loss 0.02272804965752931, train_loss 0.012274965993128717\n",
            "val_loss 0.022206641427640405, train_loss 0.012353327447856102\n",
            "val_loss 0.023770719586561125, train_loss 0.011801826648004011\n",
            "val_loss 0.023511547085252545, train_loss 0.011968348401709707\n",
            "val_loss 0.022701242178501117, train_loss 0.011412625945463708\n",
            "val_loss 0.020144831647298165, train_loss 0.011385730192184858\n",
            "val_loss 0.02019090379721352, train_loss 0.010782812869415508\n",
            "val_loss 0.016355494230630853, train_loss 0.011013833922334015\n",
            "val_loss 0.019603052658161948, train_loss 0.010741839011268127\n",
            "val_loss 0.020300097972864195, train_loss 0.01057142527654357\n",
            "val_loss 0.01861149156111337, train_loss 0.010205569596952596\n",
            "val_loss 0.020170228707471063, train_loss 0.009858721778557183\n",
            "val_loss 0.01886049755449806, train_loss 0.01003938673145283\n",
            "val_loss 0.016643822939090787, train_loss 0.00968864876264279\n",
            "val_loss 0.01678430263795668, train_loss 0.00956832644222048\n",
            "val_loss 0.01844113821252471, train_loss 0.009294180600015326\n",
            "val_loss 0.017027414944909867, train_loss 0.009289098815958298\n",
            "val_loss 0.015795296712645464, train_loss 0.009244595761111843\n",
            "val_loss 0.01568872597068548, train_loss 0.00911006725333426\n",
            "val_loss 0.01600937974772283, train_loss 0.009136049892890071\n",
            "val_loss 0.015058944586753135, train_loss 0.009015840970603492\n",
            "val_loss 0.014321481501240105, train_loss 0.008704632602914006\n",
            "val_loss 0.015861846339401034, train_loss 0.008804692963667966\n",
            "val_loss 0.015784340071979732, train_loss 0.00849404173087192\n",
            "val_loss 0.01514747448620342, train_loss 0.008434271700509371\n",
            "val_loss 0.015020331655673328, train_loss 0.008552345122560995\n",
            "val_loss 0.015309521082256522, train_loss 0.008214872872986652\n",
            "val_loss 0.015433318140872178, train_loss 0.00820555536657435\n",
            "val_loss 0.015626747007703497, train_loss 0.008418240303541064\n",
            "val_loss 0.014100828865276915, train_loss 0.008149641554230192\n",
            "val_loss 0.015415659780126243, train_loss 0.008000550808709695\n",
            "val_loss 0.014010275020042345, train_loss 0.007758255635704332\n",
            "val_loss 0.014634434687239782, train_loss 0.007929013704522214\n",
            "val_loss 0.014488513206708289, train_loss 0.007722573931576735\n",
            "val_loss 0.015740046145483143, train_loss 0.007703688263747875\n",
            "val_loss 0.014634942861628674, train_loss 0.007749234506680946\n",
            "val_loss 0.014734727236486616, train_loss 0.007686526197384735\n",
            "val_loss 0.013679928020795895, train_loss 0.007467275266450138\n",
            "val_loss 0.012209166765567802, train_loss 0.007639684774186633\n",
            "val_loss 0.013562640570813701, train_loss 0.007444280210386859\n",
            "val_loss 0.015020604315435603, train_loss 0.007399641165356023\n",
            "val_loss 0.01371815254956129, train_loss 0.007407263986159697\n",
            "val_loss 0.014107522346256745, train_loss 0.00722147041286658\n",
            "val_loss 0.013412102551332543, train_loss 0.007204163332529571\n",
            "val_loss 0.01314813313650943, train_loss 0.007086237671426198\n",
            "val_loss 0.012021991235780575, train_loss 0.007055816153030193\n",
            "val_loss 0.013714826488867403, train_loss 0.0070332733918528215\n",
            "val_loss 0.01323260557438646, train_loss 0.007002889391231359\n",
            "val_loss 0.012803276095184541, train_loss 0.007087092496318008\n",
            "val_loss 0.012208193246984765, train_loss 0.006782276626385817\n",
            "val_loss 0.01281391373392017, train_loss 0.006740815403503836\n",
            "val_loss 0.0128552529747997, train_loss 0.006881431594209045\n",
            "val_loss 0.01248278803059033, train_loss 0.0067987034915425225\n",
            "val_loss 0.012583583815112001, train_loss 0.00684178623887753\n",
            "val_loss 0.012960398658843977, train_loss 0.006675192913245581\n",
            "val_loss 0.012360307137881006, train_loss 0.00650129003082872\n",
            "val_loss 0.012018133008497812, train_loss 0.006624224196282139\n",
            "val_loss 0.01116833732374722, train_loss 0.006499477271246937\n",
            "val_loss 0.01215441760296623, train_loss 0.006389609289167602\n",
            "val_loss 0.01306770195164496, train_loss 0.006555865497388151\n",
            "val_loss 0.012448469763178201, train_loss 0.006429153806401775\n",
            "val_loss 0.012013974260716211, train_loss 0.006275142704290466\n",
            "val_loss 0.012729180865876731, train_loss 0.006371957752981796\n",
            "val_loss 0.012505385645088695, train_loss 0.0062797852672226385\n",
            "val_loss 0.011935017705407171, train_loss 0.0062618337789499155\n",
            "val_loss 0.011654303912960347, train_loss 0.006063031132008299\n",
            "val_loss 0.012049119313735337, train_loss 0.006079390290441042\n",
            "val_loss 0.01278576066495762, train_loss 0.006069346554278302\n",
            "val_loss 0.012036254870749654, train_loss 0.006212490495965056\n",
            "val_loss 0.0113523086954263, train_loss 0.0061468898496001\n",
            "val_loss 0.011848189773570213, train_loss 0.006260023921206935\n",
            "val_loss 0.011010782261423413, train_loss 0.006118191736686223\n",
            "val_loss 0.011050939497848352, train_loss 0.006064590486407348\n",
            "val_loss 0.011191998138314202, train_loss 0.0060378037614175414\n",
            "val_loss 0.011545447468580234, train_loss 0.005976091368645088\n",
            "val_loss 0.01076885200327351, train_loss 0.005887222419697962\n",
            "val_loss 0.01105703469099743, train_loss 0.005852602939164147\n",
            "val_loss 0.010560784864549836, train_loss 0.005916611457012867\n",
            "val_loss 0.01168089516239152, train_loss 0.005843788724490912\n",
            "val_loss 0.011260934231714124, train_loss 0.005682800078354434\n",
            "val_loss 0.010117920343098896, train_loss 0.005844575704882827\n",
            "val_loss 0.010502000086098199, train_loss 0.005756187116526443\n",
            "val_loss 0.01037987627044675, train_loss 0.005790516310115131\n",
            "val_loss 0.011830933823560675, train_loss 0.005672717838625022\n",
            "val_loss 0.010956891799079521, train_loss 0.005758634847994689\n",
            "val_loss 0.010713661780048693, train_loss 0.005644620611404983\n",
            "val_loss 0.010456358313205696, train_loss 0.005618421864426703\n",
            "val_loss 0.010211157160589382, train_loss 0.005838310198085127\n",
            "val_loss 0.011900610246119044, train_loss 0.00547723430251583\n",
            "val_loss 0.010678661035462503, train_loss 0.005698452157891193\n",
            "val_loss 0.00979976260591121, train_loss 0.005441285211618545\n",
            "val_loss 0.010640881936110201, train_loss 0.005664824569542303\n",
            "val_loss 0.010911851443705104, train_loss 0.0055176467739404475\n",
            "val_loss 0.010525978472349899, train_loss 0.005326461927525255\n",
            "val_loss 0.010817645842298156, train_loss 0.0055503751158739924\n",
            "val_loss 0.011009990473144821, train_loss 0.0054342353341613955\n",
            "val_loss 0.009792761520615647, train_loss 0.005553162278107649\n",
            "val_loss 0.010792473056131886, train_loss 0.005556726717676352\n",
            "val_loss 0.010099752479720683, train_loss 0.005414956280803564\n",
            "val_loss 0.01033354969916954, train_loss 0.00545582193731749\n",
            "val_loss 0.009146230105044586, train_loss 0.005554110870201038\n",
            "val_loss 0.009996912371189822, train_loss 0.005409717470633908\n",
            "val_loss 0.009574139935984497, train_loss 0.005429181834221433\n",
            "val_loss 0.009296911261266185, train_loss 0.005465358056751755\n",
            "val_loss 0.0097951578486356, train_loss 0.005377224882543429\n",
            "val_loss 0.010233856702134723, train_loss 0.005200507085655021\n",
            "val_loss 0.00998197101322668, train_loss 0.005376763169764789\n",
            "val_loss 0.010226325989656506, train_loss 0.005299544375210385\n",
            "val_loss 0.009772351025825455, train_loss 0.0052202900213727714\n",
            "val_loss 0.01063612356294124, train_loss 0.005220639758098255\n",
            "val_loss 0.010188339803190458, train_loss 0.0051993906968956765\n",
            "val_loss 0.010669000221505052, train_loss 0.005189698495487725\n",
            "val_loss 0.010051839442125388, train_loss 0.005092340448354328\n",
            "val_loss 0.00940660575005625, train_loss 0.005291532393472286\n",
            "val_loss 0.010108907934987829, train_loss 0.005287462193946089\n",
            "val_loss 0.00981845750429091, train_loss 0.005095346906081423\n",
            "val_loss 0.010249143337298717, train_loss 0.0051812651196554505\n",
            "val_loss 0.010123263300352153, train_loss 0.0049629127232938865\n",
            "val_loss 0.010553746954316184, train_loss 0.005115749264763958\n",
            "val_loss 0.009619091746530363, train_loss 0.005106915114767884\n",
            "val_loss 0.010112994606384918, train_loss 0.005147753437711866\n",
            "val_loss 0.010415360033512115, train_loss 0.00519250301748873\n",
            "early stopping\n"
          ]
        }
      ],
      "source": [
        "# model\n",
        "model = DJMooreSeq(embed_size=64, encoder_layers=4, decoder_layers=4, max_targets=max_targets, max_step=1.4, dropout=0.1, nheads=4,dev='cuda').to('cuda')\n",
        "\n",
        "# epochs\n",
        "epochs = 1000\n",
        "\n",
        "# loss, opti, schedu\n",
        "loss_func = MaskedSequenceLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.001)\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=5,  num_training_steps=epochs)\n",
        "\n",
        "# train\n",
        "train_losses, val_losses = train(model, train_loader, val_loader, optimizer, scheduler, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EVLza1gx0Ffa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "collapsed": true,
        "id": "EVLza1gx0Ffa",
        "outputId": "623d3fad-6983-4eb4-e14b-b0c70357f67c"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (43) must match the size of tensor b (36) at non-singleton dimension 2",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-288702145.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Loss: {test_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-288702145.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mbatch_targets_sliced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_targets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_with_length_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_targets_sliced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1040114774.py\u001b[0m in \u001b[0;36mmse_with_length_mask\u001b[0;34m(predictions, targets, combined_mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# loss with mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmse_with_length_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mmasked_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (43) must match the size of tensor b (36) at non-singleton dimension 2"
          ]
        }
      ],
      "source": [
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_sequence, batch_targets, batch_masks, batch_start_pos, batch_input_lengths, batch_output_lengths in test_loader:\n",
        "            batch_sequence = batch_sequence.to('cuda')\n",
        "            batch_targets = batch_targets.to('cuda')\n",
        "            batch_masks = batch_masks.to('cuda')\n",
        "            batch_start_pos = batch_start_pos.to('cuda')\n",
        "            batch_input_lengths = batch_input_lengths.to('cuda')\n",
        "            batch_output_lengths = batch_output_lengths.to('cuda')\n",
        "\n",
        "            predictions = model(batch_sequence, batch_start_pos, batch_masks,\n",
        "                                batch_output_lengths, batch_input_lengths)\n",
        "\n",
        "            batch_size, _, max_seq_len, _ = predictions.shape\n",
        "            len_mask = torch.zeros(batch_size, max_seq_len, device=predictions.device, dtype=torch.bool)\n",
        "            for i, length in enumerate(batch_output_lengths):\n",
        "                len_mask[i, :length] = True\n",
        "\n",
        "            target_mask_expanded = batch_masks.unsqueeze(-1).unsqueeze(-1)\n",
        "            length_mask_expanded = len_mask.unsqueeze(1).unsqueeze(-1)\n",
        "            combined_mask = target_mask_expanded * length_mask_expanded\n",
        "\n",
        "            batch_targets_sliced = batch_targets[:, :, :max_seq_len, :]\n",
        "            loss = mse_with_length_mask(predictions, batch_targets_sliced, combined_mask.expand_as(predictions))\n",
        "\n",
        "            total_loss += loss.item() * batch_sequence.size(0)\n",
        "            total_batches += batch_sequence.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "test_loss = test(model, test_loader)\n",
        "print(f'Test Loss: {test_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rTYw9BR_0Sms",
      "metadata": {
        "collapsed": true,
        "id": "rTYw9BR_0Sms"
      },
      "outputs": [],
      "source": [
        "def visualize_predictions(model, data_loader, play_idx=0, target_player_idx=0):\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_sequence, batch_targets, batch_masks, batch_start_pos, batch_input_lengths, batch_output_lengths in data_loader:\n",
        "            batch_sequence = batch_sequence.to('cuda')\n",
        "            batch_targets = batch_targets.to('cuda')\n",
        "            batch_masks = batch_masks.to('cuda')\n",
        "            batch_start_pos = batch_start_pos.to('cuda')\n",
        "            batch_input_lengths = batch_input_lengths.to('cuda')\n",
        "            batch_output_lengths = batch_output_lengths.to('cuda')\n",
        "\n",
        "\n",
        "            predictions = model(batch_sequence, batch_start_pos, batch_masks,\n",
        "                                batch_output_lengths, batch_input_lengths)\n",
        "\n",
        "            predicted_trajectory = predictions[play_idx, target_player_idx, :, :].cpu().numpy()\n",
        "            actual_trajectory = batch_targets[play_idx, target_player_idx, :, :].cpu().numpy()\n",
        "            mask = batch_masks[play_idx, target_player_idx].cpu().numpy()\n",
        "            output_length = batch_output_lengths[play_idx].cpu().numpy()\n",
        "\n",
        "\n",
        "            predicted_trajectory = predicted_trajectory[:output_length]\n",
        "            actual_trajectory = actual_trajectory[:output_length]\n",
        "\n",
        "            predicted_trajectory[:, 0] *= 120\n",
        "            predicted_trajectory[:, 1] *= 53.3\n",
        "            actual_trajectory[:, 0] *= 120\n",
        "            actual_trajectory[:, 1] *= 53.3\n",
        "\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(actual_trajectory[:, 0], actual_trajectory[:, 1], marker='o', linestyle='-', color='blue', label='Actual')\n",
        "            plt.plot(predicted_trajectory[:, 0], predicted_trajectory[:, 1], marker='x', linestyle='--', color='red', label='Predicted')\n",
        "            plt.xlabel('X Coordinate (yards)')\n",
        "            plt.ylabel('Y Coordinate (yards)')\n",
        "            plt.title(f'Predicted vs Actual Trajectory for Play {play_idx}, Target Player {target_player_idx}')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "            break\n",
        "\n",
        "visualize_predictions(model, test_loader, play_idx=5, target_player_idx=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q8mlriTipxjL",
      "metadata": {
        "id": "q8mlriTipxjL"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"2500_4_4_4_model.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "eb3b0c43"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nflLab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
