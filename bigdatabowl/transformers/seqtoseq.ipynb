{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a9cccd1d",
      "metadata": {
        "id": "a9cccd1d"
      },
      "source": [
        "# Using a Transformer to Predict NFL Player Movements"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "331ac290",
      "metadata": {
        "id": "331ac290"
      },
      "source": [
        "#### Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4ef573e",
      "metadata": {
        "id": "d4ef573e"
      },
      "source": [
        "##### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e9b4M7YS2sh4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9b4M7YS2sh4",
        "outputId": "4341de58-e34a-420a-aba1-b896cc753d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "882c941d",
      "metadata": {
        "collapsed": true,
        "id": "882c941d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/databowl/')\n",
        "df = pd.read_csv('2023_tracking.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5960ee90",
      "metadata": {
        "id": "5960ee90"
      },
      "outputs": [],
      "source": [
        "play_ids = df['play_id_n'].unique()[2000:4500]\n",
        "df = df[df['play_id_n'].isin(play_ids)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40823073",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40823073",
        "outputId": "d9ecb57a-5919-4c70-8db5-48abb51a2809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "max_targets = df.groupby(['play_id_n', 'frame_id'])['player_to_predict'].sum().max()\n",
        "print(max_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb3b0c43",
      "metadata": {
        "id": "eb3b0c43"
      },
      "source": [
        "##### Tabular to Pixel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7bdcf7e",
      "metadata": {
        "id": "c7bdcf7e"
      },
      "outputs": [],
      "source": [
        "def pixel_map(player_data, target_player_ids, max_targets, grid_width=121, grid_height=55, sigma=.8):\n",
        "\n",
        "    num_channels = 2 + max_targets + 1\n",
        "    # three channels, one for offense, one for defense, one for ball location, one for player to predict\n",
        "    pixel_map = np.zeros((num_channels, grid_height, grid_width), dtype=np.float32)\n",
        "\n",
        "    x_vals = player_data['x'].values\n",
        "    y_vals = player_data['y'].values\n",
        "\n",
        "    for i, (x, y) in enumerate(zip(x_vals, y_vals)):\n",
        "        x_min = max(0, int(np.floor(x - 2*sigma)))\n",
        "        x_max = min(grid_width, int(np.ceil(x + 2*sigma)) + 1)\n",
        "        y_min = max(0, int(np.floor(y - 2*sigma)))\n",
        "        y_max = min(grid_height, int(np.ceil(y + 2*sigma)) + 1)\n",
        "\n",
        "        for xi in range(x_min, x_max):\n",
        "            for yi in range(y_min, y_max):\n",
        "                dist_sq = (xi - x)**2 + (yi - y)**2\n",
        "                weight = np.exp(-dist_sq / (2 * sigma**2))\n",
        "\n",
        "                player_id = player_data.iloc[i].get('nfl_id', None)\n",
        "\n",
        "                if player_id in target_player_ids:\n",
        "                    target_idx = target_player_ids.index(player_id)\n",
        "                    if target_idx < max_targets: # to prevent error\n",
        "                        pixel_map[2 + target_idx, yi, xi] += weight\n",
        "                elif player_data.iloc[i]['player_side'] == 'Offense':\n",
        "                    pixel_map[0, yi, xi] += weight\n",
        "                elif player_data.iloc[i]['player_side'] == 'Defense':\n",
        "                    pixel_map[1, yi, xi] += weight\n",
        "\n",
        "\n",
        "    ball_x = player_data['ball_land_x'].iloc[0]\n",
        "    ball_y = player_data['ball_land_y'].iloc[0]\n",
        "\n",
        "    ball_x_min = max(0, int(np.floor(ball_x - 2*sigma)))\n",
        "    ball_x_max = min(grid_width, int(np.ceil(ball_x + 2*sigma)) + 1)\n",
        "    ball_y_min = max(0, int(np.floor(ball_y - 2*sigma)))\n",
        "    ball_y_max = min(grid_height, int(np.ceil(ball_y + 2*sigma)) + 1)\n",
        "\n",
        "    for xi in range(ball_x_min, ball_x_max):\n",
        "        for yi in range(ball_y_min, ball_y_max):\n",
        "            dist_sq = (xi - ball_x)**2 + (yi - ball_y)**2\n",
        "            weight = np.exp(-dist_sq / (2 * sigma**2))\n",
        "            pixel_map[2 + max_targets, yi, xi] += weight\n",
        "\n",
        "    return pixel_map"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fdb8c7f",
      "metadata": {
        "id": "5fdb8c7f"
      },
      "source": [
        "testing one play"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a45368c4",
      "metadata": {
        "id": "a45368c4",
        "outputId": "666b0591-43c3-4c9a-dbb5-635116ef356c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dalto\\AppData\\Local\\Temp\\ipykernel_25552\\2474093878.py:3: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_grids_t = df_play_id.groupby(['play_id_n','frame_id']).apply(\n"
          ]
        }
      ],
      "source": [
        "df_play_id = df[df['play_id_n'] == 456]\n",
        "target_player_ids = df_play_id[df_play_id['player_to_predict'] == True]['nfl_id'].unique().tolist()\n",
        "df_grids_t = df_play_id.groupby(['play_id_n','frame_id']).apply(\n",
        "    lambda x: pd.Series({'grid': pixel_map(x, target_player_ids, max_targets)})\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84373868",
      "metadata": {
        "id": "84373868"
      },
      "source": [
        "grid for all plays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fbb8477",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fbb8477",
        "outputId": "ba7bfdee-fb54-40de-c9cd-6a5a32a8980e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3746108319.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_grids = df.groupby(['play_id_n','frame_id']).apply(\n"
          ]
        }
      ],
      "source": [
        "df_grids = df.groupby(['play_id_n','frame_id']).apply(\n",
        "    lambda x: pd.Series({'grid': pixel_map(x,  x[x['player_to_predict'] == True]['nfl_id'].unique().tolist(), max_targets)})\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9189e025",
      "metadata": {
        "id": "9189e025"
      },
      "outputs": [],
      "source": [
        "df_grids = df_grids.reset_index()\n",
        "df_grids = df_grids.sort_values(['play_id_n', 'frame_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fe42dca",
      "metadata": {
        "id": "8fe42dca"
      },
      "source": [
        "visual test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35e0b800",
      "metadata": {
        "id": "35e0b800"
      },
      "outputs": [],
      "source": [
        "sample_grid = df_grids_t['grid'].iloc[30]\n",
        "\n",
        "# Count how many target player channels have data\n",
        "num_targets = 0\n",
        "for i in range(max_targets):\n",
        "    if sample_grid[2 + i].sum() > 0:\n",
        "        num_targets += 1\n",
        "\n",
        "# Create subplots: 2 base channels + ball + target players\n",
        "total_plots = 3 + num_targets\n",
        "cols = 4\n",
        "rows = (total_plots + cols - 1) // cols\n",
        "\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(14, 5*rows))\n",
        "axes = axes.flatten() if total_plots > 1 else [axes]\n",
        "\n",
        "# Plot offense\n",
        "axes[0].imshow(sample_grid[0], origin='lower', cmap='Reds')\n",
        "axes[0].set_title('Offense Players')\n",
        "axes[0].set_xlabel('X (yards)')\n",
        "axes[0].set_ylabel('Y (yards)')\n",
        "\n",
        "# Plot defense\n",
        "axes[1].imshow(sample_grid[1], origin='lower', cmap='Blues')\n",
        "axes[1].set_title('Defense Players')\n",
        "axes[1].set_xlabel('X (yards)')\n",
        "axes[1].set_ylabel('Y (yards)')\n",
        "\n",
        "# Plot ball location (at index 2 + max_targets)\n",
        "axes[2].imshow(sample_grid[2 + max_targets], origin='lower', cmap='Purples')\n",
        "axes[2].set_title('Ball Landing Location')\n",
        "axes[2].set_xlabel('X (yards)')\n",
        "axes[2].set_ylabel('Y (yards)')\n",
        "\n",
        "# Plot each target player (channels 2 through 2+max_targets-1)\n",
        "plot_idx = 3\n",
        "for i in range(max_targets):\n",
        "    if sample_grid[2 + i].sum() > 0:\n",
        "        axes[plot_idx].imshow(sample_grid[2 + i], origin='lower', cmap='Greens')\n",
        "        axes[plot_idx].set_title(f'Target Player {i+1}')\n",
        "        axes[plot_idx].set_xlabel('X (yards)')\n",
        "        axes[plot_idx].set_ylabel('Y (yards)')\n",
        "        plot_idx += 1\n",
        "\n",
        "for idx in range(total_plots, len(axes)):\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3e99f11",
      "metadata": {
        "id": "c3e99f11"
      },
      "outputs": [],
      "source": [
        "df_grids.to_pickle(\"full_grids_2500.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adae6a33",
      "metadata": {
        "id": "adae6a33"
      },
      "source": [
        "### Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b67e7a",
      "metadata": {
        "id": "69b67e7a"
      },
      "source": [
        "##### Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1cc55cbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1cc55cbb",
        "outputId": "ee8a7837-ebe2-4703-a7ff-675b86aa8752"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79e6a9c62430>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.functional as F\n",
        "import gc\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "df_grids = pd.read_pickle(\"full_grids_2500.pkl\")\n",
        "torch.manual_seed(26)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c6635c9",
      "metadata": {
        "id": "7c6635c9"
      },
      "source": [
        "##### Inital Params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "663f7b76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "663f7b76",
        "outputId": "210b88db-3517-4d23-b370-1c5c5c9b0e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "106\n",
            "36\n"
          ]
        }
      ],
      "source": [
        "max_targets = int(df.groupby(['play_id_n', 'frame_id'])['player_to_predict'].sum().max())\n",
        "max_input = int((df['frame_id'] - df['num_frames_output']).max())\n",
        "max_output = int((df['num_frames_output']).max())\n",
        "print(max_targets)\n",
        "print(max_input)\n",
        "print(max_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a399299f",
      "metadata": {
        "id": "a399299f"
      },
      "source": [
        "##### Time Encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c509a20a",
      "metadata": {
        "id": "c509a20a"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_size, dropout, max_length=150):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        # droput\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # create matrix\n",
        "        pe = torch.zeros(max_length, embed_size)\n",
        "\n",
        "        # position tensor shape\n",
        "        position = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # div_term tensor shape\n",
        "        div_term = torch.exp(torch.arange(0, embed_size, 2).float() * (-torch.log(torch.tensor(10000.0)) / embed_size))\n",
        "\n",
        "        # apply sin to even indices\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        # apply cos to odd indices\n",
        "        if embed_size % 2 == 1:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term[:-1])\n",
        "        else:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # register as buffer so it moves with model to device\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        pe_slice = self.pe[:x.size(1), :].to(x.device)\n",
        "        x = x + pe_slice\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "889addf7",
      "metadata": {
        "id": "889addf7"
      },
      "source": [
        "##### Player Positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c9266a40",
      "metadata": {
        "id": "c9266a40"
      },
      "outputs": [],
      "source": [
        "class PlayerPositionEmbedding(nn.Module):\n",
        "    def __init__(self, embed_size, max_targets, num_positions = 17):\n",
        "        super().__init__() # Added parentheses here\n",
        "        self.embed_size = embed_size\n",
        "\n",
        "        self.position_projection = nn.Embedding(num_positions, embed_size)\n",
        "    def forward(self, player_positons, target_masks):\n",
        "        # ints to learnable embedding space\n",
        "        pos_embeds = self.position_projection(player_positons.long().squeeze(-1))\n",
        "\n",
        "        # target mask, ignore padded values\n",
        "        target_mask_expand = target_masks.unsqueeze(-1).expand_as(pos_embeds)\n",
        "        pos_embeds = pos_embeds * target_mask_expand.float()\n",
        "\n",
        "        return pos_embeds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd980b7c",
      "metadata": {
        "id": "bd980b7c"
      },
      "source": [
        "##### Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e8d6455d",
      "metadata": {
        "id": "e8d6455d"
      },
      "outputs": [],
      "source": [
        "class CNN_DownSample(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # variable based on amount of targets\n",
        "        input_chan = 2 + max_targets + 1\n",
        "\n",
        "        # using stride rather than max pooling preforms better as max pooling tends to compress feat. too much.\n",
        "        self.heatmap_encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_chan, out_channels=16, kernel_size=3, stride = 2, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride = 2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride = 2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride = 2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.GELU()\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.heatmap_encoder(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f884d25",
      "metadata": {
        "id": "6f884d25"
      },
      "source": [
        "##### MHA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1b4da6b9",
      "metadata": {
        "id": "1b4da6b9"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, nhead, mask, dropout=0.15):\n",
        "        super().__init__() # inhert from parent class\n",
        "\n",
        "        if d_model % nhead != 0:\n",
        "            raise ValueError(f\"d_model ({d_model}) must be divisible by nhead ({nhead})\")\n",
        "\n",
        "        self.d_model = d_model # dimension of model\n",
        "        self.nhead = nhead # number of attention heads, multi headed\n",
        "        self.head_dim = d_model // nhead\n",
        "\n",
        "        # create key query and values\n",
        "        self.qkv_proj = nn.Linear(d_model, 3 * d_model)\n",
        "        # learn context as a product of the attention heads\n",
        "        self.out_proj = nn.Linear(d_model, d_model)\n",
        "        # dropout as a form of regularzation\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # scaling function\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        B, L, _ = x.shape # batch and length\n",
        "\n",
        "        # create q, k, v values | init just random matrix mults, learned parameter\n",
        "        x_fp32 = x.float()\n",
        "        qkv = self.qkv_proj(x_fp32) # use full percison for attention calculations\n",
        "\n",
        "        # split key, query, and value vectors into diff pares\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "\n",
        "        # transpose the matrix so that batch and nhead are treated as batches and self attention is calculated from there\n",
        "        q = q.view(B, L, self.nhead, self.head_dim).transpose(1, 2)\n",
        "        k = k.view(B, L, self.nhead, self.head_dim).transpose(1, 2)\n",
        "        v = v.view(B, L, self.nhead, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # scaled dot product, scale so values arent 0 or 1\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale # matrix mult\n",
        "\n",
        "        # set masked values to -inf so softmax does not \"give\" attention to them\n",
        "        if mask is not None:\n",
        "          if mask.dim() == 2:\n",
        "            mask = mask.expand(B, self.nhead, L, L)\n",
        "          elif mask.dim() == 3:\n",
        "            mask = mask.unsqueeze(1)\n",
        "            mask = mask.expand(B, self.nhead, L, L)\n",
        "          elif mask.dim() == 4:\n",
        "            mask = mask.expand(B, self.nhead, L, L)\n",
        "\n",
        "          scores = scores.masked_fill(mask == 0, torch.finfo(scores.dtype).min) # ignore masked values\n",
        "\n",
        "        # softmax to give attention weights to each token\n",
        "        attn_weights = torch.softmax(scores, dim=-1)\n",
        "\n",
        "        # drop some weights\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # context vector for a given input sequence\n",
        "        context = torch.matmul(attn_weights, v)\n",
        "\n",
        "        # transpose so the matrix is in the correct size to be concatinated\n",
        "        context = context.transpose(1, 2).contiguous().view(B, L, self.d_model)\n",
        "\n",
        "        # \"combine\" the outputs from the head to one general vector\n",
        "        output = self.out_proj(context)\n",
        "\n",
        "        return output.to(x.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee94df07",
      "metadata": {
        "id": "ee94df07"
      },
      "source": [
        "transformer block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "445638fb",
      "metadata": {
        "id": "445638fb"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, nhead=4, mask=None, dropout=0.15):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        # self attention class definied above\n",
        "        self.self_attn = MultiHeadAttention(d_model=d_model, nhead=nhead, dropout=dropout, mask=mask)\n",
        "\n",
        "        # feed forward network for each token\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model*2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout), # to combat overfitting\n",
        "            nn.Linear(d_model*2, d_model)\n",
        "        )\n",
        "\n",
        "        # normilzations so values are between 0-1, learned gamma and beta parameters\n",
        "        # to shift center and var for values.\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # standard dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        residual = x\n",
        "        # normalized pre attention layer, gradients flow black directly without the normalizing effecting x values\n",
        "        norm_x = self.norm1(x)\n",
        "        # self attention\n",
        "        attn_output = self.self_attn(norm_x, mask)\n",
        "        # adding residual back to self attention\n",
        "        x = residual + self.dropout(attn_output)\n",
        "\n",
        "        residual = x\n",
        "        # normalize values\n",
        "        # we do so because over the amount of layers scale can get distorted, lead to super big or small values\n",
        "        norm_x = self.norm2(x)\n",
        "        # basic fcn\n",
        "        ff_output = self.feed_forward(norm_x)\n",
        "        # adding residual back so that the gradient can flow directly back.\n",
        "        # adds a 1 + terms to gradients, helps solve the vanishing gradients problem\n",
        "        x = residual + self.dropout(ff_output)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f52a344",
      "metadata": {
        "id": "2f52a344"
      },
      "source": [
        "Encoder Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fb6e6e4c",
      "metadata": {
        "id": "fb6e6e4c"
      },
      "outputs": [],
      "source": [
        "class TransEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, embed_size, num_layers, nhead, device, dropout, mask, max_length):\n",
        "        super(TransEncoder, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.device = device\n",
        "\n",
        "        # learned matrix projection\n",
        "        self.input_projection = nn.Linear(input_dim, embed_size)\n",
        "        # postional encoding\n",
        "        self.position_encoding = PositionalEncoding(embed_size, dropout, max_length)\n",
        "        # layers of model, just stacked encoding layer\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                TransformerBlock(\n",
        "                    embed_size,\n",
        "                    mask=mask,\n",
        "                    nhead=nhead, # number of attention heads\n",
        "                    dropout=dropout\n",
        "                )\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "        # normalize after attention\n",
        "        self.norm = nn.LayerNorm(embed_size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # input layer matrix mult\n",
        "        projected_input = self.input_projection(x)\n",
        "        # position encodings\n",
        "        out = self.position_encoding(projected_input)\n",
        "        # mask to correct dim\n",
        "        mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "        # pass through transformer block\n",
        "        for layer in self.layers:\n",
        "            out = layer(out, mask)\n",
        "        # normalize gradients\n",
        "        out = self.norm(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61374dbf",
      "metadata": {
        "id": "61374dbf"
      },
      "source": [
        "##### Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0bb3bc89",
      "metadata": {
        "id": "0bb3bc89"
      },
      "outputs": [],
      "source": [
        "# prevent lookahead\n",
        "def create_causal_mask(seq_len, device):\n",
        "    mask = torch.tril(torch.ones(seq_len, seq_len, device=device))\n",
        "    return mask.bool()\n",
        "\n",
        "# seq mask to deal with padded values\n",
        "def seq_maks(input_lengths, max_input, device):\n",
        "    batch_size = len(input_lengths)\n",
        "    input_mask = torch.zeros(batch_size, max_input, device=device, dtype=torch.bool)\n",
        "    for i, length in enumerate(input_lengths):\n",
        "        input_mask[i, :length] = True\n",
        "\n",
        "# loss with mask\n",
        "def mse_with_length_mask(predictions, targets, combined_mask):\n",
        "    mse = (predictions - targets) ** 2\n",
        "    masked_mse = mse * combined_mask.float()\n",
        "\n",
        "    valid_elements = combined_mask.sum()\n",
        "\n",
        "    if valid_elements > 0:\n",
        "        return masked_mse.sum() / valid_elements\n",
        "    else:\n",
        "        return torch.tensor(0.0, device=predictions.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2d1449e",
      "metadata": {
        "id": "b2d1449e"
      },
      "source": [
        "##### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e5fada4f",
      "metadata": {
        "id": "e5fada4f"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, dropout, embedding, nhead):\n",
        "        super().__init__()\n",
        "        # attention layers\n",
        "        self.attention_self = MultiHeadAttention(d_model=embedding, nhead=4, mask=None, dropout=dropout)\n",
        "\n",
        "        # cross atten, query values, info\n",
        "        self.cross_q_proj = nn.Linear(embedding, embedding)\n",
        "        self.cross_k_proj = nn.Linear(embedding, embedding)\n",
        "        self.cross_v_proj =  nn.Linear(embedding, embedding)\n",
        "        self.cross_out_proj = nn.Linear(embedding, embedding)\n",
        "\n",
        "        self.nhead = nhead\n",
        "        self.head_dim = embedding // nhead\n",
        "        self.scale = self.head_dim ** -0.5 # 1/sqrt(dk)\n",
        "\n",
        "        # layer normal\n",
        "        self.norm1 = nn.LayerNorm(embedding)\n",
        "        self.norm2 = nn.LayerNorm(embedding)\n",
        "        self.norm3 = nn.LayerNorm(embedding)\n",
        "\n",
        "        # droput\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # fcnn\n",
        "        self.fcnn = nn.Sequential(\n",
        "            nn.Linear(embedding, embedding*2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.15),\n",
        "            nn.Linear(embedding*2, embedding)\n",
        "        )\n",
        "    # decoder forward pass\n",
        "    def forward(self, decoder_input, encoded_context, target_mask = None, casual_mask=None):\n",
        "\n",
        "        # self attention amoung decoder\n",
        "        residual = decoder_input\n",
        "        norm_x = self.norm1(decoder_input)\n",
        "        self_attn = self.attention_self(norm_x, casual_mask)\n",
        "        decoder_input = residual + self.dropout(self_attn)\n",
        "\n",
        "        # cross attention to encoder\n",
        "        norm_x = self.norm2(decoder_input)\n",
        "        cross_atn = self.encoder_cross_attention(norm_x, encoded_context)\n",
        "        # dropout, also cant do inplace ops bc of backprop\n",
        "        decoder_input = decoder_input + self.dropout(cross_atn)\n",
        "\n",
        "        # fcnn predictions\n",
        "        norm_x = self.norm3(decoder_input)\n",
        "        ffcn = self.fcnn(norm_x)\n",
        "        out = decoder_input + self.dropout(ffcn)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def encoder_cross_attention(self, query, key_value):\n",
        "        B, L_q, _ = query.shape # decoder input\n",
        "        B, L_kv, _ = key_value.shape # encoder output\n",
        "\n",
        "        q = self.cross_q_proj(query)\n",
        "        k = self.cross_k_proj(key_value)\n",
        "        v = self.cross_v_proj(key_value)\n",
        "\n",
        "        q = q.view(B, L_q, self.nhead, self.head_dim).transpose(1, 2)\n",
        "        k = k.view(B, L_kv, self.nhead, self.head_dim).transpose(1, 2)\n",
        "        v = v.view(B, L_kv, self.nhead, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
        "\n",
        "        attn_weights = torch.softmax(scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context = torch.matmul(attn_weights, v)\n",
        "        context = context.transpose(1, 2).contiguous().view(B, L_q, -1)\n",
        "\n",
        "        output = self.cross_out_proj(context)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c99a1811",
      "metadata": {
        "id": "c99a1811"
      },
      "source": [
        "Decoder block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2fca8aa6",
      "metadata": {
        "id": "2fca8aa6"
      },
      "outputs": [],
      "source": [
        "class TransDecoder(nn.Module):\n",
        "    def __init__(self, target_mask, embedding, dropout, nhead, layers, max_targets, max_step_change, max_seq_len):\n",
        "        super(TransDecoder, self).__init__()\n",
        "        self.max_targets = max_targets\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.embedding = embedding\n",
        "        self.max_step = max_step_change\n",
        "\n",
        "        self.max_velocity = max_step_change if max_step_change else 1.35\n",
        "        self.smoothing_factor = 0.7\n",
        "\n",
        "        # project 2d cords to embedding space\n",
        "        self.positon_projection = nn.Linear(2, embedding)\n",
        "\n",
        "        # player pos embeddings\n",
        "        self.player_pos_embedding = PlayerPositionEmbedding(embedding, max_targets)\n",
        "\n",
        "        # project outputs back to 2d space\n",
        "        self.output_projection = nn.Linear(embedding, 2)\n",
        "\n",
        "        # postional embeddings\n",
        "        self.pos_embed = PositionalEncoding(embed_size=embedding, dropout=0.15, max_length=150)\n",
        "\n",
        "        # decoder layers\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(embedding=embedding, dropout=dropout, nhead=nhead)\n",
        "            for _ in range(layers)\n",
        "        ])\n",
        "\n",
        "        # normalization\n",
        "        self.norm = nn.LayerNorm(embedding)\n",
        "\n",
        "    def smooth_velo(self, new_pos, current_pos, previous_pos=None):\n",
        "        # cast to full percision\n",
        "        new_pos = new_pos.float()\n",
        "        current_pos = current_pos.float()\n",
        "        if previous_pos is not None:\n",
        "            previous_pos = previous_pos.float()\n",
        "\n",
        "        # clamp preds to reasonable bounds\n",
        "        max_step = self.max_velocity * 2\n",
        "        delta = new_pos - current_pos\n",
        "        delta_mag = torch.norm(delta, p=2, dim=-1, keepdim=True).clamp(min=1e-8)\n",
        "\n",
        "        scale_smooth = torch.tanh(max_step / delta_mag)\n",
        "        delta_clamped = delta * scale_smooth\n",
        "\n",
        "        if previous_pos is None:\n",
        "            # use clamped delta, limit max change\n",
        "            delta_mag_clamped = torch.norm(delta_clamped, p=2, dim=-1, keepdim=True)\n",
        "            # clamp exponent to prevent overflow\n",
        "            exp_arg = torch.clamp(delta_mag_clamped / self.max_velocity - 1.0, min=0.0, max=10.0)\n",
        "            # scale\n",
        "            soft_scale = torch.exp(-exp_arg)\n",
        "            # smoothed change\n",
        "            smoothed_delta = delta_clamped * soft_scale\n",
        "\n",
        "            return current_pos + smoothed_delta\n",
        "        else:\n",
        "            previous_velocity = current_pos - previous_pos\n",
        "            # eucledian distance between the two\n",
        "            velocity_mag = torch.norm(previous_velocity, p=2, dim=-1, keepdim=True)\n",
        "            # already smoothed velocity\n",
        "            predicted_velocity = delta_clamped\n",
        "            predicted_velocity_mag = torch.norm(predicted_velocity, p=2, dim=-1, keepdim=True)\n",
        "\n",
        "            # smooth acceleration pen\n",
        "            velocity_change_mag = torch.abs(predicted_velocity_mag - velocity_mag)\n",
        "            # sigmod so pen is smooth and diff\n",
        "            accel_pen = torch.sigmoid(-velocity_change_mag / self.max_velocity)\n",
        "            # smoothed velo\n",
        "            smoothed_velo = (previous_velocity * self.smoothing_factor +\n",
        "                             predicted_velocity * (1.0 - self.smoothing_factor)) * accel_pen\n",
        "            # smooth velo clamping\n",
        "            smoothed_velocity_mag = torch.norm(smoothed_velo, p=2, dim = -1, keepdim=True)\n",
        "            velocity_scale = torch.tanh((self.max_velocity * 1.5) / smoothed_velocity_mag)\n",
        "            # prevent exploding gradients\n",
        "            result = current_pos + smoothed_velo * velocity_scale\n",
        "            result = torch.clamp(result, min=-0.1, max=1.1)\n",
        "\n",
        "            return result\n",
        "\n",
        "    def forward(self, encoded_context, start_positons, target_mask,\n",
        "                future_steps, input_len, target_seq, teacher_prob, player_positons):\n",
        "\n",
        "        # batch, max_seq, device\n",
        "        batch_size = encoded_context.shape[0]\n",
        "        device = encoded_context.device\n",
        "        max_seq_len = self.max_seq_len\n",
        "\n",
        "        # player pos embeddings\n",
        "        player_pos_embeds = self.player_pos_embedding(player_positons, target_mask)\n",
        "\n",
        "        # output tensor\n",
        "        all_outputs = torch.zeros(batch_size, self.max_targets, max_seq_len, 2, device=device)\n",
        "\n",
        "        # autoregressive\n",
        "        decoder_sequence = [[] for _ in range(batch_size)]\n",
        "        current_postions = start_positons.clone()\n",
        "        previous_pos = None\n",
        "\n",
        "        # output sequence\n",
        "        for step in range(max_seq_len):\n",
        "            # project pos to embedding space\n",
        "            pos_embeds = self.positon_projection(current_postions)\n",
        "\n",
        "            # positional embedding\n",
        "            pos_embeds = pos_embeds + player_pos_embeds\n",
        "\n",
        "            # add positional context\n",
        "            pos_encoding = self.pos_embed.pe[step, :self.embedding].unsqueeze(0).unsqueeze(0)\n",
        "            # Replace inplace addition with out-of-place addition\n",
        "            pos_input = pos_embeds + pos_encoding\n",
        "            # add sequence dim back\n",
        "            pos_input = pos_input.unsqueeze(2)\n",
        "\n",
        "            # decoder seq\n",
        "            for batch_idx in range(batch_size):\n",
        "                decoder_sequence[batch_idx].append(pos_input[batch_idx])\n",
        "\n",
        "            if step == 0:\n",
        "                # if first step use init pos\n",
        "                decoder_input = pos_input\n",
        "                casual_mask = None\n",
        "\n",
        "            else:\n",
        "                # decoder inputs\n",
        "                batch_decoder_inputs = []\n",
        "\n",
        "                # get decoder seq for values\n",
        "                for batch_idx in range(batch_size):\n",
        "                    if len(decoder_sequence[batch_idx]) > 0:\n",
        "                        sample_sequence = torch.cat(decoder_sequence[batch_idx], dim = 1)\n",
        "                        batch_decoder_inputs.append(sample_sequence)\n",
        "                    else:\n",
        "                        dummy_input = torch.zeros(self.max_targets, step+1, self.embedding, device=device)\n",
        "                        batch_decoder_inputs.append(dummy_input)\n",
        "\n",
        "                # all samples for decoder input\n",
        "                decoder_input = torch.stack(batch_decoder_inputs)\n",
        "\n",
        "                # casual mask\n",
        "                seq_len = step + 1\n",
        "                casual_mask = create_causal_mask(seq_len, device)\n",
        "\n",
        "\n",
        "            # transformer layers\n",
        "            batch_size_curr, max_targets_curr, seq_len_curr, embed_dim_curr = decoder_input.shape\n",
        "            decoder_input_reshaped = decoder_input.view(batch_size_curr * max_targets_curr, seq_len_curr, embed_dim_curr)\n",
        "\n",
        "            # decoder layer\n",
        "            decoded = decoder_input_reshaped\n",
        "\n",
        "            # masking for future seq\n",
        "            if casual_mask is not None:\n",
        "               casual_mask_expanded = casual_mask.unsqueeze(0).expand(batch_size_curr * max_targets_curr, seq_len_curr, seq_len_curr)\n",
        "            else:\n",
        "               casual_mask_expanded = None\n",
        "\n",
        "            # pass through decoder layers\n",
        "            expanded_context = encoded_context.unsqueeze(1).repeat(1, max_targets_curr, 1, 1)\n",
        "            expanded_context = expanded_context.view(batch_size_curr * max_targets_curr, -1, self.embedding)\n",
        "\n",
        "            for layer in self.layers:\n",
        "                decoded = layer(decoded, expanded_context,target_mask, casual_mask_expanded)\n",
        "\n",
        "            # normalize gradients\n",
        "            decoded = self.norm(decoded)\n",
        "\n",
        "            # reshape and project back to cords\n",
        "            decoded = decoded.view(batch_size_curr, max_targets_curr, seq_len_curr, embed_dim_curr)\n",
        "            predictions = self.output_projection(decoded[:, :, -1, :])\n",
        "\n",
        "            # smooth velocity predictiosn\n",
        "            clamp_pred = self.smooth_velo(predictions, current_postions, previous_pos)\n",
        "\n",
        "            # store every prediction\n",
        "            all_outputs[:, :, step, :] = clamp_pred\n",
        "\n",
        "            # store rpevious postion, teacher forcing generation\n",
        "            previous_pos = current_postions.clone()\n",
        "            teacher_forcing = torch.rand(size=(batch_size, 1, 1), device=device)\n",
        "\n",
        "            # stack all predictions\n",
        "            if (teacher_forcing <= teacher_prob).any():\n",
        "                # ground truth\n",
        "                mask = (teacher_forcing <= teacher_prob).squeeze()\n",
        "                current_postions[mask] = target_seq[mask, :, step, :]\n",
        "            else:\n",
        "                # model predicitons\n",
        "                current_postions = clamp_pred.clone()\n",
        "\n",
        "        return all_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a8d4489",
      "metadata": {
        "id": "9a8d4489"
      },
      "source": [
        "##### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ad1faa5f",
      "metadata": {
        "id": "ad1faa5f"
      },
      "outputs": [],
      "source": [
        "class DJMooreSeq(nn.Module):\n",
        "    def __init__(self, embed_size, encoder_layers, decoder_layers,\n",
        "                 max_targets, dropout, nheads, max_step, dev='cuda') -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # general vars\n",
        "        self.embedding_size = embed_size\n",
        "        self.max_targets = max_targets\n",
        "        self.device = dev\n",
        "\n",
        "        # context cnn\n",
        "        self.context_cnn = CNN_DownSample()\n",
        "        # output size\n",
        "        context_cnn_output = 128 * 4 * 8\n",
        "\n",
        "        # transformer encoder\n",
        "        self.encoder = TransEncoder(input_dim=context_cnn_output,\n",
        "                                    embed_size=embed_size,\n",
        "                                    num_layers=encoder_layers,\n",
        "                                    device=dev,\n",
        "                                    nhead = nheads,\n",
        "                                    mask=None,\n",
        "                                    dropout=dropout,\n",
        "                                    max_length=150)\n",
        "\n",
        "        # decoder\n",
        "        self.decoder = TransDecoder(target_mask=None,\n",
        "                                    embedding=embed_size,\n",
        "                                    dropout=dropout,\n",
        "                                    nhead=nheads,\n",
        "                                    layers=decoder_layers,\n",
        "                                    max_targets=max_targets,\n",
        "                                    max_step_change=max_step,\n",
        "                                    max_seq_len=max_output)\n",
        "\n",
        "    def forward(self, heatmap_sequence, start_pos, target_mask,\n",
        "                future_steps, input_lengths, target_seq, player_positions, teacher_prob):\n",
        "        # derive batch size, length of transformer output\n",
        "        batch_size, seq_len = heatmap_sequence.shape[:2]\n",
        "\n",
        "        # cnn features\n",
        "        cnn_features = []\n",
        "        for t in range(seq_len):\n",
        "            frame = heatmap_sequence[:,t]\n",
        "            features = self.context_cnn(frame)\n",
        "            features = features.flatten(1)\n",
        "            cnn_features.append(features)\n",
        "\n",
        "        # stack and encode\n",
        "        sequence_feat = torch.stack(cnn_features, dim=1)\n",
        "\n",
        "        # encoder mask based on input seq\n",
        "        encoder_mask = torch.zeros(batch_size, seq_len, device=heatmap_sequence.device, dtype=torch.bool)\n",
        "        for i, length in enumerate(input_lengths):\n",
        "            encoder_mask[i, :length] = True\n",
        "\n",
        "        # context\n",
        "        encoded_context = self.encoder(sequence_feat, encoder_mask)\n",
        "        # output predictions\n",
        "        predictions = self.decoder(encoded_context, start_pos, target_mask,\n",
        "                                   future_steps, input_lengths, target_seq,\n",
        "                                   teacher_prob, player_positions)\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "883ff497",
      "metadata": {
        "id": "883ff497"
      },
      "source": [
        "##### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "696a328f",
      "metadata": {
        "id": "696a328f"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, loss_func, optimizer, scheduler, epochs):\n",
        "  # scaler for amp\n",
        "  scaler = torch.GradScaler(device=\"cuda\")\n",
        "\n",
        "  # loss\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  # early stopping\n",
        "  best_loss = np.inf\n",
        "  early_stop_rounds = 0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    # train mode, loss and batches\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    batches = 0\n",
        "    teacher_prob = max(0.1, 1.0 - epoch * 0.025)\n",
        "\n",
        "    for batch_sequence, batch_targets, batch_masks, batch_start_pos, batch_input_lengths, batch_output_lengths, batch_player_pos in train_loader:\n",
        "\n",
        "        # move all items to gpu\n",
        "        batch_sequence = batch_sequence.to('cuda')\n",
        "        batch_targets = batch_targets.to('cuda')\n",
        "        batch_masks = batch_masks.to('cuda')\n",
        "        batch_start_pos = batch_start_pos.to('cuda')\n",
        "        batch_input_lengths = batch_input_lengths.to('cuda')\n",
        "        batch_output_lengths = batch_output_lengths.to('cuda')\n",
        "        batch_player_pos = batch_player_pos.to('cuda')\n",
        "\n",
        "        # zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.autocast(device_type=\"cuda\"):\n",
        "            # forward pass\n",
        "            predictions = model(batch_sequence, batch_start_pos, batch_masks,\n",
        "                                batch_output_lengths, batch_input_lengths,\n",
        "                                target_seq = batch_targets, teacher_prob=teacher_prob, player_positions = batch_player_pos)\n",
        "\n",
        "        # train loss\n",
        "        loss = loss_func(predictions, batch_targets, batch_masks, batch_output_lengths)\n",
        "\n",
        "        # backprop\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # epoch loss\n",
        "        epoch_loss += loss.item() * batch_sequence.size(0)\n",
        "        batches += batch_sequence.size(0)\n",
        "\n",
        "    # training losses\n",
        "    avg_loss = epoch_loss / batches\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    # val set losses\n",
        "    model.eval()\n",
        "    val_epoch_loss = 0\n",
        "    val_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_sequence, val_targets, val_masks, val_start_pos, val_input_lengths, val_output_lengths, val_player_pos in val_loader:\n",
        "            # to cuda\n",
        "            val_sequence = val_sequence.to('cuda')\n",
        "            val_targets = val_targets.to('cuda')\n",
        "            val_masks = val_masks.to('cuda')\n",
        "            val_start_pos = val_start_pos.to('cuda')\n",
        "            val_input_lengths = val_input_lengths.to('cuda')\n",
        "            val_output_lengths = val_output_lengths.to('cuda')\n",
        "            val_player_pos = val_player_pos.to('cuda')\n",
        "\n",
        "            # predictions and loss on val set\n",
        "            val_predictions = model(val_sequence, val_start_pos, val_masks, val_output_lengths,\n",
        "                                    val_input_lengths, target_seq = val_targets, teacher_prob = 0,\n",
        "                                    player_positions = val_player_pos)\n",
        "\n",
        "            # validtion losses\n",
        "            val_loss = loss_func(val_predictions, val_targets, val_masks, val_output_lengths)\n",
        "\n",
        "            val_epoch_loss += val_loss.item() * val_sequence.size(0)\n",
        "            val_batches += val_sequence.size(0)\n",
        "\n",
        "    # val set losses\n",
        "    val_epoch_loss = val_epoch_loss / val_batches\n",
        "    val_losses.append(val_epoch_loss)\n",
        "\n",
        "    # learning rate sched.\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f'val_loss {val_epoch_loss}, train_loss {avg_loss}')\n",
        "\n",
        "    # early stopping check\n",
        "    if val_epoch_loss < best_loss:\n",
        "        best_loss = val_epoch_loss\n",
        "        early_stop_rounds = 0\n",
        "        torch.save(model.state_dict(), f\"best_model.pth\")\n",
        "    else:\n",
        "        early_stop_rounds += 1\n",
        "\n",
        "    if early_stop_rounds > 20:\n",
        "        print('early stopping')\n",
        "        return train_losses, val_losses\n",
        "\n",
        "  return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64a43f95",
      "metadata": {
        "id": "64a43f95"
      },
      "source": [
        "##### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "45a24262",
      "metadata": {
        "id": "45a24262"
      },
      "outputs": [],
      "source": [
        "class MaskedSequenceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, predictions, targets, target_mask, output_len):\n",
        "        _, _, max_seq_len, _ = predictions.shape\n",
        "\n",
        "        if predictions.shape[2] != targets.shape[2]:\n",
        "            raise ValueError(\"seq len mismatch\")\n",
        "\n",
        "        # len mask\n",
        "        length_mask = torch.arange(max_seq_len, device=predictions.device)[None, :] < output_len[:, None]\n",
        "\n",
        "        # masking\n",
        "        target_mask_expanded = target_mask.unsqueeze(-1).unsqueeze(-1)\n",
        "        length_mask_expanded = length_mask.unsqueeze(1).unsqueeze(-1)\n",
        "        combined_mask = target_mask_expanded & length_mask_expanded\n",
        "        combined_mask = combined_mask.expand_as(predictions)\n",
        "\n",
        "        # mse\n",
        "        diff = (predictions - targets) **2\n",
        "        masked_diff = diff * combined_mask.float()\n",
        "\n",
        "        # valid ele\n",
        "        valid_elements = combined_mask.sum()\n",
        "\n",
        "        if valid_elements > 0:\n",
        "            return masked_diff.sum() / valid_elements\n",
        "        else:\n",
        "            return torch.tensor(0.0, device=predictions.device, requires_grad=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3a8c28",
      "metadata": {
        "id": "7e3a8c28"
      },
      "source": [
        "##### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f2ffdfec",
      "metadata": {
        "id": "f2ffdfec"
      },
      "outputs": [],
      "source": [
        "# create dataset instance by instance rather than all at once\n",
        "class NFLSequenceDataset(Dataset):\n",
        "    def __init__(self, df_grids, df_tracking, max_targets, max_input, max_output, split_indices=None):\n",
        "        # input vars\n",
        "        self.df_grids = df_grids\n",
        "        self.df_tracking = df_tracking\n",
        "        self.max_targets = max_targets\n",
        "        self.max_input = max_input\n",
        "        self.max_output = max_output\n",
        "\n",
        "        # play_ids\n",
        "        self.play_ids = df_grids['play_id_n'].unique()\n",
        "        if split_indices is not None:\n",
        "            self.play_ids = self.play_ids[split_indices]\n",
        "\n",
        "        # players to predict for each play\n",
        "        self.player_to_predict = df_tracking[df_tracking['player_to_predict'] == True].groupby('play_id_n')['nfl_id'].unique()\n",
        "\n",
        "    def __len__(self):\n",
        "        # how many plays\n",
        "        return len(self.play_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        play_id = self.play_ids[idx]\n",
        "\n",
        "        # data for a given play\n",
        "        play_data = self.df_grids[self.df_grids['play_id_n'] == play_id].sort_values('frame_id')\n",
        "        df_data = self.df_tracking[self.df_tracking['play_id_n'] == play_id]\n",
        "\n",
        "        # seq lengths\n",
        "        total_frames = int(play_data['frame_id'].max())\n",
        "        output_frames = int(df_data['num_frames_output'].max())\n",
        "        input_seq_len = int(total_frames - output_frames)\n",
        "        output_seq_len = int(output_frames)\n",
        "\n",
        "        # target play ids\n",
        "        if play_id in self.player_to_predict:\n",
        "            players = self.player_to_predict[play_id][:self.max_targets]\n",
        "        else:\n",
        "            players = []\n",
        "\n",
        "        num_receivers = len(players)\n",
        "\n",
        "        # mask for less than max target\n",
        "        target_mask = torch.zeros(self.max_targets, dtype=torch.bool)\n",
        "        target_mask[:num_receivers] = True\n",
        "\n",
        "        # input seq\n",
        "        input_sequence = torch.zeros(self.max_input, *play_data['grid'].iloc[0].shape, dtype=torch.float32)\n",
        "        act_input = min(input_seq_len, self.max_input)\n",
        "\n",
        "        for i in range(act_input):\n",
        "            if i < total_frames:\n",
        "                grid = torch.from_numpy(play_data['grid'].iloc[i]).float()\n",
        "                input_sequence[i] = grid\n",
        "\n",
        "\n",
        "        # start positons\n",
        "        start_pos = torch.zeros(self.max_targets, 2)\n",
        "        target_player_pos = torch.zeros(max_targets, 1)\n",
        "\n",
        "        # last frame from dataset\n",
        "        last_frame_id = input_seq_len\n",
        "\n",
        "        last_frame_data = self.df_tracking[\n",
        "            (self.df_tracking['play_id_n'] == play_id) &\n",
        "            (self.df_tracking['frame_id'] == last_frame_id)\n",
        "        ]\n",
        "\n",
        "        # init postions fo start plyer\n",
        "        for i, receiver_id in enumerate(players):\n",
        "            receiver_data = last_frame_data[last_frame_data['nfl_id'] == receiver_id]\n",
        "            if not receiver_data.empty:\n",
        "                x = float(receiver_data['x'].iloc[0]) / 120\n",
        "                y = float(receiver_data['y'].iloc[0]) / 53.3\n",
        "                start_pos[i] = torch.tensor([x, y])\n",
        "\n",
        "                # add player postion\n",
        "                pos_map = {'WR': 1, 'SS':2, 'CB':3, 'RB':4, 'OLB':5,\n",
        "                           'ILB':6, 'TE':7, 'FS':8, 'MLB':9, 'DE':10,\n",
        "                           'DT':11, 'FB':12, 'S':13, 'T':14, 'NT':15, 'QB':16, 'LB':17}\n",
        "                pos = pos_map.get(receiver_data.get('player_position', 'WR').iloc[0], 1)\n",
        "                target_player_pos[i] = torch.tensor(pos)\n",
        "\n",
        "        # target seq\n",
        "        target_positions = torch.zeros(self.max_targets, self.max_output, 2)\n",
        "        act_output = min(output_frames, self.max_output)\n",
        "\n",
        "        # target postions\n",
        "        for step in range(act_output):\n",
        "            frame_idx = input_seq_len + step\n",
        "\n",
        "            if frame_idx < len(play_data):\n",
        "                target_frame = play_data.iloc[frame_idx]['frame_id']\n",
        "                target_frame_data = self.df_tracking[\n",
        "                    (self.df_tracking['play_id_n'] == play_id) &\n",
        "                    (self.df_tracking['frame_id'] == target_frame)\n",
        "                ]\n",
        "\n",
        "                for i, receiver_id in enumerate(players):\n",
        "                    receiver_data = target_frame_data[target_frame_data['nfl_id'] == receiver_id]\n",
        "                    if not receiver_data.empty:\n",
        "                        x = float(receiver_data['x'].iloc[0]) / 120\n",
        "                        y = float(receiver_data['y'].iloc[0]) / 53.3\n",
        "                        target_positions[i, step] = torch.tensor([x, y])\n",
        "\n",
        "\n",
        "        return (\n",
        "            input_sequence,\n",
        "            target_positions,\n",
        "            target_mask,\n",
        "            start_pos,\n",
        "            torch.tensor(act_input),\n",
        "            torch.tensor(act_output),\n",
        "            target_player_pos\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfcbdcfc",
      "metadata": {
        "id": "bfcbdcfc"
      },
      "source": [
        "##### Data Prep, Training, Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4b627e37",
      "metadata": {
        "id": "4b627e37"
      },
      "outputs": [],
      "source": [
        "# split by indexs\n",
        "play_indices = np.arange(len(df_grids['play_id_n'].unique()))\n",
        "train_idx, test_idx = train_test_split(play_indices, test_size=0.4, random_state=26)\n",
        "test_idx, val_idx = train_test_split(test_idx, test_size=.9, random_state=26)\n",
        "\n",
        "# create the datasets dynamically\n",
        "train_dataset = NFLSequenceDataset(df_grids, df, max_targets, int(max_input), int(max_output), train_idx)\n",
        "val_dataset = NFLSequenceDataset(df_grids, df, max_targets, int(max_input), int(max_output), val_idx)\n",
        "test_dataset = NFLSequenceDataset(df_grids, df, max_targets, int(max_input), int(max_output), test_idx)\n",
        "\n",
        "# create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "8ZnN4jdggoE5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZnN4jdggoE5",
        "outputId": "9af5b8d0-e5bd-4f85-b7f1-0d95af78e175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1951874\n"
          ]
        }
      ],
      "source": [
        "# model\n",
        "model = DJMooreSeq(embed_size=128, encoder_layers=4, decoder_layers=4,\n",
        "                   max_targets=max_targets, max_step=1.4, dropout=0.1, nheads=8 ,dev='cuda').to('cuda')\n",
        "\n",
        "# params\n",
        "trainable_params = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
        "print(trainable_params)\n",
        "\n",
        "# clean envi\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "cfa8b6b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "cfa8b6b1",
        "outputId": "13fcdf5c-83c7-4432-9b92-e6f1f4bddd36",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss 0.29747403568691677, train_loss 0.03847201937890571\n",
            "val_loss 0.09931000696288214, train_loss 0.018856806498344824\n",
            "val_loss 0.07168205536074108, train_loss 0.004983011121942621\n",
            "val_loss 0.027668220202128092, train_loss 0.0028026752659808035\n",
            "val_loss 0.023487072934707007, train_loss 0.001989914607965266\n",
            "val_loss 0.03499764813317193, train_loss 0.001537072515297357\n",
            "val_loss 0.03402264436086019, train_loss 0.001284817887885172\n",
            "val_loss 0.027084768820140097, train_loss 0.0011053092704336766\n",
            "val_loss 0.024456332913703388, train_loss 0.0009850164705826699\n",
            "val_loss 0.01509583368897438, train_loss 0.0008284221264108529\n",
            "val_loss 0.03358910229470995, train_loss 0.0007152706422620331\n",
            "val_loss 0.01718441668070025, train_loss 0.0006551048440008384\n",
            "val_loss 0.013383303417099847, train_loss 0.0006170258199310173\n",
            "val_loss 0.013914905422263675, train_loss 0.0005717151045404455\n",
            "val_loss 0.017754289110501607, train_loss 0.0005306964714849448\n",
            "val_loss 0.009285083508325947, train_loss 0.0004971735090847411\n",
            "val_loss 0.041886556247870126, train_loss 0.00048649881057866406\n",
            "val_loss 0.027795591122574275, train_loss 0.0004784282228565248\n",
            "val_loss 0.01709849427971575, train_loss 0.0004732730702254111\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1063950151.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-4039969485.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, loss_func, optimizer, scheduler, epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# move all items to gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mbatch_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mbatch_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mbatch_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# epochs\n",
        "epochs = 1000\n",
        "\n",
        "# loss, opti, schedu\n",
        "loss_func = MaskedSequenceLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.001)\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=10, num_training_steps=epochs)\n",
        "\n",
        "# train\n",
        "train_losses, val_losses = train(model, train_loader, val_loader, loss_func, optimizer, scheduler, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "y-MKVAXri79k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-MKVAXri79k",
        "outputId": "f43d3c36-87fa-4049-ed05-0c691a764a01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "state_dict = torch.load(\"best_model.pth\")\n",
        "model.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "rTYw9BR_0Sms",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "collapsed": true,
        "id": "rTYw9BR_0Sms",
        "outputId": "c3baa54f-7990-4093-87f9-676bce5e4d81"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def visualize_predictions(model, data_loader, play_idx=0, target_player_idx=0):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_sequence, batch_targets, batch_masks, batch_start_pos, batch_input_lengths, batch_output_lengths, batch_player_pos in data_loader:\n",
        "            batch_sequence = batch_sequence.to('cuda')\n",
        "            batch_targets = batch_targets.to('cuda')\n",
        "            batch_masks = batch_masks.to('cuda')\n",
        "            batch_start_pos = batch_start_pos.to('cuda')\n",
        "            batch_input_lengths = batch_input_lengths.to('cuda')\n",
        "            batch_output_lengths = batch_output_lengths.to('cuda')\n",
        "            batch_player_pos = batch_player_pos.to('cuda')\n",
        "\n",
        "            with torch.autocast(device_type=\"cuda\"):\n",
        "                val_predictions = model(batch_sequence, batch_start_pos, batch_masks, batch_output_lengths,\n",
        "                                        batch_input_lengths, target_seq = batch_targets, teacher_prob = 0,\n",
        "                                        player_positions = batch_player_pos)\n",
        "\n",
        "            predicted_trajectory = val_predictions[play_idx, target_player_idx, :, :].cpu().numpy()\n",
        "            actual_trajectory = batch_targets[play_idx, target_player_idx, :, :].cpu().numpy()\n",
        "            output_length = batch_output_lengths[play_idx].cpu().numpy()\n",
        "\n",
        "\n",
        "            predicted_trajectory = predicted_trajectory[:output_length]\n",
        "            actual_trajectory = actual_trajectory[:output_length]\n",
        "\n",
        "            # scale back to normal\n",
        "            predicted_trajectory[:, 0] *= 120\n",
        "            predicted_trajectory[:, 1] *= 53.3\n",
        "            actual_trajectory[:, 0] *= 120\n",
        "            actual_trajectory[:, 1] *= 53.3\n",
        "\n",
        "            # plot trajectory\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(actual_trajectory[:, 0], actual_trajectory[:, 1], marker='o', linestyle='-', color='blue', label='Actual')\n",
        "            plt.plot(predicted_trajectory[:, 0], predicted_trajectory[:, 1], marker='x', linestyle='--', color='red', label='Predicted')\n",
        "            plt.xlabel('X Coordinate (yards)')\n",
        "            plt.ylabel('Y Coordinate (yards)')\n",
        "            plt.title(f'Predicted vs Actual Trajectory for Play {play_idx}, Target Player {target_player_idx}')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "\n",
        "            # first point in black\n",
        "            plt.plot(actual_trajectory[0, 0], actual_trajectory[0, 1], marker='o', color='black', markersize=8)\n",
        "            plt.plot(predicted_trajectory[0, 0], predicted_trajectory[0, 1], marker='x', color='black', markersize=8)\n",
        "\n",
        "            # last point blue\n",
        "            plt.plot(actual_trajectory[-1, 0], actual_trajectory[-1, 1], marker='o', color='blue', markersize=8)\n",
        "            plt.plot(predicted_trajectory[-1, 0], predicted_trajectory[-1, 1], marker='x', color='blue', markersize=8)\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "            break\n",
        "\n",
        "visualize_predictions(model, test_loader, play_idx=20, target_player_idx=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v3LJWM9U7lVZ",
      "metadata": {
        "id": "v3LJWM9U7lVZ"
      },
      "outputs": [],
      "source": [
        "# Get a sample from the training dataset\n",
        "sample_sequence, target_positions, target_mask, start_pos, input_length, output_length = train_dataset[0]\n",
        "\n",
        "# Display the target masks\n",
        "print(\"Target Masks:\")\n",
        "print(target_mask)\n",
        "\n",
        "# Display the start positions\n",
        "print(\"\\nStart Positions:\")\n",
        "print(start_pos)\n",
        "\n",
        "# Display the target positions\n",
        "print(\"\\nTarget Positions:\")\n",
        "print(target_positions)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "eb3b0c43"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nflLab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}