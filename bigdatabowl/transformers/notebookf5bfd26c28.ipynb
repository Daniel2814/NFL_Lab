{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "080187c2",
   "metadata": {
    "papermill": {
     "duration": 0.005405,
     "end_time": "2025-11-25T20:28:16.785573",
     "exception": false,
     "start_time": "2025-11-25T20:28:16.780168",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kaggle Predections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc54b503",
   "metadata": {
    "papermill": {
     "duration": 0.004103,
     "end_time": "2025-11-25T20:28:16.794100",
     "exception": false,
     "start_time": "2025-11-25T20:28:16.789997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61ada0cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T20:28:16.803927Z",
     "iopub.status.busy": "2025-11-25T20:28:16.803621Z",
     "iopub.status.idle": "2025-11-25T20:28:24.986059Z",
     "shell.execute_reply": "2025-11-25T20:28:24.985116Z"
    },
    "papermill": {
     "duration": 8.189295,
     "end_time": "2025-11-25T20:28:24.987630",
     "exception": false,
     "start_time": "2025-11-25T20:28:16.798335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24a68aeaf30>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import gc\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "torch.manual_seed(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "394d160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/dalto/OneDrive/Pictures/Documents/Emory/NFL Lab/data/2023_tracking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4bf050d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T20:28:24.998823Z",
     "iopub.status.busy": "2025-11-25T20:28:24.997839Z",
     "iopub.status.idle": "2025-11-25T20:28:25.002320Z",
     "shell.execute_reply": "2025-11-25T20:28:25.001585Z"
    },
    "papermill": {
     "duration": 0.011661,
     "end_time": "2025-11-25T20:28:25.003841",
     "exception": false,
     "start_time": "2025-11-25T20:28:24.992180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_targets = 9\n",
    "max_input = 123\n",
    "max_output = 94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "955b8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['play_id_n'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7ea96c",
   "metadata": {
    "papermill": {
     "duration": 0.004329,
     "end_time": "2025-11-25T20:28:25.012656",
     "exception": false,
     "start_time": "2025-11-25T20:28:25.008327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f71dfc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T20:28:25.022666Z",
     "iopub.status.busy": "2025-11-25T20:28:25.022294Z",
     "iopub.status.idle": "2025-11-25T20:28:25.029977Z",
     "shell.execute_reply": "2025-11-25T20:28:25.029128Z"
    },
    "papermill": {
     "duration": 0.014513,
     "end_time": "2025-11-25T20:28:25.031345",
     "exception": false,
     "start_time": "2025-11-25T20:28:25.016832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_size, dropout, max_length=150):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # droput\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # create matrix\n",
    "        pe = torch.zeros(max_length, embed_size)\n",
    "\n",
    "        # position tensor shape\n",
    "        position = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        # div_term tensor shape\n",
    "        div_term = torch.exp(torch.arange(0, embed_size, 2).float() * (-torch.log(torch.tensor(10000.0)) / embed_size))\n",
    "\n",
    "        # apply sin to even indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "\n",
    "        # apply cos to odd indices\n",
    "        if embed_size % 2 == 1:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term[:-1])\n",
    "        else:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # register as buffer so it moves with model to device\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pe_slice = self.pe[:x.size(1), :].to(x.device)\n",
    "        x = x + pe_slice\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "404ed98a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T20:28:25.042266Z",
     "iopub.status.busy": "2025-11-25T20:28:25.041526Z",
     "iopub.status.idle": "2025-11-25T20:28:25.047266Z",
     "shell.execute_reply": "2025-11-25T20:28:25.046569Z"
    },
    "papermill": {
     "duration": 0.012824,
     "end_time": "2025-11-25T20:28:25.048658",
     "exception": false,
     "start_time": "2025-11-25T20:28:25.035834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PlayerPositionEmbedding(nn.Module):\n",
    "    def __init__(self, embed_size, num_positions = 19):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        self.position_projection = nn.Embedding(num_positions, embed_size)\n",
    "\n",
    "    def forward(self, player_positons, target_masks):\n",
    "        # ints to learnable embedding space\n",
    "        pos_embeds = self.position_projection(player_positons.long().squeeze(-1))\n",
    "\n",
    "        # target mask, ignore padded values\n",
    "        target_mask_expand = target_masks.unsqueeze(-1).expand_as(pos_embeds)\n",
    "        pos_embeds = pos_embeds * target_mask_expand.float()\n",
    "\n",
    "        return pos_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ae3134f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T20:28:25.058836Z",
     "iopub.status.busy": "2025-11-25T20:28:25.058451Z",
     "iopub.status.idle": "2025-11-25T20:28:25.064519Z",
     "shell.execute_reply": "2025-11-25T20:28:25.063804Z"
    },
    "papermill": {
     "duration": 0.012726,
     "end_time": "2025-11-25T20:28:25.065881",
     "exception": false,
     "start_time": "2025-11-25T20:28:25.053155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FourierEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, scale=10.0):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.scale = scale\n",
    "        self.B = nn.Parameter(torch.randn(input_dim, embed_dim // 2) * scale, requires_grad=False)\n",
    "\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # float bc autocast\n",
    "        x_proj = (2 * np.pi * x.float()) @ self.B.float()\n",
    "        x_embed = torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "        return self.out_proj(x_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "080dccf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T20:28:25.076681Z",
     "iopub.status.busy": "2025-11-25T20:28:25.075712Z",
     "iopub.status.idle": "2025-11-25T20:28:25.086340Z",
     "shell.execute_reply": "2025-11-25T20:28:25.085599Z"
    },
    "papermill": {
     "duration": 0.01748,
     "end_time": "2025-11-25T20:28:25.087756",
     "exception": false,
     "start_time": "2025-11-25T20:28:25.070276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SpatialSoftmax(nn.Module):\n",
    "  def __init__(self, height, width, device='cuda'):\n",
    "    super(SpatialSoftmax, self).__init__()\n",
    "    self.height = height\n",
    "    self.width = width\n",
    "    self.device = device\n",
    "\n",
    "    pos_x, pos_y = np.meshgrid(np.linspace(-1., 1., width),\n",
    "                               np.linspace(-1., 1., height))\n",
    "\n",
    "    pos_x = torch.from_numpy(pos_x.reshape(self.height * self.width)).float().to(device)\n",
    "    pos_y = torch.from_numpy(pos_y.reshape(self.height * self.width)).float().to(device)\n",
    "\n",
    "    self.register_buffer('pos_x', pos_x)\n",
    "    self.register_buffer('pos_y', pos_y)\n",
    "\n",
    "  def forward(self, feature_map):\n",
    "    B, C, H, W = feature_map.shape\n",
    "    feature_flat = feature_map.view(B, C, -1)\n",
    "    softmax_attn = F.softmax(feature_flat, dim=-1)\n",
    "\n",
    "    expected_x = torch.sum(self.pos_x * softmax_attn, dim=2, keepdim = True)\n",
    "    expected_y = torch.sum(self.pos_y * softmax_attn, dim=2, keepdim = True)\n",
    "\n",
    "    expected_xy = torch.cat([expected_x, expected_y], dim=2)\n",
    "\n",
    "    return expected_xy.view(B, -1)\n",
    "\n",
    "class CNN_DownSample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        # variable based on amount of targets\n",
    "        input_chan = 2 + max_targets + 1\n",
    "\n",
    "        self.heatmap_encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_chan, out_channels=32, kernel_size=3, stride = 2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride = 1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride = 1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.spatial_softmax = SpatialSoftmax(height=28, width=61)\n",
    "\n",
    "        # heatmap to embedding\n",
    "        self.output_proj = nn.Linear(128, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.heatmap_encoder(x)\n",
    "        x = self.spatial_softmax(x)\n",
    "        x = self.output_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d434415",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T20:28:25.097824Z",
     "iopub.status.busy": "2025-11-25T20:28:25.097459Z",
     "iopub.status.idle": "2025-11-25T20:28:25.104292Z",
     "shell.execute_reply": "2025-11-25T20:28:25.103517Z"
    },
    "papermill": {
     "duration": 0.0136,
     "end_time": "2025-11-25T20:28:25.105675",
     "exception": false,
     "start_time": "2025-11-25T20:28:25.092075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, embed_size, num_layers, nhead, device, dropout, mask, max_length):\n",
    "        super(TransEncoder, self).__init__()\n",
    "        # emebef size and deivice\n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "\n",
    "        # learned matrix projection\n",
    "        self.input_projection = nn.Linear(input_dim, embed_size)\n",
    "\n",
    "        # postional encoding\n",
    "        self.position_encoding = PositionalEncoding(embed_size, dropout, max_length)\n",
    "\n",
    "        # transformer encoder layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_size,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=embed_size,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "\n",
    "        # transformation encoder\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # normalize after attention\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # input layer matrix mult\n",
    "        projected_input = self.input_projection(x)\n",
    "        # position encodings\n",
    "        out = self.position_encoding(projected_input)\n",
    "        # invert mask\n",
    "        src_key_padding_mask = ~mask\n",
    "        out = self.transformer_encoder(out, src_key_padding_mask=src_key_padding_mask)\n",
    "        # normalize gradients\n",
    "        out = self.norm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76848cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransDecoder(nn.Module):\n",
    "    def __init__(self, target_mask, embedding, dropout, nhead, layers, max_targets, max_step_change, max_seq_len):\n",
    "        super(TransDecoder, self).__init__()\n",
    "        self.max_targets = max_targets\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.embedding = embedding\n",
    "        self.max_step = max_step_change\n",
    "        self.pos_dim = 8\n",
    "        self.role_dim = 2\n",
    "\n",
    "        # project 2d cords to embedding space\n",
    "        self.start_pos_projection = FourierEmbedding(2, embedding, scale=1.0)\n",
    "\n",
    "        # projection for movement\n",
    "        self.delta_projection = FourierEmbedding(5, embedding, scale=5.0)\n",
    "\n",
    "        # player pos embeddings\n",
    "        self.player_pos_embedding = PlayerPositionEmbedding(self.pos_dim, 19)\n",
    "\n",
    "        # player pos embeddings\n",
    "        self.player_role_embedding = PlayerPositionEmbedding(self.role_dim, 4)\n",
    "\n",
    "        # concat info\n",
    "        self.input_fusion = nn.Linear(embedding + self.role_dim + self.pos_dim, embedding)\n",
    "\n",
    "        # project outputs back to 2d space\n",
    "        self.output_projection = nn.Linear(embedding, 5)\n",
    "\n",
    "        # postional embeddings\n",
    "        self.pos_embed = PositionalEncoding(embed_size=embedding, dropout=0.15, max_length=150)\n",
    "\n",
    "        # decoder layers\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=embedding,\n",
    "                                                    nhead=nhead,\n",
    "                                                    dim_feedforward=embedding,\n",
    "                                                    dropout=dropout,\n",
    "                                                    batch_first=True,\n",
    "                                                    norm_first=True)\n",
    "\n",
    "        # decoder\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=layers)\n",
    "\n",
    "        # norm\n",
    "        self.norm = nn.LayerNorm(embedding)\n",
    "\n",
    "    def forward(self, encoded_context, start_positions, target_mask, target_seq, player_position, player_role, encoder_padding_mask=None, train = True, output_lengths=None):\n",
    "        # project all of the postion embeddings\n",
    "        player_pos_embeds = self.player_pos_embedding(player_position, target_mask)\n",
    "        # role embeds\n",
    "        player_role_embeds = self.player_role_embedding(player_role, target_mask)\n",
    "        # train vs validation\n",
    "        if train:\n",
    "            return self.train_forward(encoded_context, start_positions, target_seq, player_pos_embeds, player_role_embeds, encoder_padding_mask)\n",
    "        else:\n",
    "            return self.val_forward(encoded_context, start_positions, player_pos_embeds, player_role_embeds, encoder_padding_mask)\n",
    "\n",
    "    def train_forward(self, encoded_context, start_positions, target_seq, player_pos_embeds, player_role_embeds, encoder_padding_mask):\n",
    "        device = encoded_context.device\n",
    "        B, T, S, _ = target_seq.shape\n",
    "\n",
    "        # inital postion\n",
    "        start_token = self.start_pos_projection(start_positions)\n",
    "        start_token = start_token.unsqueeze(2)\n",
    "\n",
    "        # ground truth deltas, we shift right, input at T2 is our target for t1\n",
    "        shifted_targets = target_seq[:, :, :-1, :]\n",
    "        delta_targets = self.delta_projection(shifted_targets) # project the change in pos sep from start, diff units\n",
    "\n",
    "        # add noise to prevent overfitting\n",
    "        noise = torch.rand_like(delta_targets) * 0.1\n",
    "        delta_targets = delta_targets + noise\n",
    "\n",
    "        # decoder input\n",
    "        decoder_input = torch.cat([start_token, delta_targets], dim=2)\n",
    "\n",
    "        # add player pos embeds\n",
    "        seq_len = decoder_input.shape[2]\n",
    "        pos_embeds = player_pos_embeds.unsqueeze(2).expand(-1, -1, seq_len, -1)\n",
    "        role_embeds = player_role_embeds.unsqueeze(2).expand(-1, -1, seq_len, -1)\n",
    "        combined_input = torch.cat([decoder_input, pos_embeds, role_embeds], dim = -1)\n",
    "        decoder_input_fused = self.input_fusion(combined_input)\n",
    "\n",
    "        # add time encoding\n",
    "        decoder_input_reshaped = decoder_input_fused.view(B*T, S, self.embedding)\n",
    "        decoder_input_encoded = self.pos_embed(decoder_input_reshaped)\n",
    "\n",
    "        # prevent lookahead\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(S, device=device)\n",
    "\n",
    "        # expand encoded context\n",
    "        expanded_context = encoded_context.repeat_interleave(T, dim=0)\n",
    "\n",
    "        if encoder_padding_mask is not None:\n",
    "            memory_key_padding_mask = encoder_padding_mask.repeat_interleave(T, dim=0)\n",
    "        else:\n",
    "            memory_key_padding_mask = None\n",
    "\n",
    "\n",
    "        decoded = self.transformer_decoder(tgt=decoder_input_encoded,\n",
    "                                           memory=expanded_context,\n",
    "                                           tgt_mask=tgt_mask,\n",
    "                                           memory_key_padding_mask=memory_key_padding_mask)\n",
    "        # batch norm\n",
    "        decoded = self.norm(decoded)\n",
    "\n",
    "        # predicted delta\n",
    "        all_preds = self.output_projection(decoded)\n",
    "\n",
    "        # reshape back to og targ seq shape\n",
    "        return all_preds.view(B, T, S, 5)\n",
    "\n",
    "    def val_forward(self, encoded_context, start_positions, player_pos_embeds, player_role_embeds, encoder_padding_mask):\n",
    "        device = encoded_context.device\n",
    "        batch_size = encoded_context.shape[0]\n",
    "\n",
    "        # init pos\n",
    "        current_input = self.start_pos_projection(start_positions).unsqueeze(2)\n",
    "\n",
    "        # player pos embeddings\n",
    "        pos_embeds = player_pos_embeds.unsqueeze(2)\n",
    "        role_embeds = player_role_embeds.unsqueeze(2)\n",
    "        combined_init = torch.cat([current_input, role_embeds, pos_embeds], dim=-1)\n",
    "        current_input_fused = self.input_fusion(combined_init)\n",
    "\n",
    "        # reshape, previous inputs\n",
    "        decoder_history = current_input_fused.view(batch_size * self.max_targets, 1, self.embedding)\n",
    "\n",
    "        # context\n",
    "        expanded_context = encoded_context.repeat_interleave(self.max_targets, dim=0)\n",
    "\n",
    "        # mem mask\n",
    "        if encoder_padding_mask is not None:\n",
    "            memory_key_padding_mask = encoder_padding_mask.repeat_interleave(self.max_targets, dim=0)\n",
    "        else:\n",
    "            memory_key_padding_mask = None\n",
    "\n",
    "        all_predictions = []\n",
    "\n",
    "        # predict actual output seq\n",
    "        for step in range(self.max_seq_len):\n",
    "\n",
    "            # postions\n",
    "            history_encoded = self.pos_embed(decoder_history)\n",
    "\n",
    "            # casual mask\n",
    "            seq_len = history_encoded.shape[1]\n",
    "            tgt_mask = nn.Transformer.generate_square_subsequent_mask(seq_len, device=device)\n",
    "\n",
    "            # through the decoded layers\n",
    "            decoded = self.transformer_decoder(\n",
    "                tgt = history_encoded,\n",
    "                memory = expanded_context,\n",
    "                tgt_mask=tgt_mask,\n",
    "                memory_key_padding_mask=memory_key_padding_mask)\n",
    "\n",
    "            decoded = self.norm(decoded)\n",
    "\n",
    "            # predict only last step\n",
    "            last_step_output = decoded[:, -1:, :]\n",
    "            next_delta_pred = self.output_projection(last_step_output)\n",
    "\n",
    "            all_predictions.append(next_delta_pred.view(batch_size, self.max_targets, 5))\n",
    "\n",
    "            # project to cords\n",
    "            next_input_embed = self.delta_projection(next_delta_pred)\n",
    "\n",
    "            # add player id context\n",
    "            player_pos_flat = player_pos_embeds.view(batch_size * self.max_targets, 1, -1)\n",
    "            player_role_flat = player_role_embeds.view(batch_size * self.max_targets, 1, -1)\n",
    "            combined_next = torch.cat([next_input_embed, player_pos_flat, player_role_flat], dim=-1)\n",
    "            next_input_fused = self.input_fusion(combined_next)\n",
    "\n",
    "            # add to context\n",
    "            decoder_history = torch.cat([decoder_history, next_input_fused], dim=1)\n",
    "\n",
    "        # stack and return preds\n",
    "        return torch.stack(all_predictions, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e14636de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T20:28:25.142008Z",
     "iopub.status.busy": "2025-11-25T20:28:25.141154Z",
     "iopub.status.idle": "2025-11-25T20:28:25.150398Z",
     "shell.execute_reply": "2025-11-25T20:28:25.149752Z"
    },
    "papermill": {
     "duration": 0.016238,
     "end_time": "2025-11-25T20:28:25.151878",
     "exception": false,
     "start_time": "2025-11-25T20:28:25.135640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqPrediction(nn.Module):\n",
    "    def __init__(self, embed_size, encoder_layers, decoder_layers,\n",
    "                 max_targets, dropout, nheads, max_step, dev='cuda') -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # general vars\n",
    "        self.embedding_size = embed_size\n",
    "        self.max_targets = max_targets\n",
    "        self.device = dev\n",
    "\n",
    "        # context cnn\n",
    "        self.context_cnn = CNN_DownSample(dim=embed_size)\n",
    "\n",
    "        # transformer encoder\n",
    "        self.encoder = TransEncoder(input_dim=embed_size,\n",
    "                                    embed_size=embed_size,\n",
    "                                    num_layers=encoder_layers,\n",
    "                                    device=dev,\n",
    "                                    nhead = nheads,\n",
    "                                    mask=None,\n",
    "                                    dropout=dropout,\n",
    "                                    max_length=150)\n",
    "\n",
    "        # decoder\n",
    "        self.decoder = TransDecoder(target_mask=None,\n",
    "                                    embedding=embed_size,\n",
    "                                    dropout=dropout,\n",
    "                                    nhead=nheads,\n",
    "                                    layers=decoder_layers,\n",
    "                                    max_targets=max_targets,\n",
    "                                    max_step_change=max_step,\n",
    "                                    max_seq_len=max_output)\n",
    "\n",
    "    def forward(self, heatmap_sequence, start_pos, target_mask,\n",
    "                input_lengths, target_seq, player_positions, player_role, train=True):\n",
    "        # derive batch size, length of transformer output\n",
    "        batch_size, seq_len = heatmap_sequence.shape[:2]\n",
    "\n",
    "        # cnn features\n",
    "        cnn_features = []\n",
    "        for t in range(seq_len):\n",
    "            frame = heatmap_sequence[:,t]\n",
    "            features = self.context_cnn(frame)\n",
    "            features = features.flatten(1)\n",
    "            cnn_features.append(features)\n",
    "\n",
    "        # stack and encode\n",
    "        sequence_feat = torch.stack(cnn_features, dim=1)\n",
    "\n",
    "        # encoder mask based on input seq\n",
    "        encoder_mask = torch.zeros(batch_size, seq_len, device=heatmap_sequence.device, dtype=torch.bool)\n",
    "        for i, length in enumerate(input_lengths):\n",
    "            encoder_mask[i, :length] = True\n",
    "\n",
    "        # context\n",
    "        encoded_context = self.encoder(sequence_feat, mask=encoder_mask)\n",
    "\n",
    "        # catch na context\n",
    "        if torch.isnan(encoded_context).any() or torch.isinf(encoded_context).any():\n",
    "            print(encoded_context)\n",
    "            raise ValueError()\n",
    "\n",
    "        # encoder padding mask\n",
    "        encoder_padding_mask = ~encoder_mask\n",
    "\n",
    "        # output predictions\n",
    "        predictions = self.decoder(encoded_context, start_pos, target_mask, target_seq, player_positions, player_role, encoder_padding_mask, train)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2fbde758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T20:28:25.162418Z",
     "iopub.status.busy": "2025-11-25T20:28:25.161603Z",
     "iopub.status.idle": "2025-11-25T20:28:25.526718Z",
     "shell.execute_reply": "2025-11-25T20:28:25.525526Z"
    },
    "papermill": {
     "duration": 0.372204,
     "end_time": "2025-11-25T20:28:25.528498",
     "exception": false,
     "start_time": "2025-11-25T20:28:25.156294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalto\\anaconda3\\envs\\nflLab\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = SeqPrediction(embed_size=64, encoder_layers=7, decoder_layers=2,\n",
    "                   max_targets=max_targets, max_step=1.4, dropout=0.2, nheads=2 , dev='cuda').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f4ccda83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345989\n"
     ]
    }
   ],
   "source": [
    "trainable_params = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
    "print(trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a1aa63db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T20:28:25.539810Z",
     "iopub.status.busy": "2025-11-25T20:28:25.539001Z",
     "iopub.status.idle": "2025-11-25T20:28:25.659602Z",
     "shell.execute_reply": "2025-11-25T20:28:25.658635Z"
    },
    "papermill": {
     "duration": 0.129477,
     "end_time": "2025-11-25T20:28:25.662670",
     "exception": false,
     "start_time": "2025-11-25T20:28:25.533193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"C:/Users/dalto/OneDrive/Pictures/Documents/Emory/NFL Lab/model_weights/11_24_2.8_64_7_2.pth\")\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a26c4047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62caa15d",
   "metadata": {
    "papermill": {
     "duration": 0.007617,
     "end_time": "2025-11-25T20:28:25.678669",
     "exception": false,
     "start_time": "2025-11-25T20:28:25.671052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Pixel Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c04a86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_map(player_data, target_player_ids, max_targets, grid_width=121, grid_height=55, sigma=.8):\n",
    "\n",
    "    num_channels = 2 + max_targets + 1\n",
    "    # three channels, one for offense, one for defense, one for ball location, one for player to predict\n",
    "    pixel_map = np.zeros((num_channels, grid_height, grid_width), dtype=np.float32)\n",
    "\n",
    "    x_vals = player_data['x'].values\n",
    "    y_vals = player_data['y'].values\n",
    "\n",
    "    for i, (x, y) in enumerate(zip(x_vals, y_vals)):\n",
    "        x_min = max(0, int(np.floor(x - 2*sigma)))\n",
    "        x_max = min(grid_width, int(np.ceil(x + 2*sigma)) + 1)\n",
    "        y_min = max(0, int(np.floor(y - 2*sigma)))\n",
    "        y_max = min(grid_height, int(np.ceil(y + 2*sigma)) + 1)\n",
    "\n",
    "        for xi in range(x_min, x_max):\n",
    "            for yi in range(y_min, y_max):\n",
    "                dist_sq = (xi - x)**2 + (yi - y)**2\n",
    "                weight = np.exp(-dist_sq / (2 * sigma**2))\n",
    "\n",
    "                player_id = player_data.iloc[i].get('nfl_id', None)\n",
    "\n",
    "                if player_id in target_player_ids:\n",
    "                    target_idx = target_player_ids.index(player_id)\n",
    "                    if target_idx < max_targets: # to prevent error\n",
    "                        pixel_map[2 + target_idx, yi, xi] += weight\n",
    "                elif player_data.iloc[i]['player_side'] == 'Offense':\n",
    "                    pixel_map[0, yi, xi] += weight\n",
    "                elif player_data.iloc[i]['player_side'] == 'Defense':\n",
    "                    pixel_map[1, yi, xi] += weight\n",
    "\n",
    "\n",
    "    ball_x = player_data['ball_land_x'].iloc[0]\n",
    "    ball_y = player_data['ball_land_y'].iloc[0]\n",
    "\n",
    "    ball_x_min = max(0, int(np.floor(ball_x - 2*sigma)))\n",
    "    ball_x_max = min(grid_width, int(np.ceil(ball_x + 2*sigma)) + 1)\n",
    "    ball_y_min = max(0, int(np.floor(ball_y - 2*sigma)))\n",
    "    ball_y_max = min(grid_height, int(np.ceil(ball_y + 2*sigma)) + 1)\n",
    "\n",
    "    for xi in range(ball_x_min, ball_x_max):\n",
    "        for yi in range(ball_y_min, ball_y_max):\n",
    "            dist_sq = (xi - ball_x)**2 + (yi - ball_y)**2\n",
    "            weight = np.exp(-dist_sq / (2 * sigma**2))\n",
    "            pixel_map[2 + max_targets, yi, xi] += weight\n",
    "\n",
    "    return pixel_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53afd690",
   "metadata": {
    "papermill": {
     "duration": 0.004442,
     "end_time": "2025-11-25T20:28:25.737870",
     "exception": false,
     "start_time": "2025-11-25T20:28:25.733428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0f1846c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T20:28:25.748893Z",
     "iopub.status.busy": "2025-11-25T20:28:25.748011Z",
     "iopub.status.idle": "2025-11-25T20:28:54.199380Z",
     "shell.execute_reply": "2025-11-25T20:28:54.198604Z"
    },
    "papermill": {
     "duration": 28.458786,
     "end_time": "2025-11-25T20:28:54.201120",
     "exception": false,
     "start_time": "2025-11-25T20:28:25.742334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scaling functions\n",
    "def var_mean_scalars(df_tracking):\n",
    "    # standard scale postion on field\n",
    "    pos_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    pos_scaler.fit(df_tracking[['x', 'y']].values)\n",
    "\n",
    "    # sort to ensure time, then take the mean change in diff between play\n",
    "    df_sorted = df_tracking.sort_values(['play_id_n', 'nfl_id', 'frame_id'])\n",
    "    deltas = df_sorted.groupby(['play_id_n', 'nfl_id'])[['x', 'y']].diff()\n",
    "\n",
    "    # rename, dop nams\n",
    "    deltas.columns = ['delta_x', 'delta_y']\n",
    "    deltas_clean = deltas.dropna()\n",
    "\n",
    "    # scaler for change values, fit to the delta\n",
    "    delta_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    delta_scaler.fit(deltas_clean[['delta_x', 'delta_y']].values)\n",
    "\n",
    "    return pos_scaler, delta_scaler\n",
    "\n",
    "df_scaler = pd.read_csv('C:/Users/dalto/OneDrive/Pictures/Documents/Emory/NFL Lab/data/2023_tracking.csv')\n",
    "pos, delta = var_mean_scalars(df_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0a13308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test: pd.DataFrame, test_input: pd.DataFrame) -> pd.DataFrame:\n",
    "    from torch.nn.utils.rnn import pad_sequence\n",
    "    # convert to pandas\n",
    "    test_input = test_input\n",
    "    # play_id_n\n",
    "    test_input['play_id_n'] = test_input.groupby(['game_id','play_id']).ngroup()\n",
    "    # normalize \n",
    "    test_input.loc[test_input['play_direction'] == 'left', 'y'] = 53.3 - test_input.loc[test_input['play_direction'] == 'left', 'y']\n",
    "    test_input.loc[test_input['play_direction'] == 'left', 'x'] = 120 - test_input.loc[test_input['play_direction'] == 'left', 'x']\n",
    "    \n",
    "    MAX_TARGETS = 9\n",
    "    # dicts\n",
    "    pos_dict = {1: ['WR'], 2: ['TE'], 3: ['QB'], 4: ['FB'], 13: ['RB'],\n",
    "                5: ['SS'], 6: ['CB'], 7: ['FS'], 8: ['S'], 9: ['ILB'], \n",
    "                10: ['LB'], 11: ['MLB'], 12: ['DE'], 14: ['NT'],\n",
    "                15: ['OLB'], 16: ['DT'], 17: ['T'], 18: ['K'], 19:['P']}\n",
    "    \n",
    "    role_dict = {0: ['Passer'], 1:['Targeted Receiver'], 2:['Defensive Coverage'], 3:['Other Route Runner']}\n",
    "    \n",
    "    # batch info\n",
    "    batch_grids = []\n",
    "    batch_start_pos_list = []\n",
    "    batch_player_pos_list = []\n",
    "    batch_player_role_list = []\n",
    "    batch_target_mask_list = []\n",
    "    batch_input_lengths = []\n",
    "    batch_play_directions = []\n",
    "\n",
    "    # info for df reconstruction\n",
    "    meta_target_ids = []\n",
    "    meta_output_lens = []\n",
    "    for (play_id, game_id), play_df in test_input.groupby(['play_id', 'game_id']):\n",
    "        # play direction store\n",
    "        batch_play_directions.append(play_df['play_direction'].iloc[0])\n",
    "        # sort frames\n",
    "        play_df = play_df.sort_values('frame_id')\n",
    "        frame_ids = play_df['frame_id'].unique()\n",
    "\n",
    "        # targets to predict\n",
    "        target_ids = play_df[play_df['player_to_predict'] == True]['nfl_id'].unique().tolist()\n",
    "        current_targets = target_ids[:MAX_TARGETS]\n",
    "        meta_target_ids.append(current_targets)\n",
    "\n",
    "        # output lens\n",
    "        t_lens = []\n",
    "        for tid in current_targets:\n",
    "            p_data = play_df[play_df['nfl_id'] == tid]\n",
    "            t_lens.append(int(p_data['num_frames_output'].iloc[0]))\n",
    "        meta_output_lens.append(t_lens)\n",
    "\n",
    "        # input grids\n",
    "        grids = []\n",
    "        for fid in frame_ids:\n",
    "            frame_data = play_df[play_df['frame_id'] == fid]\n",
    "            grid = pixel_map(frame_data, target_ids, max_targets=MAX_TARGETS)\n",
    "            grids.append(torch.from_numpy(grid).float())\n",
    "\n",
    "        # play sequence \n",
    "        play_sequence = torch.stack(grids)\n",
    "        batch_grids.append(play_sequence)\n",
    "        batch_input_lengths.append(len(frame_ids))\n",
    "\n",
    "        # last frame \n",
    "        last_frame = play_df[play_df['frame_id'] == frame_ids[-1]]\n",
    "\n",
    "        # start pos, positon, role\n",
    "        p_start_pos = torch.zeros(MAX_TARGETS, 2)\n",
    "        p_pos_ids = torch.zeros(MAX_TARGETS, dtype=torch.long)\n",
    "        p_role_ids = torch.zeros(MAX_TARGETS, dtype=torch.long)\n",
    "        p_mask = torch.zeros(MAX_TARGETS, dtype=torch.bool)\n",
    "        \n",
    "        # mask, postion, role\n",
    "        for i, tid in enumerate(current_targets):\n",
    "            p_data = last_frame[last_frame['nfl_id'] == tid]\n",
    "            if not p_data.empty:\n",
    "                # Start Pos\n",
    "                x, y = p_data['x'].iloc[0], p_data['y'].iloc[0]\n",
    "                scaled_xy = pos.transform([[x, y]])[0]\n",
    "                p_start_pos[i] = torch.tensor(scaled_xy)\n",
    "                \n",
    "                # Position ID\n",
    "                p_pos_str = p_data['player_position'].iloc[0]\n",
    "                pid = 0\n",
    "                for k, v in pos_dict.items():\n",
    "                    if p_pos_str in v:\n",
    "                        pid = k\n",
    "                        break\n",
    "                p_pos_ids[i] = pid\n",
    "\n",
    "                 # Role ID\n",
    "                p_role_str = p_data['player_role'].iloc[0]\n",
    "                print(p_role_str)\n",
    "                rid = 0\n",
    "                for k, v in role_dict.items():\n",
    "                    if p_role_str in v:\n",
    "                        rid = k\n",
    "                        break\n",
    "                p_role_ids[i] = rid\n",
    "                \n",
    "                # Mask\n",
    "                p_mask[i] = True\n",
    "        \n",
    "        batch_start_pos_list.append(p_start_pos)\n",
    "        batch_player_pos_list.append(p_pos_ids)\n",
    "        batch_player_role_list.append(p_role_ids)\n",
    "        batch_target_mask_list.append(p_mask)\n",
    "    \n",
    "    batch_sequence = pad_sequence(batch_grids, batch_first=True).to('cuda')\n",
    "    # stack all \n",
    "    batch_start_pos = torch.stack(batch_start_pos_list).to('cuda') # (B, 9, 2)\n",
    "    player_pos_tensor = torch.stack(batch_player_pos_list).to('cuda') # (B, 9)\n",
    "    player_role_tensor = torch.stack(batch_player_role_list).to('cuda') # (B, 9)\n",
    "    print(player_role_tensor)\n",
    "    target_mask = torch.stack(batch_target_mask_list).to('cuda') # (B, 9)\n",
    "\n",
    "    # model predecions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(batch_sequence, batch_start_pos, target_mask, \n",
    "                          batch_input_lengths, target_seq = None, player_positions=player_pos_tensor, player_role = player_role_tensor, train=False)    \n",
    "    # preds shape\n",
    "    pred_deltas_xy = predictions[:, :, :, :2]\n",
    "    B, S, T, _ = pred_deltas_xy.shape\n",
    "    \n",
    "    # reshape for inverse transform\n",
    "    pred_deltas_flat = pred_deltas_xy.reshape(-1, 2).cpu().numpy()\n",
    "    start_pos_flat = batch_start_pos.reshape(-1, 2).cpu().numpy()\n",
    "    \n",
    "    pred_deltas_unscaled_flat = delta.inverse_transform(pred_deltas_flat)\n",
    "    start_pos_unscaled_flat = pos.inverse_transform(start_pos_flat)\n",
    "\n",
    "    # reshape back for gpu \n",
    "    pred_deltas_unscaled = torch.tensor(pred_deltas_unscaled_flat).view(B, S, T, 2)\n",
    "    start_pos_unscaled = torch.tensor(start_pos_unscaled_flat).view(B, S, 2)\n",
    "\n",
    "    # calculate trajectory\n",
    "    pred_traj = torch.cumsum(pred_deltas_unscaled, dim=2) + start_pos_unscaled.unsqueeze(2)\n",
    "    \n",
    "    # to cpu\n",
    "    pred_traj_np = pred_traj.cpu().numpy()\n",
    "\n",
    "    # construct df\n",
    "    final_trajs = []\n",
    "    final_ids = []\n",
    "    final_steps = []\n",
    "    \n",
    "    for b in range(B):\n",
    "        targets = meta_target_ids[b]\n",
    "        lens = meta_output_lens[b]\n",
    "        play_traj = pred_traj_np[b] \n",
    "        play_dir = batch_play_directions[b]\n",
    "        \n",
    "        for i, tid in enumerate(targets):\n",
    "            seq_len = lens[i]\n",
    "            # cut sequnece below max\n",
    "            seq_len = min(seq_len, play_traj.shape[1])\n",
    "            \n",
    "            traj = play_traj[i, :seq_len, :]\n",
    "\n",
    "            if play_dir == 'left':\n",
    "                traj[:, 0] = 120 - traj[:, 0]\n",
    "                traj[:, 1] = 53.3 - traj[:, 1]\n",
    "\n",
    "            final_trajs.append(traj)\n",
    "            final_ids.extend([tid] * seq_len)\n",
    "            final_steps.extend(np.arange(1, seq_len + 1))\n",
    "    \n",
    "    # concate\n",
    "    flat_traj = np.concatenate(final_trajs, axis=0)\n",
    "\n",
    "    # add info cols\n",
    "    df_pred = pd.DataFrame(flat_traj, columns=['x', 'y'])\n",
    "\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "85572ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targeted Receiver\n",
      "Defensive Coverage\n",
      "Defensive Coverage\n",
      "tensor([[1, 2, 2, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "predections = predict(test=df['play_id_n'], test_input=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957a1fe5",
   "metadata": {
    "papermill": {
     "duration": 0.004449,
     "end_time": "2025-11-25T20:28:54.256516",
     "exception": false,
     "start_time": "2025-11-25T20:28:54.252067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f18a00e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T20:28:54.266871Z",
     "iopub.status.busy": "2025-11-25T20:28:54.266475Z",
     "iopub.status.idle": "2025-11-25T20:28:54.623203Z",
     "shell.execute_reply": "2025-11-25T20:28:54.622382Z"
    },
    "papermill": {
     "duration": 0.364017,
     "end_time": "2025-11-25T20:28:54.624923",
     "exception": false,
     "start_time": "2025-11-25T20:28:54.260906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import kaggle_evaluation.nfl_inference_server\n",
    "\n",
    "inference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1ac2411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T20:28:54.636299Z",
     "iopub.status.busy": "2025-11-25T20:28:54.635285Z",
     "iopub.status.idle": "2025-11-25T20:30:01.244378Z",
     "shell.execute_reply": "2025-11-25T20:30:01.243517Z"
    },
    "papermill": {
     "duration": 66.616579,
     "end_time": "2025-11-25T20:30:01.246262",
     "exception": false,
     "start_time": "2025-11-25T20:28:54.629683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(('/kaggle/input/nfl-big-data-bowl-2026-prediction/',))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14210809,
     "sourceId": 114239,
     "sourceType": "competition"
    },
    {
     "datasetId": 8835561,
     "sourceId": 13867751,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 514781,
     "modelInstanceId": 499547,
     "sourceId": 660473,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "nflLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 111.024322,
   "end_time": "2025-11-25T20:30:03.275934",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-25T20:28:12.251612",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
